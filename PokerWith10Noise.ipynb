{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "poker = pd.read_csv(\"poker.csv\")\n",
    "poker.columns.values\n",
    "poker = poker.head(200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "j = 0\n",
    "features = ['S1', ' C1', ' S2', ' C2', ' S3', ' C3', ' S4', ' C4', ' S5', ' C5']\n",
    "for index, m in poker.iterrows():\n",
    "    if index % 20 == 0:\n",
    "        poker.at[index,features[j]] = i + 1\n",
    "        j += 3\n",
    "        i+=10\n",
    "        if j >= 9:\n",
    "            j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for index, m in poker.iterrows():\n",
    "    if index % 20 == 0:\n",
    "        if index < 199994:\n",
    "            poker.at[index+5,:] = poker.loc[j,:]\n",
    "        else:\n",
    "            poker.at[index+1,:] = poker.loc[j,:]\n",
    "        j += 120\n",
    "        if j >= 199994:\n",
    "            j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "poker.to_csv('pokerNoise.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199970</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199971</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199972</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199973</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199974</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199975</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199976</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199977</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199978</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199979</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199980</th>\n",
       "      <td>100091</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199981</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199982</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199983</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199984</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199985</th>\n",
       "      <td>99941</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199986</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199987</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199988</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199989</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199990</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199991</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199992</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199994</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            S1   C1   S2   C2   S3   C3   S4   C4   S5   C5  Class\n",
       "0          101   12    3    2    3   11    4    5    2    5      1\n",
       "1            1    9    4    6    1    4    3    2    3    9      1\n",
       "2            1    4    3   13    2   13    2    1    3    6      1\n",
       "3            3   10    2    7    1    2    2   11    4    9      0\n",
       "4            1    3    4    5    3    4    1   12    4    6      0\n",
       "5          101   12    3    2    3   11    4    5    2    5      1\n",
       "6            3    2    4    9    3    7    4    3    4    5      0\n",
       "7            4    4    3   13    1    8    3    9    3   10      0\n",
       "8            1    9    3    8    4    4    1    7    3    5      0\n",
       "9            4    7    3   12    1   13    1    9    2    6      0\n",
       "10           2   12    1    3    2   11    2    7    4    8      0\n",
       "11           4    2    2    9    2    7    1    5    3   11      0\n",
       "12           1   13    2    6    1    6    2   11    3    5      1\n",
       "13           3    8    2    7    1    9    3    6    2    3      0\n",
       "14           2   10    1   11    1    9    3    1    1   13      0\n",
       "15           4    2    4   12    2   12    2    7    3   10      1\n",
       "16           4    5    2    2    4    9    1    5    4    1      1\n",
       "17           2    3    3    9    2    1    2    6    4   10      0\n",
       "18           1    7    2   11    4    1    2    9    3   13      0\n",
       "19           4   12    1    6    3    1    2    2    1    8      0\n",
       "20           2    5    3  111    3   13    4   13    3    8      1\n",
       "21           1    3    4    8    2    1    1   12    3    5      0\n",
       "22           2    8    4    6    1   12    2   13    1    8      1\n",
       "23           1    7    4   13    4    9    1    9    1   10      1\n",
       "24           2   13    3    3    2   11    2    6    1    4      0\n",
       "25         161    1    3   11    3   10    1    1    1   10      2\n",
       "26           2    5    3    7    2   12    3    3    2   11      0\n",
       "27           3    4    2    1    3   10    1    8    4    1      1\n",
       "28           4   11    2   13    4    4    3    8    4    1      0\n",
       "29           4   10    2    5    4    8    1    6    2   13      0\n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...\n",
       "199970       2    2    4    7    1    5    1    3    4    5      1\n",
       "199971       2    2    2    4    3    2    3   13    1    5      1\n",
       "199972       1    2    2   11    1    9    3    8    4    2      1\n",
       "199973       2    4    2    5    4    9    3   12    4    6      0\n",
       "199974       1    2    2    1    4    7    3    5    4    3      0\n",
       "199975       2   13    2   10    3    5    4    7    4    1      0\n",
       "199976       3   10    1    1    3    8    3    3    4    4      0\n",
       "199977       1    8    1    4    2    5    2   12    1   13      0\n",
       "199978       3   13    1    1    4   13    2    7    3    7      2\n",
       "199979       4   12    1    3    3    5    4    8    4    1      0\n",
       "199980  100091    4    1    8    2    8    4   10    1    2      1\n",
       "199981       1   12    4    7    3    7    3    5    2   12      2\n",
       "199982       3   13    1    1    1   10    1    5    4   10      1\n",
       "199983       2    2    1    4    4    2    2    8    1   12      1\n",
       "199984       3   12    1    8    1   12    2   10    4   12      3\n",
       "199985   99941    7    3    4    4    4    3   13    2    8      1\n",
       "199986       3    9    1    6    4    1    1    9    4    4      1\n",
       "199987       3    4    4    3    4   10    2   12    1    5      0\n",
       "199988       4    5    4   11    3    1    3   12    2   10      0\n",
       "199989       1    2    2   11    2    6    1    8    2    5      0\n",
       "199990       3   13    1   12    4    4    3    4    2    9      1\n",
       "199991       3   11    1    1    2    1    3   12    1    8      1\n",
       "199992       2    7    4   11    1    4    3    8    1    7      1\n",
       "199993       4    3    4    1    4   12    4    4    3   10      0\n",
       "199994       3    9    1    9    3    4    1    2    2    6      1\n",
       "199995       4   13    3   10    4    1    4    8    4    6      0\n",
       "199996       4   10    1   13    1    6    4    1    2   13      1\n",
       "199997       2    7    1    5    1    1    4    7    2    5      2\n",
       "199998       2    8    1    2    3    9    3   12    1    4      0\n",
       "199999       4    5    1   11    1    4    3   11    2    4      2\n",
       "\n",
       "[200000 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = poker.iloc[:,0:8]\n",
    "labels = poker.iloc[:,8].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.values.astype(np.float32) #returns a numpy array\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_scaled = pd.DataFrame(x_scaled)\n",
    "poker = pd.concat([df_scaled, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True) #5 fores me 2 folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean and k tuning on 10% noise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.30      0.30      0.30     24941\n",
      "          3       0.29      0.29      0.29     25043\n",
      "          2       0.29      0.29      0.29     24984\n",
      "          4       0.29      0.29      0.29     25032\n",
      "\n",
      "avg / total       0.29      0.29      0.29    100000\n",
      "\n",
      "accuracy:  0.29367\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.30      0.30      0.30     25148\n",
      "          3       0.29      0.29      0.29     24813\n",
      "          2       0.29      0.29      0.29     24862\n",
      "          4       0.30      0.30      0.30     25177\n",
      "\n",
      "avg / total       0.29      0.29      0.29    100000\n",
      "\n",
      "accuracy:  0.29461\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.30      0.30      0.30     25147\n",
      "          3       0.29      0.29      0.29     24706\n",
      "          2       0.29      0.29      0.29     24997\n",
      "          4       0.30      0.30      0.30     25150\n",
      "\n",
      "avg / total       0.29      0.29      0.29    100000\n",
      "\n",
      "accuracy:  0.29435\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.30      0.30      0.30     24942\n",
      "          3       0.30      0.29      0.29     25150\n",
      "          2       0.29      0.30      0.30     24849\n",
      "          4       0.29      0.30      0.30     25059\n",
      "\n",
      "avg / total       0.30      0.30      0.30    100000\n",
      "\n",
      "accuracy:  0.29583\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.29      0.30      0.30     25002\n",
      "          3       0.29      0.28      0.29     25040\n",
      "          2       0.29      0.29      0.29     24986\n",
      "          4       0.29      0.30      0.30     24972\n",
      "\n",
      "avg / total       0.29      0.29      0.29    100000\n",
      "\n",
      "accuracy:  0.29278\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.30      0.29      0.29     25087\n",
      "          3       0.29      0.29      0.29     24816\n",
      "          2       0.29      0.29      0.29     24860\n",
      "          4       0.30      0.29      0.30     25237\n",
      "\n",
      "avg / total       0.29      0.29      0.29    100000\n",
      "\n",
      "accuracy:  0.29322\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.30      0.30      0.30     25111\n",
      "          3       0.29      0.29      0.29     24882\n",
      "          2       0.30      0.30      0.30     24960\n",
      "          4       0.29      0.30      0.30     25047\n",
      "\n",
      "avg / total       0.29      0.29      0.29    100000\n",
      "\n",
      "accuracy:  0.2948\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.30      0.30      0.30     24978\n",
      "          3       0.30      0.29      0.29     24974\n",
      "          2       0.29      0.29      0.29     24886\n",
      "          4       0.30      0.30      0.30     25162\n",
      "\n",
      "avg / total       0.30      0.30      0.30    100000\n",
      "\n",
      "accuracy:  0.29554\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.30      0.30      0.30     25178\n",
      "          3       0.29      0.29      0.29     24808\n",
      "          2       0.30      0.29      0.30     25059\n",
      "          4       0.30      0.30      0.30     24955\n",
      "\n",
      "avg / total       0.30      0.30      0.30    100000\n",
      "\n",
      "accuracy:  0.29676\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.29      0.29      0.29     24911\n",
      "          3       0.30      0.29      0.29     25048\n",
      "          2       0.29      0.30      0.29     24787\n",
      "          4       0.30      0.30      0.30     25254\n",
      "\n",
      "avg / total       0.29      0.29      0.29    100000\n",
      "\n",
      "accuracy:  0.29462\n",
      "mean accuracy 0.294618\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "mean_accuracy_model_euclidean = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=1, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.28      0.37      0.32     25016\n",
      "          3       0.28      0.30      0.29     25013\n",
      "          2       0.28      0.26      0.27     24802\n",
      "          4       0.30      0.20      0.24     25169\n",
      "\n",
      "avg / total       0.29      0.28      0.28    100000\n",
      "\n",
      "accuracy:  0.28373\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.28      0.38      0.32     25073\n",
      "          3       0.28      0.30      0.29     24843\n",
      "          2       0.29      0.25      0.27     25044\n",
      "          4       0.29      0.20      0.24     25040\n",
      "\n",
      "avg / total       0.28      0.28      0.28    100000\n",
      "\n",
      "accuracy:  0.28326\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.28      0.38      0.32     24891\n",
      "          3       0.28      0.30      0.29     25009\n",
      "          2       0.29      0.25      0.27     24905\n",
      "          4       0.29      0.20      0.24     25195\n",
      "\n",
      "avg / total       0.28      0.28      0.28    100000\n",
      "\n",
      "accuracy:  0.282\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.28      0.37      0.32     25198\n",
      "          3       0.28      0.30      0.29     24847\n",
      "          2       0.29      0.26      0.27     24941\n",
      "          4       0.30      0.21      0.24     25014\n",
      "\n",
      "avg / total       0.29      0.28      0.28    100000\n",
      "\n",
      "accuracy:  0.28433\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.27      0.37      0.31     25067\n",
      "          3       0.28      0.30      0.29     25077\n",
      "          2       0.28      0.25      0.27     24809\n",
      "          4       0.30      0.21      0.24     25047\n",
      "\n",
      "avg / total       0.28      0.28      0.28    100000\n",
      "\n",
      "accuracy:  0.28191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.28      0.37      0.32     25022\n",
      "          3       0.28      0.31      0.29     24779\n",
      "          2       0.29      0.25      0.27     25037\n",
      "          4       0.30      0.20      0.24     25162\n",
      "\n",
      "avg / total       0.28      0.28      0.28    100000\n",
      "\n",
      "accuracy:  0.28243\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.27      0.37      0.32     24932\n",
      "          3       0.28      0.30      0.29     24948\n",
      "          2       0.29      0.25      0.27     24996\n",
      "          4       0.30      0.20      0.24     25124\n",
      "\n",
      "avg / total       0.28      0.28      0.28    100000\n",
      "\n",
      "accuracy:  0.28209\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.28      0.37      0.32     25157\n",
      "          3       0.28      0.31      0.29     24908\n",
      "          2       0.28      0.25      0.27     24850\n",
      "          4       0.30      0.20      0.24     25085\n",
      "\n",
      "avg / total       0.28      0.28      0.28    100000\n",
      "\n",
      "accuracy:  0.28318\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.28      0.38      0.32     24893\n",
      "          3       0.28      0.31      0.29     24936\n",
      "          2       0.29      0.25      0.27     25002\n",
      "          4       0.30      0.20      0.24     25169\n",
      "\n",
      "avg / total       0.29      0.28      0.28    100000\n",
      "\n",
      "accuracy:  0.28415\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.28      0.37      0.32     25196\n",
      "          3       0.28      0.30      0.29     24920\n",
      "          2       0.28      0.25      0.27     24844\n",
      "          4       0.30      0.21      0.25     25040\n",
      "\n",
      "avg / total       0.28      0.28      0.28    100000\n",
      "\n",
      "accuracy:  0.28311\n",
      "mean accuracy 0.283019\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.35      0.30     24972\n",
      "          3       0.26      0.27      0.27     24937\n",
      "          2       0.27      0.24      0.25     24952\n",
      "          4       0.27      0.20      0.23     25139\n",
      "\n",
      "avg / total       0.27      0.27      0.26    100000\n",
      "\n",
      "accuracy:  0.26617\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.27      0.36      0.31     25117\n",
      "          3       0.27      0.28      0.27     24919\n",
      "          2       0.27      0.23      0.25     24894\n",
      "          4       0.28      0.21      0.24     25070\n",
      "\n",
      "avg / total       0.27      0.27      0.27    100000\n",
      "\n",
      "accuracy:  0.27069\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.27      0.35      0.30     25174\n",
      "          3       0.26      0.27      0.27     24899\n",
      "          2       0.27      0.23      0.25     24858\n",
      "          4       0.27      0.21      0.24     25069\n",
      "\n",
      "avg / total       0.27      0.27      0.26    100000\n",
      "\n",
      "accuracy:  0.26657\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.36      0.30     24915\n",
      "          3       0.26      0.27      0.27     24957\n",
      "          2       0.27      0.23      0.25     24988\n",
      "          4       0.27      0.20      0.23     25140\n",
      "\n",
      "avg / total       0.27      0.27      0.26    100000\n",
      "\n",
      "accuracy:  0.26508\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.35      0.30     25086\n",
      "          3       0.27      0.28      0.27     24997\n",
      "          2       0.27      0.23      0.25     24877\n",
      "          4       0.27      0.21      0.24     25040\n",
      "\n",
      "avg / total       0.27      0.27      0.27    100000\n",
      "\n",
      "accuracy:  0.26807\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.36      0.30     25003\n",
      "          3       0.26      0.28      0.27     24859\n",
      "          2       0.27      0.23      0.25     24969\n",
      "          4       0.27      0.20      0.23     25169\n",
      "\n",
      "avg / total       0.27      0.27      0.26    100000\n",
      "\n",
      "accuracy:  0.26774\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.36      0.30     25087\n",
      "          3       0.27      0.27      0.27     25040\n",
      "          2       0.27      0.24      0.25     24715\n",
      "          4       0.28      0.21      0.24     25158\n",
      "\n",
      "avg / total       0.27      0.27      0.27    100000\n",
      "\n",
      "accuracy:  0.26843\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.35      0.30     25002\n",
      "          3       0.26      0.28      0.27     24816\n",
      "          2       0.27      0.23      0.25     25131\n",
      "          4       0.27      0.20      0.23     25051\n",
      "\n",
      "avg / total       0.27      0.27      0.26    100000\n",
      "\n",
      "accuracy:  0.26698\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.27      0.36      0.31     25033\n",
      "          3       0.27      0.28      0.27     24802\n",
      "          2       0.27      0.23      0.25     25103\n",
      "          4       0.28      0.21      0.24     25062\n",
      "\n",
      "avg / total       0.27      0.27      0.27    100000\n",
      "\n",
      "accuracy:  0.26918\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.27      0.36      0.31     25056\n",
      "          3       0.27      0.28      0.27     25054\n",
      "          2       0.27      0.23      0.25     24743\n",
      "          4       0.27      0.21      0.24     25147\n",
      "\n",
      "avg / total       0.27      0.27      0.27    100000\n",
      "\n",
      "accuracy:  0.26856\n",
      "mean accuracy 0.267747\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.27      0.34      0.30     25052\n",
      "          3       0.26      0.27      0.27     24993\n",
      "          2       0.26      0.23      0.25     24880\n",
      "          4       0.27      0.22      0.24     25075\n",
      "\n",
      "avg / total       0.27      0.27      0.26    100000\n",
      "\n",
      "accuracy:  0.26551\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.34      0.29     25037\n",
      "          3       0.26      0.27      0.26     24863\n",
      "          2       0.26      0.23      0.25     24966\n",
      "          4       0.27      0.22      0.24     25134\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26311\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.34      0.29     25003\n",
      "          3       0.26      0.26      0.26     25066\n",
      "          2       0.26      0.24      0.25     24676\n",
      "          4       0.27      0.22      0.25     25255\n",
      "\n",
      "avg / total       0.27      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26458\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.33      0.29     25086\n",
      "          3       0.26      0.27      0.27     24790\n",
      "          2       0.27      0.23      0.25     25170\n",
      "          4       0.27      0.22      0.24     24954\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26279\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.34      0.29     24944\n",
      "          3       0.27      0.27      0.27     24847\n",
      "          2       0.27      0.23      0.25     25026\n",
      "          4       0.27      0.22      0.24     25183\n",
      "\n",
      "avg / total       0.27      0.27      0.26    100000\n",
      "\n",
      "accuracy:  0.26512\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.33      0.29     25145\n",
      "          3       0.26      0.26      0.26     25009\n",
      "          2       0.27      0.24      0.25     24820\n",
      "          4       0.27      0.23      0.25     25026\n",
      "\n",
      "avg / total       0.27      0.27      0.26    100000\n",
      "\n",
      "accuracy:  0.26537\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.34      0.30     24981\n",
      "          3       0.26      0.27      0.26     24873\n",
      "          2       0.27      0.23      0.25     25099\n",
      "          4       0.27      0.23      0.25     25047\n",
      "\n",
      "avg / total       0.27      0.27      0.26    100000\n",
      "\n",
      "accuracy:  0.26545\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.34      0.30     25108\n",
      "          3       0.27      0.27      0.27     24983\n",
      "          2       0.27      0.24      0.25     24747\n",
      "          4       0.27      0.22      0.24     25162\n",
      "\n",
      "avg / total       0.27      0.27      0.27    100000\n",
      "\n",
      "accuracy:  0.26702\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.33      0.30     25169\n",
      "          3       0.26      0.26      0.26     24831\n",
      "          2       0.26      0.23      0.24     24898\n",
      "          4       0.26      0.22      0.24     25102\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26061\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.34      0.30     24920\n",
      "          3       0.26      0.26      0.26     25025\n",
      "          2       0.26      0.23      0.25     24948\n",
      "          4       0.27      0.22      0.24     25107\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26367\n",
      "mean accuracy 0.26432300000000003\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=15, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.29     25117\n",
      "          3       0.26      0.27      0.26     24863\n",
      "          2       0.27      0.24      0.25     24963\n",
      "          4       0.27      0.23      0.25     25057\n",
      "\n",
      "avg / total       0.27      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26478\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.33      0.29     24972\n",
      "          3       0.26      0.26      0.26     24993\n",
      "          2       0.27      0.24      0.25     24883\n",
      "          4       0.28      0.23      0.25     25152\n",
      "\n",
      "avg / total       0.27      0.27      0.26    100000\n",
      "\n",
      "accuracy:  0.26545\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.29     25002\n",
      "          3       0.26      0.26      0.26     25086\n",
      "          2       0.26      0.24      0.25     24809\n",
      "          4       0.27      0.23      0.25     25103\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26277\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.29     25087\n",
      "          3       0.26      0.27      0.26     24770\n",
      "          2       0.27      0.24      0.25     25037\n",
      "          4       0.27      0.23      0.25     25106\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26233\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.29     25098\n",
      "          3       0.26      0.26      0.26     24987\n",
      "          2       0.26      0.24      0.25     24801\n",
      "          4       0.27      0.22      0.24     25114\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26281\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.27      0.33      0.29     24991\n",
      "          3       0.26      0.27      0.27     24869\n",
      "          2       0.27      0.24      0.25     25045\n",
      "          4       0.27      0.23      0.25     25095\n",
      "\n",
      "avg / total       0.27      0.27      0.27    100000\n",
      "\n",
      "accuracy:  0.26647\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.29     25073\n",
      "          3       0.26      0.26      0.26     24890\n",
      "          2       0.26      0.24      0.25     24860\n",
      "          4       0.27      0.23      0.25     25177\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26278\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.29     25016\n",
      "          3       0.26      0.26      0.26     24966\n",
      "          2       0.27      0.24      0.26     24986\n",
      "          4       0.27      0.23      0.24     25032\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26376\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.27      0.32      0.29     25096\n",
      "          3       0.26      0.27      0.27     24901\n",
      "          2       0.27      0.24      0.25     25025\n",
      "          4       0.27      0.23      0.25     24978\n",
      "\n",
      "avg / total       0.27      0.27      0.26    100000\n",
      "\n",
      "accuracy:  0.26562\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.33      0.29     24993\n",
      "          3       0.26      0.26      0.26     24955\n",
      "          2       0.26      0.24      0.25     24821\n",
      "          4       0.27      0.22      0.24     25231\n",
      "\n",
      "avg / total       0.27      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26497\n",
      "mean accuracy 0.264174\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=20, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.28     25011\n",
      "          3       0.26      0.25      0.26     25094\n",
      "          2       0.26      0.24      0.25     24920\n",
      "          4       0.27      0.24      0.25     24975\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.29     25078\n",
      "          3       0.26      0.26      0.26     24762\n",
      "          2       0.26      0.24      0.25     24926\n",
      "          4       0.27      0.23      0.25     25234\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26186\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28     25053\n",
      "          3       0.26      0.26      0.26     24912\n",
      "          2       0.27      0.24      0.25     24977\n",
      "          4       0.26      0.23      0.25     25058\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26163\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.29     25036\n",
      "          3       0.26      0.26      0.26     24944\n",
      "          2       0.26      0.24      0.25     24869\n",
      "          4       0.26      0.23      0.24     25151\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26063\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.29     25060\n",
      "          3       0.26      0.26      0.26     24953\n",
      "          2       0.26      0.25      0.25     24832\n",
      "          4       0.27      0.23      0.25     25155\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26336\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.29     25029\n",
      "          3       0.26      0.26      0.26     24903\n",
      "          2       0.26      0.23      0.25     25014\n",
      "          4       0.27      0.24      0.25     25054\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26309\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.29     24940\n",
      "          3       0.26      0.25      0.26     24895\n",
      "          2       0.26      0.23      0.24     25002\n",
      "          4       0.27      0.23      0.25     25163\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26128\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28     25149\n",
      "          3       0.26      0.26      0.26     24961\n",
      "          2       0.26      0.24      0.25     24844\n",
      "          4       0.26      0.23      0.24     25046\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25983\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28     25166\n",
      "          3       0.26      0.26      0.26     24894\n",
      "          2       0.26      0.25      0.25     24800\n",
      "          4       0.26      0.23      0.24     25140\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26196\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.33      0.29     24923\n",
      "          3       0.26      0.26      0.26     24962\n",
      "          2       0.26      0.23      0.25     25046\n",
      "          4       0.27      0.24      0.25     25069\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.26311\n",
      "mean accuracy 0.2616820000000001\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=30, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.30      0.28     25255\n",
      "          3       0.26      0.24      0.25     25041\n",
      "          2       0.26      0.25      0.25     24735\n",
      "          4       0.26      0.25      0.25     24969\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25794\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.28     24834\n",
      "          3       0.26      0.25      0.25     24815\n",
      "          2       0.26      0.23      0.24     25111\n",
      "          4       0.26      0.23      0.24     25240\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25748\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28     25023\n",
      "          3       0.26      0.25      0.26     24928\n",
      "          2       0.26      0.23      0.24     25057\n",
      "          4       0.26      0.25      0.25     24992\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25931\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.30      0.28     25066\n",
      "          3       0.25      0.25      0.25     24928\n",
      "          2       0.26      0.24      0.25     24789\n",
      "          4       0.26      0.24      0.25     25217\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.2575\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28     25070\n",
      "          3       0.26      0.25      0.25     24995\n",
      "          2       0.26      0.24      0.25     24765\n",
      "          4       0.26      0.24      0.25     25170\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25872\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28     25019\n",
      "          3       0.26      0.25      0.25     24861\n",
      "          2       0.26      0.23      0.25     25081\n",
      "          4       0.26      0.24      0.25     25039\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25775\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28     25087\n",
      "          3       0.25      0.24      0.25     24947\n",
      "          2       0.26      0.24      0.25     24919\n",
      "          4       0.26      0.25      0.25     25047\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25764\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28     25002\n",
      "          3       0.26      0.26      0.26     24909\n",
      "          2       0.26      0.24      0.24     24927\n",
      "          4       0.26      0.23      0.25     25162\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25711\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28     24930\n",
      "          3       0.26      0.25      0.26     24926\n",
      "          2       0.26      0.24      0.25     24968\n",
      "          4       0.26      0.24      0.25     25176\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25839\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.30      0.28     25159\n",
      "          3       0.26      0.25      0.25     24930\n",
      "          2       0.26      0.23      0.25     24878\n",
      "          4       0.26      0.24      0.25     25033\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25886\n",
      "mean accuracy 0.25806999999999997\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=50, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28     24935\n",
      "          3       0.26      0.24      0.25     24942\n",
      "          2       0.25      0.23      0.24     24957\n",
      "          4       0.26      0.25      0.25     25166\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25657\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.29      0.28     25154\n",
      "          3       0.25      0.24      0.24     24914\n",
      "          2       0.25      0.23      0.24     24889\n",
      "          4       0.25      0.27      0.26     25043\n",
      "\n",
      "avg / total       0.26      0.26      0.25    100000\n",
      "\n",
      "accuracy:  0.25545\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      0.30      0.28     25059\n",
      "          3       0.25      0.23      0.24     24834\n",
      "          2       0.25      0.23      0.24     24880\n",
      "          4       0.26      0.25      0.26     25227\n",
      "\n",
      "avg / total       0.25      0.25      0.25    100000\n",
      "\n",
      "accuracy:  0.25473\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.30      0.28     25030\n",
      "          3       0.26      0.24      0.25     25022\n",
      "          2       0.25      0.22      0.24     24966\n",
      "          4       0.25      0.26      0.26     24982\n",
      "\n",
      "avg / total       0.25      0.25      0.25    100000\n",
      "\n",
      "accuracy:  0.25488\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      0.31      0.28     24951\n",
      "          3       0.26      0.23      0.24     24957\n",
      "          2       0.25      0.24      0.25     24868\n",
      "          4       0.26      0.25      0.25     25224\n",
      "\n",
      "avg / total       0.26      0.26      0.25    100000\n",
      "\n",
      "accuracy:  0.25578\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      0.29      0.27     25138\n",
      "          3       0.26      0.24      0.25     24899\n",
      "          2       0.26      0.22      0.24     24978\n",
      "          4       0.25      0.26      0.26     24985\n",
      "\n",
      "avg / total       0.25      0.25      0.25    100000\n",
      "\n",
      "accuracy:  0.25416\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.30      0.28     25182\n",
      "          3       0.25      0.24      0.25     24792\n",
      "          2       0.25      0.24      0.24     24852\n",
      "          4       0.26      0.25      0.25     25174\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25634\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28     24907\n",
      "          3       0.26      0.23      0.24     25064\n",
      "          2       0.25      0.23      0.24     24994\n",
      "          4       0.26      0.26      0.26     25035\n",
      "\n",
      "avg / total       0.26      0.26      0.25    100000\n",
      "\n",
      "accuracy:  0.2558\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.30      0.28     25072\n",
      "          3       0.25      0.24      0.25     24899\n",
      "          2       0.26      0.23      0.24     24903\n",
      "          4       0.26      0.25      0.25     25126\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25672\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.30      0.28     25017\n",
      "          3       0.25      0.23      0.24     24957\n",
      "          2       0.25      0.22      0.24     24943\n",
      "          4       0.26      0.26      0.26     25083\n",
      "\n",
      "avg / total       0.25      0.25      0.25    100000\n",
      "\n",
      "accuracy:  0.25463\n",
      "mean accuracy 0.255506\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      0.31      0.28     24955\n",
      "          3       0.26      0.24      0.25     24925\n",
      "          2       0.25      0.21      0.23     24991\n",
      "          4       0.26      0.26      0.26     25129\n",
      "\n",
      "avg / total       0.25      0.25      0.25    100000\n",
      "\n",
      "accuracy:  0.25447\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      0.29      0.27     25134\n",
      "          3       0.26      0.22      0.24     24931\n",
      "          2       0.25      0.23      0.24     24855\n",
      "          4       0.25      0.27      0.26     25080\n",
      "\n",
      "avg / total       0.25      0.25      0.25    100000\n",
      "\n",
      "accuracy:  0.25377\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.32      0.28     24931\n",
      "          3       0.26      0.24      0.25     24895\n",
      "          2       0.25      0.22      0.24     24915\n",
      "          4       0.25      0.25      0.25     25259\n",
      "\n",
      "avg / total       0.26      0.26      0.25    100000\n",
      "\n",
      "accuracy:  0.25624\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.29      0.27     25158\n",
      "          3       0.26      0.23      0.24     24961\n",
      "          2       0.26      0.23      0.24     24931\n",
      "          4       0.25      0.28      0.26     24950\n",
      "\n",
      "avg / total       0.26      0.26      0.25    100000\n",
      "\n",
      "accuracy:  0.25525\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      0.30      0.27     25031\n",
      "          3       0.25      0.23      0.24     24890\n",
      "          2       0.26      0.21      0.23     25111\n",
      "          4       0.26      0.28      0.27     24968\n",
      "\n",
      "avg / total       0.26      0.26      0.25    100000\n",
      "\n",
      "accuracy:  0.25525\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.30      0.28     25058\n",
      "          3       0.25      0.22      0.24     24966\n",
      "          2       0.25      0.24      0.24     24735\n",
      "          4       0.26      0.26      0.26     25241\n",
      "\n",
      "avg / total       0.25      0.25      0.25    100000\n",
      "\n",
      "accuracy:  0.25431\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.29      0.27     25110\n",
      "          3       0.26      0.24      0.25     24853\n",
      "          2       0.25      0.22      0.23     24937\n",
      "          4       0.26      0.27      0.26     25100\n",
      "\n",
      "avg / total       0.25      0.25      0.25    100000\n",
      "\n",
      "accuracy:  0.25456\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28     24979\n",
      "          3       0.25      0.22      0.23     25003\n",
      "          2       0.26      0.23      0.24     24909\n",
      "          4       0.26      0.27      0.26     25109\n",
      "\n",
      "avg / total       0.26      0.26      0.26    100000\n",
      "\n",
      "accuracy:  0.25633\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.29      0.27     25197\n",
      "          3       0.25      0.23      0.24     24887\n",
      "          2       0.25      0.23      0.24     24819\n",
      "          4       0.25      0.26      0.26     25097\n",
      "\n",
      "avg / total       0.25      0.25      0.25    100000\n",
      "\n",
      "accuracy:  0.25448\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      0.31      0.28     24892\n",
      "          3       0.25      0.23      0.24     24969\n",
      "          2       0.25      0.21      0.23     25027\n",
      "          4       0.25      0.26      0.26     25112\n",
      "\n",
      "avg / total       0.25      0.25      0.25    100000\n",
      "\n",
      "accuracy:  0.25355\n",
      "mean accuracy 0.2548210000000001\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=150, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.294618, 0.283019, 0.267747, 0.26432300000000003, 0.264174, 0.2616820000000001, 0.25806999999999997, 0.255506, 0.2548210000000001]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-fcb2653aa17c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmean_accuracy_model_euclidean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_accuracy_model_euclidean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "print mean_accuracy_model_euclidean\n",
    "k = [1, 5, 10, 15, 20, 30, 50, 100, 150]\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(k, mean_accuracy_model_euclidean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minkowski and k tuning on 10% dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "mean_accuracy_model_minkowski = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=1, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=15, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=20, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=30, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=50, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=150, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mean_accuracy_model_minkowski\n",
    "k = [1, 5, 10, 15, 20, 30, 50, 100, 150]\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(k, mean_accuracy_model_minkowski)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(k, mean_accuracy_model_minkowski)\n",
    "ax.plot(k, mean_accuracy_model_euclidean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
