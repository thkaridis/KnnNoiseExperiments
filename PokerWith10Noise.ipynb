{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S1', ' C1', ' S2', ' C2', ' S3', ' C3', ' S4', ' C4', ' S5',\n",
       "       ' C5', 'Class'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poker = pd.read_csv(\"poker.csv\")\n",
    "poker.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "j = 0\n",
    "features = ['S1', ' C1', ' S2', ' C2', ' S3', ' C3', ' S4', ' C4', ' S5', ' C5']\n",
    "for index, m in poker.iterrows():\n",
    "    if index % 20 == 0:\n",
    "        poker.at[index,features[j]] = i + 1\n",
    "        j += 3\n",
    "        i+=10\n",
    "        if j >= 9:\n",
    "            j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for index, m in poker.iterrows():\n",
    "    if index % 20 == 0:\n",
    "        if index < 1025003:\n",
    "            poker.at[index+5,:] = poker.loc[j,:]\n",
    "        else:\n",
    "            poker.at[index+1,:] = poker.loc[j,:]\n",
    "        j += 120\n",
    "        if j >= 1025008:\n",
    "            j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "poker.to_csv('/home/valia/Documents/AppliedDataScience/pokerNoise.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024979</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024980</th>\n",
       "      <td>512591</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024981</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024982</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024983</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024984</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024985</th>\n",
       "      <td>512441</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024986</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024987</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024988</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024989</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024990</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024991</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024992</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024993</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024994</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024995</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024996</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024997</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024998</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024999</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025000</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>512601</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025001</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025002</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025003</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025004</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025005</th>\n",
       "      <td>512501</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025006</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025007</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025008</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025009 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             S1   C1   S2      C2   S3   C3   S4   C4   S5   C5  Class\n",
       "0           101   12    3       2    3   11    4    5    2    5      1\n",
       "1             1    9    4       6    1    4    3    2    3    9      1\n",
       "2             1    4    3      13    2   13    2    1    3    6      1\n",
       "3             3   10    2       7    1    2    2   11    4    9      0\n",
       "4             1    3    4       5    3    4    1   12    4    6      0\n",
       "5           101   12    3       2    3   11    4    5    2    5      1\n",
       "6             3    2    4       9    3    7    4    3    4    5      0\n",
       "7             4    4    3      13    1    8    3    9    3   10      0\n",
       "8             1    9    3       8    4    4    1    7    3    5      0\n",
       "9             4    7    3      12    1   13    1    9    2    6      0\n",
       "10            2   12    1       3    2   11    2    7    4    8      0\n",
       "11            4    2    2       9    2    7    1    5    3   11      0\n",
       "12            1   13    2       6    1    6    2   11    3    5      1\n",
       "13            3    8    2       7    1    9    3    6    2    3      0\n",
       "14            2   10    1      11    1    9    3    1    1   13      0\n",
       "15            4    2    4      12    2   12    2    7    3   10      1\n",
       "16            4    5    2       2    4    9    1    5    4    1      1\n",
       "17            2    3    3       9    2    1    2    6    4   10      0\n",
       "18            1    7    2      11    4    1    2    9    3   13      0\n",
       "19            4   12    1       6    3    1    2    2    1    8      0\n",
       "20            2    5    3     111    3   13    4   13    3    8      1\n",
       "21            1    3    4       8    2    1    1   12    3    5      0\n",
       "22            2    8    4       6    1   12    2   13    1    8      1\n",
       "23            1    7    4      13    4    9    1    9    1   10      1\n",
       "24            2   13    3       3    2   11    2    6    1    4      0\n",
       "25          161    1    3      11    3   10    1    1    1   10      2\n",
       "26            2    5    3       7    2   12    3    3    2   11      0\n",
       "27            3    4    2       1    3   10    1    8    4    1      1\n",
       "28            4   11    2      13    4    4    3    8    4    1      0\n",
       "29            4   10    2       5    4    8    1    6    2   13      0\n",
       "...         ...  ...  ...     ...  ...  ...  ...  ...  ...  ...    ...\n",
       "1024979       4    5    4      13    3   10    1   13    3    2      1\n",
       "1024980  512591    3    1      11    4    2    3    6    3    9      0\n",
       "1024981       4    1    2       1    1    3    2    6    3    1      3\n",
       "1024982       3    2    3       1    4   10    4    6    1    3      0\n",
       "1024983       2    9    3       1    4    5    2    6    3   10      0\n",
       "1024984       3   10    1       5    3    3    4    3    4    2      1\n",
       "1024985  512441    2    3       6    4    1    2    3    2   11      0\n",
       "1024986       2   12    3       9    1    4    3    7    4    3      0\n",
       "1024987       4    8    1       8    1    4    3    3    4   12      1\n",
       "1024988       4   11    3       2    2   13    4    6    4   12      0\n",
       "1024989       4   10    2      11    2    9    4    5    1    8      0\n",
       "1024990       2   11    2       9    4    9    4    6    2   10      1\n",
       "1024991       4    6    4      10    1    1    1    4    1    3      0\n",
       "1024992       2    6    2      13    2    5    4    3    2   11      0\n",
       "1024993       4    7    1      10    2    6    1   11    3    7      1\n",
       "1024994       2   12    1       2    4    8    3    3    4    6      0\n",
       "1024995       2   11    1       5    1   10    4   10    2   13      1\n",
       "1024996       3    7    3      13    2    4    1   12    3    8      0\n",
       "1024997       1    8    4       1    4   12    1   13    1   10      0\n",
       "1024998       4   12    3      11    4    4    3   12    2   12      3\n",
       "1024999       2    8    2      12    4    3    4    2    4    4      0\n",
       "1025000       2   12    3  512601    3    8    4    1    4    2      0\n",
       "1025001       4   10    2      13    4    5    4    7    1    5      1\n",
       "1025002       1   12    2       9    2   12    4    8    1   13      1\n",
       "1025003       3    5    3       7    4   11    3   11    3    2      1\n",
       "1025004       3    9    2       6    4   11    4   12    2    4      0\n",
       "1025005  512501   13    4       4    4    7    1    3    4   13      1\n",
       "1025006       2    1    2      10    4    4    4    1    4   13      1\n",
       "1025007       2   12    4       3    1   10    1   12    4    9      1\n",
       "1025008       1    7    3      11    3    3    4    8    3    7      1\n",
       "\n",
       "[1025009 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2\n",
       "1          3\n",
       "2          3\n",
       "3          4\n",
       "4          4\n",
       "5          2\n",
       "6          4\n",
       "7          3\n",
       "8          3\n",
       "9          2\n",
       "10         4\n",
       "11         3\n",
       "12         3\n",
       "13         2\n",
       "14         1\n",
       "15         3\n",
       "16         4\n",
       "17         4\n",
       "18         3\n",
       "19         1\n",
       "20         3\n",
       "21         3\n",
       "22         1\n",
       "23         1\n",
       "24         1\n",
       "25         1\n",
       "26         2\n",
       "27         4\n",
       "28         4\n",
       "29         2\n",
       "          ..\n",
       "1024979    3\n",
       "1024980    3\n",
       "1024981    3\n",
       "1024982    1\n",
       "1024983    3\n",
       "1024984    4\n",
       "1024985    2\n",
       "1024986    4\n",
       "1024987    4\n",
       "1024988    4\n",
       "1024989    1\n",
       "1024990    2\n",
       "1024991    1\n",
       "1024992    2\n",
       "1024993    3\n",
       "1024994    4\n",
       "1024995    2\n",
       "1024996    3\n",
       "1024997    1\n",
       "1024998    2\n",
       "1024999    4\n",
       "1025000    4\n",
       "1025001    1\n",
       "1025002    1\n",
       "1025003    3\n",
       "1025004    2\n",
       "1025005    4\n",
       "1025006    4\n",
       "1025007    4\n",
       "1025008    3\n",
       "Name:  S5, Length: 1025009, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = poker.iloc[:,0:8]\n",
    "labels = poker.iloc[:,8].apply(str)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True) #5 fores me 2 folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean and k tuning on 10% noise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.30      0.30    128489\n",
      "           3       0.30      0.30      0.30    127625\n",
      "           2       0.30      0.30      0.30    128416\n",
      "           4       0.30      0.30      0.30    127975\n",
      "\n",
      "   micro avg       0.30      0.30      0.30    512505\n",
      "   macro avg       0.30      0.30      0.30    512505\n",
      "weighted avg       0.30      0.30      0.30    512505\n",
      "\n",
      "accuracy:  0.29930829943122506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.30      0.30    128844\n",
      "           3       0.30      0.30      0.30    127824\n",
      "           2       0.30      0.30      0.30    127576\n",
      "           4       0.30      0.30      0.30    128260\n",
      "\n",
      "   micro avg       0.30      0.30      0.30    512504\n",
      "   macro avg       0.30      0.30      0.30    512504\n",
      "weighted avg       0.30      0.30      0.30    512504\n",
      "\n",
      "accuracy:  0.29977327006228244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.30      0.30    128526\n",
      "           3       0.30      0.29      0.30    127925\n",
      "           2       0.30      0.30      0.30    127642\n",
      "           4       0.30      0.30      0.30    128412\n",
      "\n",
      "   micro avg       0.30      0.30      0.30    512505\n",
      "   macro avg       0.30      0.30      0.30    512505\n",
      "weighted avg       0.30      0.30      0.30    512505\n",
      "\n",
      "accuracy:  0.29939415225217314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.30      0.30    128807\n",
      "           3       0.30      0.30      0.30    127524\n",
      "           2       0.30      0.30      0.30    128350\n",
      "           4       0.30      0.30      0.30    127823\n",
      "\n",
      "   micro avg       0.30      0.30      0.30    512504\n",
      "   macro avg       0.30      0.30      0.30    512504\n",
      "weighted avg       0.30      0.30      0.30    512504\n",
      "\n",
      "accuracy:  0.2998142453522314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.30      0.30    128839\n",
      "           3       0.30      0.30      0.30    127580\n",
      "           2       0.30      0.30      0.30    127715\n",
      "           4       0.30      0.30      0.30    128371\n",
      "\n",
      "   micro avg       0.30      0.30      0.30    512505\n",
      "   macro avg       0.30      0.30      0.30    512505\n",
      "weighted avg       0.30      0.30      0.30    512505\n",
      "\n",
      "accuracy:  0.3008692598120994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.30      0.30    128494\n",
      "           3       0.30      0.30      0.30    127869\n",
      "           2       0.30      0.30      0.30    128277\n",
      "           4       0.30      0.30      0.30    127864\n",
      "\n",
      "   micro avg       0.30      0.30      0.30    512504\n",
      "   macro avg       0.30      0.30      0.30    512504\n",
      "weighted avg       0.30      0.30      0.30    512504\n",
      "\n",
      "accuracy:  0.3003957042286499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.30      0.30    128766\n",
      "           3       0.30      0.30      0.30    128021\n",
      "           2       0.30      0.30      0.30    127764\n",
      "           4       0.30      0.30      0.30    127954\n",
      "\n",
      "   micro avg       0.30      0.30      0.30    512505\n",
      "   macro avg       0.30      0.30      0.30    512505\n",
      "weighted avg       0.30      0.30      0.30    512505\n",
      "\n",
      "accuracy:  0.29969463712549144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.30      0.30    128567\n",
      "           3       0.30      0.30      0.30    127428\n",
      "           2       0.30      0.30      0.30    128228\n",
      "           4       0.30      0.30      0.30    128281\n",
      "\n",
      "   micro avg       0.30      0.30      0.30    512504\n",
      "   macro avg       0.30      0.30      0.30    512504\n",
      "weighted avg       0.30      0.30      0.30    512504\n",
      "\n",
      "accuracy:  0.3006396047640604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.30      0.30    128317\n",
      "           3       0.30      0.30      0.30    128193\n",
      "           2       0.30      0.30      0.30    128090\n",
      "           4       0.30      0.30      0.30    127905\n",
      "\n",
      "   micro avg       0.30      0.30      0.30    512505\n",
      "   macro avg       0.30      0.30      0.30    512505\n",
      "weighted avg       0.30      0.30      0.30    512505\n",
      "\n",
      "accuracy:  0.2990507409683808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.30      0.30    129016\n",
      "           3       0.30      0.30      0.30    127256\n",
      "           2       0.30      0.30      0.30    127902\n",
      "           4       0.30      0.30      0.30    128330\n",
      "\n",
      "   micro avg       0.30      0.30      0.30    512504\n",
      "   macro avg       0.30      0.30      0.30    512504\n",
      "weighted avg       0.30      0.30      0.30    512504\n",
      "\n",
      "accuracy:  0.29983961100791406\n",
      "mean accuracy 0.2998779525004508\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "mean_accuracy_model_euclidean = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=1, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.37      0.32    128604\n",
      "           3       0.28      0.31      0.29    127636\n",
      "           2       0.28      0.25      0.27    128097\n",
      "           4       0.30      0.20      0.24    128168\n",
      "\n",
      "   micro avg       0.28      0.28      0.28    512505\n",
      "   macro avg       0.28      0.28      0.28    512505\n",
      "weighted avg       0.28      0.28      0.28    512505\n",
      "\n",
      "accuracy:  0.28293577623632943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.37      0.32    128729\n",
      "           3       0.28      0.31      0.29    127813\n",
      "           2       0.28      0.25      0.27    127895\n",
      "           4       0.30      0.20      0.24    128067\n",
      "\n",
      "   micro avg       0.28      0.28      0.28    512504\n",
      "   macro avg       0.28      0.28      0.28    512504\n",
      "weighted avg       0.28      0.28      0.28    512504\n",
      "\n",
      "accuracy:  0.2830436445374085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.37      0.32    128886\n",
      "           3       0.28      0.31      0.29    127672\n",
      "           2       0.28      0.25      0.27    127761\n",
      "           4       0.30      0.20      0.24    128186\n",
      "\n",
      "   micro avg       0.28      0.28      0.28    512505\n",
      "   macro avg       0.28      0.28      0.28    512505\n",
      "weighted avg       0.28      0.28      0.28    512505\n",
      "\n",
      "accuracy:  0.2823796841006429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.37      0.32    128447\n",
      "           3       0.28      0.31      0.29    127777\n",
      "           2       0.29      0.25      0.27    128231\n",
      "           4       0.29      0.20      0.24    128049\n",
      "\n",
      "   micro avg       0.28      0.28      0.28    512504\n",
      "   macro avg       0.28      0.28      0.28    512504\n",
      "weighted avg       0.28      0.28      0.28    512504\n",
      "\n",
      "accuracy:  0.2828309632705306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.37      0.32    128648\n",
      "           3       0.28      0.31      0.29    127547\n",
      "           2       0.28      0.25      0.27    128087\n",
      "           4       0.30      0.20      0.24    128223\n",
      "\n",
      "   micro avg       0.28      0.28      0.28    512505\n",
      "   macro avg       0.28      0.28      0.28    512505\n",
      "weighted avg       0.28      0.28      0.28    512505\n",
      "\n",
      "accuracy:  0.28306065306679934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.37      0.32    128685\n",
      "           3       0.28      0.30      0.29    127902\n",
      "           2       0.28      0.25      0.27    127905\n",
      "           4       0.29      0.20      0.24    128012\n",
      "\n",
      "   micro avg       0.28      0.28      0.28    512504\n",
      "   macro avg       0.28      0.28      0.28    512504\n",
      "weighted avg       0.28      0.28      0.28    512504\n",
      "\n",
      "accuracy:  0.2812231709411048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.37      0.32    128839\n",
      "           3       0.28      0.31      0.29    127711\n",
      "           2       0.29      0.25      0.27    128111\n",
      "           4       0.30      0.20      0.24    127844\n",
      "\n",
      "   micro avg       0.28      0.28      0.28    512505\n",
      "   macro avg       0.28      0.28      0.28    512505\n",
      "weighted avg       0.28      0.28      0.28    512505\n",
      "\n",
      "accuracy:  0.2827191929834831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.37      0.32    128494\n",
      "           3       0.28      0.31      0.29    127738\n",
      "           2       0.28      0.25      0.27    127881\n",
      "           4       0.30      0.20      0.24    128391\n",
      "\n",
      "   micro avg       0.28      0.28      0.28    512504\n",
      "   macro avg       0.28      0.28      0.28    512504\n",
      "weighted avg       0.28      0.28      0.28    512504\n",
      "\n",
      "accuracy:  0.28272364703494995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.37      0.31    128755\n",
      "           3       0.28      0.30      0.29    127917\n",
      "           2       0.29      0.26      0.27    128032\n",
      "           4       0.30      0.20      0.24    127801\n",
      "\n",
      "   micro avg       0.28      0.28      0.28    512505\n",
      "   macro avg       0.28      0.28      0.28    512505\n",
      "weighted avg       0.28      0.28      0.28    512505\n",
      "\n",
      "accuracy:  0.2822489536687447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.37      0.32    128578\n",
      "           3       0.28      0.31      0.29    127532\n",
      "           2       0.28      0.25      0.27    127960\n",
      "           4       0.30      0.20      0.24    128434\n",
      "\n",
      "   micro avg       0.28      0.28      0.28    512504\n",
      "   macro avg       0.28      0.28      0.28    512504\n",
      "weighted avg       0.28      0.28      0.28    512504\n",
      "\n",
      "accuracy:  0.28242706398389084\n",
      "mean accuracy 0.2825592749823885\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.35      0.30    128646\n",
      "           3       0.26      0.28      0.27    127869\n",
      "           2       0.26      0.23      0.25    127848\n",
      "           4       0.27      0.20      0.23    128142\n",
      "\n",
      "   micro avg       0.26      0.26      0.26    512505\n",
      "   macro avg       0.26      0.26      0.26    512505\n",
      "weighted avg       0.26      0.26      0.26    512505\n",
      "\n",
      "accuracy:  0.26424327567535927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.35      0.30    128687\n",
      "           3       0.26      0.27      0.27    127580\n",
      "           2       0.26      0.23      0.24    128144\n",
      "           4       0.27      0.20      0.23    128093\n",
      "\n",
      "   micro avg       0.26      0.26      0.26    512504\n",
      "   macro avg       0.26      0.26      0.26    512504\n",
      "weighted avg       0.26      0.26      0.26    512504\n",
      "\n",
      "accuracy:  0.26340282222187533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.35      0.30    128761\n",
      "           3       0.26      0.28      0.27    127487\n",
      "           2       0.27      0.23      0.25    128014\n",
      "           4       0.27      0.20      0.23    128243\n",
      "\n",
      "   micro avg       0.26      0.26      0.26    512505\n",
      "   macro avg       0.26      0.26      0.26    512505\n",
      "weighted avg       0.26      0.26      0.26    512505\n",
      "\n",
      "accuracy:  0.26384132837728413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.35      0.30    128572\n",
      "           3       0.26      0.27      0.27    127962\n",
      "           2       0.26      0.23      0.24    127978\n",
      "           4       0.26      0.20      0.23    127992\n",
      "\n",
      "   micro avg       0.26      0.26      0.26    512504\n",
      "   macro avg       0.26      0.26      0.26    512504\n",
      "weighted avg       0.26      0.26      0.26    512504\n",
      "\n",
      "accuracy:  0.2639452570126282\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.35      0.30    128959\n",
      "           3       0.26      0.28      0.27    127416\n",
      "           2       0.26      0.23      0.24    127870\n",
      "           4       0.26      0.20      0.23    128260\n",
      "\n",
      "   micro avg       0.26      0.26      0.26    512505\n",
      "   macro avg       0.26      0.26      0.26    512505\n",
      "weighted avg       0.26      0.26      0.26    512505\n",
      "\n",
      "accuracy:  0.2628364601320963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.35      0.30    128374\n",
      "           3       0.26      0.27      0.27    128033\n",
      "           2       0.26      0.23      0.24    128122\n",
      "           4       0.26      0.20      0.23    127975\n",
      "\n",
      "   micro avg       0.26      0.26      0.26    512504\n",
      "   macro avg       0.26      0.26      0.26    512504\n",
      "weighted avg       0.26      0.26      0.26    512504\n",
      "\n",
      "accuracy:  0.2628252657540234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.35      0.30    128353\n",
      "           3       0.26      0.27      0.27    127938\n",
      "           2       0.27      0.23      0.25    128060\n",
      "           4       0.27      0.20      0.23    128154\n",
      "\n",
      "   micro avg       0.26      0.26      0.26    512505\n",
      "   macro avg       0.26      0.26      0.26    512505\n",
      "weighted avg       0.26      0.26      0.26    512505\n",
      "\n",
      "accuracy:  0.2638705963844255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.35      0.30    128980\n",
      "           3       0.26      0.28      0.27    127511\n",
      "           2       0.26      0.23      0.24    127932\n",
      "           4       0.27      0.20      0.23    128081\n",
      "\n",
      "   micro avg       0.26      0.26      0.26    512504\n",
      "   macro avg       0.26      0.26      0.26    512504\n",
      "weighted avg       0.26      0.26      0.26    512504\n",
      "\n",
      "accuracy:  0.2627979488940574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.35      0.30    128435\n",
      "           3       0.26      0.27      0.27    127913\n",
      "           2       0.26      0.23      0.25    128011\n",
      "           4       0.26      0.20      0.23    128146\n",
      "\n",
      "   micro avg       0.26      0.26      0.26    512505\n",
      "   macro avg       0.26      0.26      0.26    512505\n",
      "weighted avg       0.26      0.26      0.26    512505\n",
      "\n",
      "accuracy:  0.2627993873230505\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=15, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=20, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=30, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=50, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(poker):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=150, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mean_accuracy_model_euclidean\n",
    "k = [1, 5, 10, 15, 20, 30, 50, 100, 150]\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(k, mean_accuracy_model_euclidean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minkowski and k tuning on 10% dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "mean_accuracy_model_minkowski = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=1, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=15, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=20, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=30, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=50, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=150, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mean_accuracy_model_minkowski\n",
    "k = [1, 5, 10, 15, 20, 30, 50, 100, 150]\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(k, mean_accuracy_model_minkowski)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(k, mean_accuracy_model_minkowski)\n",
    "ax.plot(k, mean_accuracy_model_euclidean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
