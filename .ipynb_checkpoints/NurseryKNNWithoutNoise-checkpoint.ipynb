{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nursery_numerical.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:,0:8]\n",
    "labels = df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = data.iloc[:10000,0:8]\n",
    "dataTest = data.iloc[10000:,0:8]\n",
    "labelsTrain = labels.iloc[0:10000]\n",
    "labelsTest = labels.iloc[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, algorithm = 'auto', metric = 'minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(dataTrain, labelsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = knn.predict(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    recomend       0.42      0.43      0.43       980\n",
      "   not_recom       0.59      0.64      0.61       552\n",
      "  spec_recom       0.00      0.00      0.00         1\n",
      "    priority       0.65      0.61      0.63      1395\n",
      "  spec_prior       0.76      0.50      0.60        32\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      2960\n",
      "   macro avg       0.48      0.44      0.45      2960\n",
      "weighted avg       0.56      0.56      0.56      2960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valia/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print classification_report(labelsTest, predicted, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True) #5 fores me 2 folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean metric and k tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.25      0.26      2211\n",
      "    priority       0.52      0.56      0.54      2111\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.45      0.47      0.46      1991\n",
      "   not_recom       0.38      0.42      0.40       165\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.33      0.34      0.33      6480\n",
      "weighted avg       0.41      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.42052469135802467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.27      0.25      0.26      2108\n",
      "    priority       0.52      0.57      0.55      2155\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.46      0.45      0.46      2054\n",
      "   not_recom       0.38      0.47      0.42       163\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.33      0.35      0.33      6480\n",
      "weighted avg       0.42      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.42314814814814816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.25      0.27      2139\n",
      "    priority       0.52      0.56      0.54      2129\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.48      0.47      0.47      2058\n",
      "   not_recom       0.35      0.44      0.39       154\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.33      0.35      0.33      6480\n",
      "weighted avg       0.42      0.43      0.43      6480\n",
      "\n",
      "accuracy:  0.42901234567901236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.26      0.27      2180\n",
      "    priority       0.52      0.56      0.54      2137\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.45      0.45      0.45      1987\n",
      "   not_recom       0.45      0.52      0.48       174\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.42      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.4242283950617284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.25      0.26      2140\n",
      "    priority       0.52      0.57      0.54      2124\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.47      0.48      0.47      2048\n",
      "   not_recom       0.34      0.39      0.36       166\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.32      0.34      0.33      6480\n",
      "weighted avg       0.42      0.43      0.42      6480\n",
      "\n",
      "accuracy:  0.42885802469135803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.25      0.27      2179\n",
      "    priority       0.52      0.55      0.54      2142\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.46      0.47      0.47      1997\n",
      "   not_recom       0.37      0.49      0.42       162\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.33      0.35      0.34      6480\n",
      "weighted avg       0.42      0.43      0.42      6480\n",
      "\n",
      "accuracy:  0.4263888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.26      0.27      2175\n",
      "    priority       0.51      0.55      0.53      2131\n",
      "  spec_prior       0.17      1.00      0.29         1\n",
      "   recommend       0.45      0.46      0.45      2003\n",
      "   not_recom       0.37      0.38      0.38       170\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.36      0.53      0.38      6480\n",
      "weighted avg       0.41      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.4192901234567901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.26      0.27      2144\n",
      "    priority       0.52      0.57      0.54      2135\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.44      0.45      2042\n",
      "   not_recom       0.36      0.46      0.40       158\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.33      0.35      0.33      6480\n",
      "weighted avg       0.42      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.4243827160493827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.25      0.26      2206\n",
      "    priority       0.51      0.54      0.53      2137\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.45      0.47      0.46      1968\n",
      "   not_recom       0.38      0.40      0.39       168\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.32      0.33      0.33      6480\n",
      "weighted avg       0.41      0.42      0.41      6480\n",
      "\n",
      "accuracy:  0.41712962962962963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.26      0.27      2113\n",
      "    priority       0.53      0.56      0.54      2129\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.48      0.46      0.47      2077\n",
      "   not_recom       0.37      0.49      0.42       160\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.33      0.35      0.34      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "accuracy:  0.4294753086419753\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=1, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            #print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.39      0.39      2170\n",
      "    priority       0.61      0.63      0.62      2184\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.54      0.50      0.52      1975\n",
      "   not_recom       0.57      0.46      0.51       150\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.42      0.40      0.41      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.5084876543209876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.39      0.42      0.40      2149\n",
      "    priority       0.59      0.68      0.64      2082\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.47      0.51      2070\n",
      "   not_recom       0.76      0.29      0.42       178\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      6480\n",
      "   macro avg       0.46      0.37      0.39      6480\n",
      "weighted avg       0.52      0.52      0.51      6480\n",
      "\n",
      "accuracy:  0.5162037037037037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.42      0.40      2142\n",
      "    priority       0.60      0.65      0.62      2120\n",
      "  spec_prior       0.56      0.49      0.52      2049\n",
      "   not_recom       0.68      0.25      0.36       169\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.55      0.45      0.48      6480\n",
      "weighted avg       0.52      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.5095679012345679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.40      0.39      2177\n",
      "    priority       0.60      0.65      0.62      2146\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.56      0.50      0.53      1996\n",
      "   not_recom       0.69      0.35      0.46       159\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.45      0.38      0.40      6480\n",
      "weighted avg       0.52      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.5131172839506173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.39      0.39      0.39      2207\n",
      "    priority       0.59      0.67      0.63      2091\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.56      0.51      0.53      2019\n",
      "   not_recom       0.70      0.33      0.45       162\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      6480\n",
      "   macro avg       0.45      0.38      0.40      6480\n",
      "weighted avg       0.52      0.52      0.51      6480\n",
      "\n",
      "accuracy:  0.5160493827160494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.37      0.41      0.39      2112\n",
      "    priority       0.60      0.63      0.62      2175\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.57      0.49      0.53      2026\n",
      "   not_recom       0.61      0.30      0.40       166\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.43      0.37      0.39      6480\n",
      "weighted avg       0.52      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.5087962962962963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.39      0.42      0.40      2161\n",
      "    priority       0.59      0.65      0.62      2095\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.57      0.49      0.53      2056\n",
      "   not_recom       0.64      0.28      0.38       167\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.44      0.37      0.39      6480\n",
      "weighted avg       0.52      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.5121913580246914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.37      0.38      0.38      2158\n",
      "    priority       0.60      0.65      0.63      2171\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.55      0.50      0.52      1989\n",
      "   not_recom       0.67      0.32      0.44       161\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.44      0.37      0.39      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.509104938271605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.37      0.38      0.38      2131\n",
      "    priority       0.60      0.66      0.63      2149\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.55      0.49      0.52      2040\n",
      "   not_recom       0.64      0.35      0.45       159\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.43      0.38      0.40      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.5075617283950618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.37      0.37      0.37      2188\n",
      "    priority       0.59      0.65      0.62      2117\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.54      0.50      0.52      2005\n",
      "   not_recom       0.67      0.30      0.42       169\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      6480\n",
      "   macro avg       0.43      0.37      0.39      6480\n",
      "weighted avg       0.50      0.50      0.50      6480\n",
      "\n",
      "accuracy:  0.5023148148148148\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            #print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.49      0.46      2186\n",
      "    priority       0.62      0.66      0.64      2095\n",
      "  spec_prior       0.59      0.48      0.53      2033\n",
      "   not_recom       0.85      0.27      0.40       166\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.62      0.48      0.51      6480\n",
      "weighted avg       0.55      0.54      0.54      6480\n",
      "\n",
      "accuracy:  0.538425925925926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.54      0.48      2133\n",
      "    priority       0.65      0.61      0.63      2171\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.51      0.55      2012\n",
      "   not_recom       0.75      0.27      0.39       162\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.49      0.38      0.41      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5458333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.55      0.48      2117\n",
      "    priority       0.65      0.63      0.64      2128\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.48      0.54      2075\n",
      "   not_recom       0.80      0.31      0.45       159\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.50      0.39      0.42      6480\n",
      "weighted avg       0.57      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5472222222222223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.46      0.45      2202\n",
      "    priority       0.62      0.64      0.63      2138\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.56      0.53      0.55      1970\n",
      "   not_recom       0.74      0.23      0.35       169\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      6480\n",
      "   macro avg       0.47      0.37      0.39      6480\n",
      "weighted avg       0.54      0.53      0.53      6480\n",
      "\n",
      "accuracy:  0.5348765432098765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.56      0.48      2118\n",
      "    priority       0.64      0.63      0.64      2103\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.47      0.53      2094\n",
      "   not_recom       0.83      0.28      0.41       163\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.50      0.39      0.41      6480\n",
      "weighted avg       0.56      0.54      0.55      6480\n",
      "\n",
      "accuracy:  0.5438271604938272\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.49      0.46      2201\n",
      "    priority       0.65      0.63      0.64      2163\n",
      "  spec_prior       0.56      0.53      0.54      1951\n",
      "   not_recom       0.83      0.30      0.44       165\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.62      0.49      0.52      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5453703703703704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.52      0.47      2142\n",
      "    priority       0.63      0.65      0.64      2119\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.48      0.54      2052\n",
      "   not_recom       0.73      0.26      0.38       166\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.48      0.38      0.41      6480\n",
      "weighted avg       0.56      0.54      0.54      6480\n",
      "\n",
      "accuracy:  0.5438271604938272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.52      0.47      2177\n",
      "    priority       0.65      0.62      0.63      2147\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.52      0.55      1993\n",
      "   not_recom       0.78      0.30      0.44       162\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.49      0.39      0.42      6480\n",
      "weighted avg       0.56      0.54      0.55      6480\n",
      "\n",
      "accuracy:  0.5442901234567902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.42      0.56      0.48      2115\n",
      "    priority       0.64      0.62      0.63      2132\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.45      0.51      2052\n",
      "   not_recom       0.83      0.21      0.34       179\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      6480\n",
      "   macro avg       0.50      0.37      0.39      6480\n",
      "weighted avg       0.56      0.53      0.53      6480\n",
      "\n",
      "accuracy:  0.5345679012345679\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.48      0.45      2204\n",
      "    priority       0.64      0.64      0.64      2134\n",
      "  spec_prior       0.57      0.53      0.55      1993\n",
      "   not_recom       0.72      0.34      0.46       149\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.59      0.49      0.52      6480\n",
      "weighted avg       0.55      0.54      0.54      6480\n",
      "\n",
      "accuracy:  0.542746913580247\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.52      0.48      2155\n",
      "    priority       0.65      0.65      0.65      2148\n",
      "  spec_prior       0.61      0.53      0.57      2025\n",
      "   not_recom       0.73      0.26      0.39       152\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.61      0.49      0.52      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5628086419753087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.51      0.48      2164\n",
      "    priority       0.64      0.66      0.65      2118\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.54      0.57      2020\n",
      "   not_recom       0.83      0.11      0.19       176\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.50      0.37      0.38      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5601851851851852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.51      0.48      2140\n",
      "    priority       0.65      0.65      0.65      2151\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.55      0.57      2021\n",
      "   not_recom       0.79      0.20      0.33       166\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.50      0.38      0.41      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5628086419753087\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.50      0.47      2179\n",
      "    priority       0.63      0.66      0.65      2115\n",
      "  spec_prior       0.60      0.54      0.57      2024\n",
      "   not_recom       0.93      0.16      0.27       162\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.65      0.47      0.49      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5572530864197531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.48      0.46      2147\n",
      "    priority       0.62      0.68      0.65      2117\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.53      0.57      2039\n",
      "   not_recom       0.88      0.08      0.15       175\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.51      0.36      0.36      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5521604938271605\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.52      0.48      2172\n",
      "    priority       0.66      0.63      0.65      2149\n",
      "  spec_prior       0.59      0.54      0.56      2006\n",
      "   not_recom       0.83      0.16      0.26       153\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.63      0.46      0.49      6480\n",
      "weighted avg       0.57      0.55      0.56      6480\n",
      "\n",
      "accuracy:  0.5549382716049382\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.54      0.48      2148\n",
      "    priority       0.66      0.61      0.64      2136\n",
      "  spec_prior       0.59      0.53      0.56      2037\n",
      "   not_recom       0.84      0.19      0.32       159\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.63      0.47      0.50      6480\n",
      "weighted avg       0.57      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5518518518518518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.45      0.45      2171\n",
      "    priority       0.63      0.71      0.67      2130\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.58      0.56      0.57      2008\n",
      "   not_recom       0.71      0.13      0.22       169\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.48      0.37      0.38      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "accuracy:  0.5592592592592592\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.54      0.49      2151\n",
      "    priority       0.66      0.67      0.67      2149\n",
      "  spec_prior       0.60      0.52      0.56      2012\n",
      "   not_recom       0.81      0.20      0.32       168\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.63      0.48      0.51      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n",
      "accuracy:  0.5677469135802469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.48      0.46      2168\n",
      "    priority       0.64      0.66      0.65      2117\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.56      0.57      2033\n",
      "   not_recom       0.72      0.11      0.19       160\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.48      0.36      0.38      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5547839506172839\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=15, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.51      0.47      2123\n",
      "    priority       0.66      0.64      0.65      2145\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.56      0.58      2045\n",
      "   not_recom       0.90      0.23      0.37       165\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.52      0.39      0.41      6480\n",
      "weighted avg       0.58      0.56      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.44      0.44      2197\n",
      "    priority       0.63      0.69      0.66      2121\n",
      "  spec_prior       0.58      0.55      0.57      1999\n",
      "   not_recom       0.86      0.19      0.31       163\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.63      0.47      0.49      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.51      0.47      2120\n",
      "    priority       0.65      0.63      0.64      2151\n",
      "  spec_prior       0.59      0.53      0.56      2048\n",
      "   not_recom       0.79      0.19      0.30       161\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.61      0.46      0.49      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.43      0.44      2200\n",
      "    priority       0.63      0.68      0.65      2115\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.57      0.58      0.57      1996\n",
      "   not_recom       0.83      0.18      0.30       167\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.50      0.37      0.39      6480\n",
      "weighted avg       0.55      0.55      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.46      0.45      2177\n",
      "    priority       0.63      0.67      0.65      2077\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.55      0.57      2075\n",
      "   not_recom       0.87      0.18      0.30       150\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.50      0.37      0.39      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.49      0.46      2143\n",
      "    priority       0.66      0.62      0.64      2189\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.57      0.56      0.56      1969\n",
      "   not_recom       0.80      0.24      0.37       178\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.49      0.38      0.41      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.47      0.46      2159\n",
      "    priority       0.64      0.68      0.66      2121\n",
      "  spec_prior       0.58      0.55      0.56      2019\n",
      "   not_recom       0.89      0.17      0.29       181\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.64      0.47      0.49      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.50      0.47      2161\n",
      "    priority       0.66      0.65      0.65      2145\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.55      0.57      2025\n",
      "   not_recom       0.77      0.28      0.41       147\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.49      0.40      0.42      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.45      0.45      2181\n",
      "    priority       0.63      0.69      0.66      2104\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.56      0.57      2020\n",
      "   not_recom       0.87      0.16      0.26       174\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.51      0.37      0.39      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.50      0.46      2139\n",
      "    priority       0.65      0.65      0.65      2162\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.54      0.56      2024\n",
      "   not_recom       0.74      0.23      0.35       154\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.48      0.38      0.41      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=20, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.43      0.45      2207\n",
      "    priority       0.62      0.70      0.66      2128\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.60      0.59      1969\n",
      "   not_recom       0.93      0.07      0.14       175\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.52      0.36      0.37      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "accuracy:  0.5609567901234568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.50      0.47      2112\n",
      "    priority       0.65      0.67      0.66      2138\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.62      0.55      0.59      2076\n",
      "   not_recom       0.92      0.16      0.27       153\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.53      0.38      0.40      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n",
      "accuracy:  0.5679012345679012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.47      0.46      2148\n",
      "    priority       0.65      0.69      0.67      2148\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.59      0.59      2019\n",
      "   not_recom       1.00      0.11      0.20       163\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.37      0.38      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.567283950617284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.45      0.45      2171\n",
      "    priority       0.63      0.69      0.66      2118\n",
      "  spec_prior       0.60      0.58      0.59      2026\n",
      "   not_recom       0.91      0.12      0.21       165\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.65      0.46      0.48      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5608024691358025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.47      0.46      2154\n",
      "    priority       0.65      0.70      0.67      2135\n",
      "  spec_prior       0.60      0.57      0.58      2032\n",
      "   not_recom       0.96      0.14      0.25       159\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.67      0.47      0.49      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n",
      "accuracy:  0.5702160493827161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.47      0.46      2165\n",
      "    priority       0.64      0.68      0.66      2131\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.59      0.59      2013\n",
      "   not_recom       0.90      0.11      0.19       169\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.52      0.37      0.38      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5645061728395062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.47      0.46      2154\n",
      "    priority       0.63      0.75      0.68      2067\n",
      "  spec_prior       0.63      0.54      0.58      2103\n",
      "   not_recom       0.69      0.12      0.20       156\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.60      0.47      0.48      6480\n",
      "weighted avg       0.57      0.57      0.57      6480\n",
      "\n",
      "accuracy:  0.5722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.47      0.47      2165\n",
      "    priority       0.66      0.66      0.66      2199\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.57      0.62      0.59      1942\n",
      "   not_recom       0.92      0.06      0.12       172\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.52      0.36      0.37      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5683641975308642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.42      0.44      2185\n",
      "    priority       0.64      0.69      0.67      2123\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.63      0.61      2021\n",
      "   not_recom       0.84      0.14      0.24       150\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.51      0.38      0.39      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5675925925925925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.48      0.47      2134\n",
      "    priority       0.65      0.71      0.68      2143\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.58      0.60      2024\n",
      "   not_recom       1.00      0.08      0.16       178\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.37      0.38      6480\n",
      "weighted avg       0.59      0.57      0.57      6480\n",
      "\n",
      "accuracy:  0.575\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=30, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.45      0.45      2178\n",
      "    priority       0.63      0.70      0.66      2118\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.59      0.60      1999\n",
      "   not_recom       0.71      0.03      0.05       183\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.48      0.35      0.35      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "accuracy:  0.5638888888888889\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.48      0.47      2141\n",
      "    priority       0.66      0.68      0.67      2148\n",
      "  spec_prior       0.60      0.59      0.60      2046\n",
      "   not_recom       1.00      0.14      0.25       145\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.68      0.47      0.50      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n",
      "accuracy:  0.5725308641975309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.44      0.44      2184\n",
      "    priority       0.63      0.70      0.66      2091\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.58      0.59      2044\n",
      "   not_recom       0.94      0.09      0.17       160\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.52      0.36      0.37      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "accuracy:  0.5580246913580247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.45      0.44      2135\n",
      "    priority       0.64      0.69      0.66      2175\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.57      0.58      2001\n",
      "   not_recom       0.88      0.14      0.24       168\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.51      0.37      0.39      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5591049382716049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.48      0.47      2165\n",
      "    priority       0.65      0.69      0.67      2129\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.57      0.58      2030\n",
      "   not_recom       0.93      0.08      0.15       154\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.53      0.36      0.37      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5674382716049383\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.46      0.46      2154\n",
      "    priority       0.65      0.69      0.67      2137\n",
      "  spec_prior       0.59      0.60      0.60      2015\n",
      "   not_recom       0.92      0.13      0.22       174\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.65      0.47      0.49      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5685185185185185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.44      0.45      2183\n",
      "    priority       0.65      0.72      0.68      2146\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.61      0.60      1992\n",
      "   not_recom       0.93      0.17      0.29       157\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.53      0.39      0.40      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "accuracy:  0.5760802469135803\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.52      0.48      2136\n",
      "    priority       0.66      0.66      0.66      2120\n",
      "  spec_prior       0.60      0.55      0.58      2053\n",
      "   not_recom       0.87      0.08      0.14       171\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.64      0.45      0.46      6480\n",
      "weighted avg       0.58      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5641975308641975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.47      0.46      2171\n",
      "    priority       0.62      0.68      0.65      2105\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.58      0.59      2025\n",
      "   not_recom       1.00      0.05      0.10       178\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.54      0.35      0.36      6480\n",
      "weighted avg       0.57      0.56      0.55      6480\n",
      "\n",
      "accuracy:  0.558641975308642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.47      0.47      2148\n",
      "    priority       0.67      0.68      0.67      2161\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.60      0.60      2020\n",
      "   not_recom       0.88      0.19      0.31       150\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.52      0.39      0.41      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "accuracy:  0.575462962962963\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=30, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.35      0.41      2194\n",
      "    priority       0.62      0.76      0.68      2108\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.65      0.61      2020\n",
      "   not_recom       1.00      0.01      0.01       157\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.35      0.34      6480\n",
      "weighted avg       0.57      0.57      0.55      6480\n",
      "\n",
      "accuracy:  0.5702160493827161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.40      0.44      2125\n",
      "    priority       0.64      0.69      0.66      2158\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.71      0.65      2025\n",
      "   not_recom       0.00      0.00      0.00       171\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.56      0.58      0.57      6480\n",
      "\n",
      "accuracy:  0.5811728395061728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.37      0.41      2150\n",
      "    priority       0.63      0.74      0.68      2107\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.69      0.64      2064\n",
      "   not_recom       1.00      0.01      0.01       158\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.54      0.36      0.35      6480\n",
      "weighted avg       0.58      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.5796296296296296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.37      0.42      2169\n",
      "    priority       0.62      0.71      0.66      2159\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.67      0.62      1981\n",
      "   not_recom       1.00      0.01      0.01       170\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.53      0.35      0.34      6480\n",
      "weighted avg       0.57      0.57      0.55      6480\n",
      "\n",
      "accuracy:  0.566358024691358\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.41      0.44      2153\n",
      "    priority       0.66      0.69      0.67      2166\n",
      "  spec_prior       0.59      0.69      0.64      2012\n",
      "   not_recom       1.00      0.01      0.01       149\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.68      0.45      0.44      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "accuracy:  0.5807098765432098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.36      0.42      2166\n",
      "    priority       0.61      0.74      0.67      2100\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.68      0.64      2033\n",
      "   not_recom       0.00      0.00      0.00       179\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.34      0.36      0.34      6480\n",
      "weighted avg       0.55      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5745370370370371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.40      0.43      2122\n",
      "    priority       0.64      0.73      0.68      2166\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.61      0.66      0.63      2034\n",
      "   not_recom       0.00      0.00      0.00       156\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.56      0.58      0.57      6480\n",
      "\n",
      "accuracy:  0.5825617283950617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.35      0.41      2197\n",
      "    priority       0.62      0.73      0.67      2100\n",
      "  spec_prior       0.57      0.69      0.63      2011\n",
      "   not_recom       0.00      0.00      0.00       172\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.42      0.44      0.43      6480\n",
      "weighted avg       0.54      0.57      0.55      6480\n",
      "\n",
      "accuracy:  0.5703703703703704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.40      0.43      2139\n",
      "    priority       0.63      0.70      0.66      2132\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.67      0.63      2044\n",
      "   not_recom       0.00      0.00      0.00       163\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.34      0.35      0.34      6480\n",
      "weighted avg       0.55      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5717592592592593\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.37      0.42      2180\n",
      "    priority       0.63      0.74      0.68      2134\n",
      "  spec_prior       0.60      0.70      0.64      2001\n",
      "   not_recom       1.00      0.01      0.01       165\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.68      0.45      0.44      6480\n",
      "weighted avg       0.58      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.5828703703703704\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.44      0.45      2143\n",
      "    priority       0.64      0.68      0.66      2159\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.65      0.62      2008\n",
      "   not_recom       1.00      0.02      0.05       168\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.36      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.571141975308642\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.43      0.45      2176\n",
      "    priority       0.64      0.72      0.68      2107\n",
      "  spec_prior       0.60      0.62      0.61      2037\n",
      "   not_recom       1.00      0.04      0.08       160\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.68      0.45      0.45      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5726851851851852\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.46      0.47      2160\n",
      "    priority       0.66      0.68      0.67      2153\n",
      "  spec_prior       0.60      0.64      0.62      2006\n",
      "   not_recom       1.00      0.06      0.12       161\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.68      0.46      0.47      6480\n",
      "weighted avg       0.59      0.58      0.57      6480\n",
      "\n",
      "accuracy:  0.578858024691358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.39      0.43      2159\n",
      "    priority       0.63      0.74      0.68      2113\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.63      0.61      2039\n",
      "   not_recom       0.80      0.02      0.05       167\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.50      0.36      0.35      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.570679012345679\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.41      0.44      2189\n",
      "    priority       0.65      0.69      0.67      2133\n",
      "  spec_prior       0.58      0.67      0.62      1992\n",
      "   not_recom       1.00      0.03      0.06       166\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.67      0.45      0.45      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.571604938271605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.44      0.45      2130\n",
      "    priority       0.63      0.72      0.67      2133\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.61      0.59      0.60      2053\n",
      "   not_recom       0.91      0.06      0.12       162\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.52      0.36      0.37      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.571141975308642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.42      0.45      2184\n",
      "    priority       0.62      0.71      0.66      2069\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.63      0.62      2063\n",
      "   not_recom       1.00      0.04      0.07       163\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.36      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.571604938271605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.44      0.45      2135\n",
      "    priority       0.66      0.68      0.67      2197\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.66      0.62      1982\n",
      "   not_recom       0.50      0.01      0.01       165\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.44      0.36      0.35      6480\n",
      "weighted avg       0.57      0.58      0.57      6480\n",
      "\n",
      "accuracy:  0.5765432098765432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.44      0.45      2130\n",
      "    priority       0.65      0.70      0.67      2147\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.63      0.61      2043\n",
      "   not_recom       0.82      0.06      0.11       158\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.51      0.36      0.37      6480\n",
      "weighted avg       0.57      0.57      0.57      6480\n",
      "\n",
      "accuracy:  0.5736111111111111\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.41      0.44      2189\n",
      "    priority       0.63      0.72      0.67      2119\n",
      "  spec_prior       0.59      0.63      0.61      2002\n",
      "   not_recom       1.00      0.02      0.03       170\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.67      0.45      0.44      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5702160493827161\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=150, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minkowski metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.26      0.27      2139\n",
      "    priority       0.52      0.55      0.53      2149\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.47      0.47      2022\n",
      "   not_recom       0.34      0.32      0.33       169\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.32      0.32      0.32      6480\n",
      "weighted avg       0.42      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.4225308641975309\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.25      0.26      2180\n",
      "    priority       0.51      0.57      0.54      2117\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.46      0.46      2023\n",
      "   not_recom       0.39      0.45      0.41       159\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.33      0.34      0.33      6480\n",
      "weighted avg       0.41      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.4217592592592593\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.27      0.25      0.26      2138\n",
      "    priority       0.53      0.56      0.54      2182\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.46      0.46      2013\n",
      "   not_recom       0.33      0.49      0.39       146\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.32      0.35      0.33      6480\n",
      "weighted avg       0.42      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.42268518518518516\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.25      0.27      2181\n",
      "    priority       0.50      0.57      0.53      2084\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.47      0.47      2032\n",
      "   not_recom       0.43      0.36      0.39       182\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.34      0.33      0.33      6480\n",
      "weighted avg       0.42      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.42453703703703705\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.24      0.26      2196\n",
      "    priority       0.53      0.57      0.55      2148\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.45      0.47      0.46      1984\n",
      "   not_recom       0.35      0.47      0.40       151\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.32      0.35      0.33      6480\n",
      "weighted avg       0.42      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.4243827160493827\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.27      0.25      0.26      2123\n",
      "    priority       0.51      0.55      0.53      2118\n",
      "  spec_prior       0.25      1.00      0.40         1\n",
      "   recommend       0.46      0.45      0.46      2061\n",
      "   not_recom       0.34      0.38      0.36       177\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.37      0.53      0.40      6480\n",
      "weighted avg       0.41      0.42      0.41      6480\n",
      "\n",
      "accuracy:  0.4162037037037037\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.27      0.23      0.25      2181\n",
      "    priority       0.52      0.57      0.54      2138\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.47      0.46      1996\n",
      "   not_recom       0.33      0.43      0.37       164\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.32      0.34      0.33      6480\n",
      "weighted avg       0.41      0.42      0.41      6480\n",
      "\n",
      "accuracy:  0.42160493827160495\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.26      0.27      2138\n",
      "    priority       0.52      0.55      0.54      2128\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.46      0.46      2049\n",
      "   not_recom       0.41      0.52      0.46       164\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.33      0.36      0.34      6480\n",
      "weighted avg       0.42      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.4243827160493827\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.28      0.25      0.27      2163\n",
      "    priority       0.51      0.56      0.54      2141\n",
      "  spec_prior       0.25      1.00      0.40         1\n",
      "   recommend       0.46      0.47      0.46      2005\n",
      "   not_recom       0.36      0.45      0.40       170\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.37      0.54      0.41      6480\n",
      "weighted avg       0.42      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.42453703703703705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.27      0.25      0.26      2156\n",
      "    priority       0.52      0.55      0.53      2125\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.47      0.47      2040\n",
      "   not_recom       0.32      0.35      0.33       158\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.31      0.32      0.32      6480\n",
      "weighted avg       0.41      0.42      0.42      6480\n",
      "\n",
      "accuracy:  0.4195987654320988\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=1, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.40      0.39      2162\n",
      "    priority       0.60      0.64      0.62      2140\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.55      0.51      0.53      2013\n",
      "   not_recom       0.63      0.28      0.39       164\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.43      0.37      0.38      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.508641975308642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.37      0.40      0.39      2157\n",
      "    priority       0.59      0.63      0.61      2126\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.54      0.49      0.51      2032\n",
      "   not_recom       0.62      0.29      0.39       164\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      6480\n",
      "   macro avg       0.42      0.36      0.38      6480\n",
      "weighted avg       0.50      0.50      0.50      6480\n",
      "\n",
      "accuracy:  0.49907407407407406\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.39      0.43      0.41      2172\n",
      "    priority       0.60      0.63      0.62      2128\n",
      "  spec_prior       0.56      0.51      0.53      2006\n",
      "   not_recom       0.70      0.26      0.38       174\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      6480\n",
      "   macro avg       0.56      0.46      0.49      6480\n",
      "weighted avg       0.52      0.52      0.52      6480\n",
      "\n",
      "accuracy:  0.5151234567901235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.41      0.40      2147\n",
      "    priority       0.59      0.66      0.62      2138\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.56      0.47      0.51      2039\n",
      "   not_recom       0.59      0.35      0.44       154\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.43      0.38      0.39      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.508641975308642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.40      0.39      2166\n",
      "    priority       0.59      0.65      0.62      2124\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.56      0.49      0.52      2020\n",
      "   not_recom       0.72      0.27      0.39       169\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.45      0.36      0.38      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.5066358024691358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.39      0.39      2153\n",
      "    priority       0.60      0.63      0.62      2142\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.55      0.51      0.53      2025\n",
      "   not_recom       0.61      0.36      0.46       159\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.43      0.38      0.40      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.5103395061728395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.42      0.40      2144\n",
      "    priority       0.62      0.63      0.62      2193\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.56      0.51      0.53      1985\n",
      "   not_recom       0.68      0.32      0.44       157\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.45      0.38      0.40      6480\n",
      "weighted avg       0.52      0.51      0.52      6480\n",
      "\n",
      "accuracy:  0.5149691358024692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.39      0.40      0.39      2175\n",
      "    priority       0.58      0.67      0.62      2073\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.57      0.48      0.52      2060\n",
      "   not_recom       0.70      0.33      0.45       171\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.45      0.38      0.40      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.5103395061728395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.39      0.39      2170\n",
      "    priority       0.59      0.66      0.63      2141\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.56      0.49      0.52      2015\n",
      "   not_recom       0.63      0.39      0.48       152\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.43      0.39      0.40      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "accuracy:  0.5111111111111111\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.37      0.39      0.38      2149\n",
      "    priority       0.59      0.64      0.62      2125\n",
      "  spec_prior       0.56      0.51      0.53      2030\n",
      "   not_recom       0.69      0.19      0.30       176\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.55      0.44      0.46      6480\n",
      "weighted avg       0.51      0.51      0.50      6480\n",
      "\n",
      "accuracy:  0.5064814814814815\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.39      0.35      2156\n",
      "    priority       0.58      0.52      0.55      2167\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.45      0.42      0.43      1998\n",
      "   not_recom       0.54      0.31      0.39       158\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.38      0.33      0.35      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.34      2164\n",
      "    priority       0.55      0.55      0.55      2099\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.40      0.43      2046\n",
      "   not_recom       0.49      0.29      0.36       170\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.37      0.32      0.34      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.40      0.36      2160\n",
      "    priority       0.57      0.51      0.54      2159\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.41      0.43      2020\n",
      "   not_recom       0.42      0.29      0.34       140\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.36      0.32      0.34      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.41      0.37      2160\n",
      "    priority       0.55      0.53      0.54      2107\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.39      0.43      2024\n",
      "   not_recom       0.57      0.27      0.37       188\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.38      0.32      0.34      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.39      0.35      2158\n",
      "    priority       0.56      0.53      0.55      2130\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.47      0.43      0.45      2028\n",
      "   not_recom       0.51      0.25      0.33       162\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.37      0.32      0.34      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.39      0.35      2162\n",
      "    priority       0.56      0.54      0.55      2136\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.46      0.40      0.43      2016\n",
      "   not_recom       0.55      0.31      0.40       166\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.38      0.33      0.35      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.39      0.36      2155\n",
      "    priority       0.57      0.53      0.55      2176\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.44      0.45      1970\n",
      "   not_recom       0.44      0.23      0.30       178\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.36      0.32      0.33      6480\n",
      "weighted avg       0.46      0.44      0.45      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.34      0.42      0.37      2165\n",
      "    priority       0.56      0.52      0.54      2090\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.49      0.40      0.44      2074\n",
      "   not_recom       0.53      0.32      0.40       150\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.38      0.33      0.35      6480\n",
      "weighted avg       0.46      0.44      0.45      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.39      0.36      2158\n",
      "    priority       0.57      0.55      0.56      2107\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.48      0.42      0.45      2033\n",
      "   not_recom       0.57      0.24      0.34       181\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      6480\n",
      "   macro avg       0.39      0.32      0.34      6480\n",
      "weighted avg       0.46      0.45      0.45      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.41      0.37      2162\n",
      "    priority       0.58      0.53      0.56      2159\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.40      0.43      2011\n",
      "   not_recom       0.50      0.38      0.43       147\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      6480\n",
      "   macro avg       0.38      0.35      0.36      6480\n",
      "weighted avg       0.46      0.45      0.45      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.46      0.45      2116\n",
      "    priority       0.66      0.65      0.66      2188\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.58      0.58      0.58      2014\n",
      "   not_recom       0.76      0.26      0.39       160\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.49      0.39      0.41      6480\n",
      "weighted avg       0.56      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5575617283950617\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.44      0.44      2203\n",
      "    priority       0.61      0.68      0.65      2078\n",
      "  spec_prior       0.59      0.55      0.57      2031\n",
      "   not_recom       0.83      0.14      0.24       168\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.62      0.46      0.48      6480\n",
      "weighted avg       0.55      0.55      0.54      6480\n",
      "\n",
      "accuracy:  0.5472222222222223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.44      0.43      2177\n",
      "    priority       0.62      0.69      0.66      2065\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.54      0.56      2076\n",
      "   not_recom       0.83      0.24      0.38       161\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.49      0.38      0.41      6480\n",
      "weighted avg       0.55      0.55      0.54      6480\n",
      "\n",
      "accuracy:  0.5469135802469136\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.47      0.45      2142\n",
      "    priority       0.66      0.64      0.65      2201\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.57      0.56      0.56      1969\n",
      "   not_recom       0.84      0.22      0.34       167\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.50      0.38      0.40      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5481481481481482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.44      0.44      2199\n",
      "    priority       0.64      0.68      0.66      2160\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.57      0.56      0.57      1962\n",
      "   not_recom       0.87      0.26      0.40       157\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.51      0.39      0.41      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5547839506172839\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.48      0.45      2120\n",
      "    priority       0.64      0.64      0.64      2106\n",
      "  spec_prior       0.58      0.55      0.56      2083\n",
      "   not_recom       0.82      0.13      0.23       171\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.62      0.45      0.47      6480\n",
      "weighted avg       0.56      0.55      0.54      6480\n",
      "\n",
      "accuracy:  0.5458333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.44      0.44      2148\n",
      "    priority       0.64      0.68      0.66      2148\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.57      0.57      0.57      2009\n",
      "   not_recom       0.82      0.13      0.23       174\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.49      0.36      0.38      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5501543209876543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.46      0.45      2171\n",
      "    priority       0.64      0.66      0.65      2118\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.55      0.57      2036\n",
      "   not_recom       0.89      0.26      0.40       154\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.51      0.39      0.41      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5498456790123457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.46      0.45      2158\n",
      "    priority       0.64      0.67      0.66      2120\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.54      0.56      2051\n",
      "   not_recom       0.76      0.32      0.45       150\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.49      0.40      0.42      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.553395061728395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.47      0.46      2161\n",
      "    priority       0.65      0.68      0.66      2146\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.57      0.58      1994\n",
      "   not_recom       0.89      0.17      0.29       178\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.51      0.38      0.40      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5603395061728395\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=15, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.50      0.47      2152\n",
      "    priority       0.64      0.69      0.66      2137\n",
      "  spec_prior       0.60      0.51      0.55      2026\n",
      "   not_recom       0.91      0.19      0.31       165\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.65      0.47      0.50      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.558179012345679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.51      0.48      2167\n",
      "    priority       0.66      0.64      0.65      2129\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.55      0.57      2019\n",
      "   not_recom       0.90      0.17      0.28       163\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.52      0.37      0.40      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5584876543209877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.50      0.47      2152\n",
      "    priority       0.64      0.64      0.64      2145\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.54      0.56      2026\n",
      "   not_recom       0.85      0.26      0.39       156\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.50      0.39      0.41      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5524691358024691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.48      0.46      2167\n",
      "    priority       0.64      0.65      0.64      2121\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.56      0.57      2019\n",
      "   not_recom       0.88      0.13      0.22       172\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.51      0.36      0.38      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5506172839506173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.50      0.48      2167\n",
      "    priority       0.65      0.67      0.66      2138\n",
      "  spec_prior       0.59      0.55      0.57      2010\n",
      "   not_recom       0.84      0.16      0.27       165\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.63      0.47      0.49      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.562962962962963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.52      0.48      2152\n",
      "    priority       0.64      0.65      0.65      2128\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.61      0.53      0.57      2035\n",
      "   not_recom       0.82      0.20      0.32       163\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.50      0.38      0.40      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5583333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.53      0.49      2122\n",
      "    priority       0.65      0.63      0.64      2142\n",
      "  spec_prior       0.61      0.54      0.57      2047\n",
      "   not_recom       0.86      0.18      0.29       169\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.64      0.47      0.50      6480\n",
      "weighted avg       0.58      0.56      0.56      6480\n",
      "\n",
      "accuracy:  0.5609567901234568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.46      0.45      2197\n",
      "    priority       0.63      0.67      0.65      2124\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.58      0.56      0.57      1998\n",
      "   not_recom       0.81      0.19      0.31       159\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.49      0.38      0.40      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5529320987654321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.47      0.46      2182\n",
      "    priority       0.63      0.69      0.66      2130\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.54      0.57      2003\n",
      "   not_recom       0.69      0.22      0.33       164\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.47      0.38      0.40      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "accuracy:  0.5569444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.51      0.47      2137\n",
      "    priority       0.65      0.64      0.64      2136\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.55      0.57      2042\n",
      "   not_recom       0.95      0.12      0.22       164\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.53      0.36      0.38      6480\n",
      "weighted avg       0.57      0.55      0.55      6480\n",
      "\n",
      "accuracy:  0.5537037037037037\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=20, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.35      0.33      2164\n",
      "    priority       0.55      0.55      0.55      2133\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.46      0.44      0.45      2018\n",
      "   not_recom       0.05      0.01      0.02       163\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.28      0.27      0.27      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "4\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.34      2156\n",
      "    priority       0.54      0.51      0.53      2133\n",
      "  spec_prior       0.46      0.43      0.45      2026\n",
      "   not_recom       0.05      0.01      0.02       165\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.34      0.33      0.33      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "5\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.34      0.32      2162\n",
      "    priority       0.55      0.51      0.53      2140\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.45      0.46      0.46      2017\n",
      "   not_recom       0.00      0.00      0.00       161\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.26      0.26      0.26      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.34      0.32      2158\n",
      "    priority       0.53      0.54      0.54      2126\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.46      0.44      0.45      2027\n",
      "   not_recom       0.02      0.01      0.01       167\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.27      0.27      0.26      6480\n",
      "weighted avg       0.42      0.43      0.43      6480\n",
      "\n",
      "5\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.35      0.33      2117\n",
      "    priority       0.56      0.53      0.54      2190\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.46      0.45      0.46      2019\n",
      "   not_recom       0.05      0.01      0.02       154\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.28      0.27      0.27      6480\n",
      "weighted avg       0.44      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.33      0.32      2203\n",
      "    priority       0.53      0.53      0.53      2076\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.45      0.45      0.45      2025\n",
      "   not_recom       0.03      0.01      0.01       174\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.26      0.26      0.26      6480\n",
      "weighted avg       0.42      0.42      0.42      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.35      0.33      2160\n",
      "    priority       0.56      0.52      0.54      2169\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.45      0.45      0.45      1981\n",
      "   not_recom       0.00      0.00      0.00       169\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.26      0.26      0.26      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.34      0.32      2160\n",
      "    priority       0.55      0.55      0.55      2097\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.44      0.45      2063\n",
      "   not_recom       0.06      0.01      0.02       159\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.27      0.27      0.27      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "5\n",
      "5\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.36      0.33      2119\n",
      "    priority       0.56      0.50      0.53      2185\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.46      0.46      2016\n",
      "   not_recom       0.04      0.01      0.02       159\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.27      0.27      0.27      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.33      0.32      2201\n",
      "    priority       0.52      0.54      0.53      2081\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.45      0.45      2028\n",
      "   not_recom       0.00      0.00      0.00       169\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.26      0.26      0.26      6480\n",
      "weighted avg       0.42      0.43      0.42      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=30, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.40      0.43      2192\n",
      "    priority       0.64      0.70      0.67      2177\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.57      0.64      0.60      1944\n",
      "   not_recom       0.89      0.05      0.09       165\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.51      0.36      0.36      6480\n",
      "weighted avg       0.57      0.57      0.55      6480\n",
      "\n",
      "accuracy:  0.5660493827160494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.44      0.45      2127\n",
      "    priority       0.63      0.72      0.67      2089\n",
      "  spec_prior       0.62      0.60      0.61      2101\n",
      "   not_recom       1.00      0.04      0.07       163\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.68      0.45      0.45      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.46      0.46      2142\n",
      "    priority       0.66      0.69      0.68      2177\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.62      0.61      2003\n",
      "   not_recom       0.80      0.05      0.10       157\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.50      0.36      0.37      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "accuracy:  0.5770061728395062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.41      0.44      2177\n",
      "    priority       0.63      0.73      0.68      2089\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.66      0.63      2042\n",
      "   not_recom       0.50      0.01      0.01       171\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.44      0.36      0.35      6480\n",
      "weighted avg       0.57      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.578395061728395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.41      0.44      2169\n",
      "    priority       0.64      0.70      0.67      2134\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.67      0.62      2019\n",
      "   not_recom       0.83      0.03      0.06       157\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.51      0.36      0.36      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "accuracy:  0.5771604938271605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.45      0.45      2150\n",
      "    priority       0.63      0.70      0.67      2132\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.59      0.60      2026\n",
      "   not_recom       1.00      0.05      0.09       171\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.36      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5671296296296297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.39      0.43      2201\n",
      "    priority       0.64      0.71      0.67      2140\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.67      0.62      1984\n",
      "   not_recom       0.72      0.08      0.15       154\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.48      0.37      0.37      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5729938271604939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.50      0.48      2118\n",
      "    priority       0.63      0.68      0.65      2126\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.58      0.59      2061\n",
      "   not_recom       1.00      0.01      0.02       174\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.35      0.35      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5679012345679012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.45      0.46      2140\n",
      "    priority       0.64      0.69      0.67      2154\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.62      0.62      2023\n",
      "   not_recom       0.89      0.05      0.09       162\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.52      0.36      0.37      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n",
      "accuracy:  0.5739197530864197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.40      0.43      2179\n",
      "    priority       0.62      0.71      0.67      2112\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.63      0.60      2022\n",
      "   not_recom       0.83      0.03      0.06       166\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.50      0.35      0.35      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "accuracy:  0.5632716049382716\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=50, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.37      0.42      2194\n",
      "    priority       0.63      0.71      0.66      2146\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.58      0.70      0.63      1974\n",
      "   not_recom       0.00      0.00      0.00       164\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.34      0.35      0.34      6480\n",
      "weighted avg       0.55      0.57      0.55      6480\n",
      "\n",
      "accuracy:  0.5719135802469136\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.37      0.42      2125\n",
      "    priority       0.63      0.74      0.68      2120\n",
      "  spec_prior       0.60      0.67      0.64      2071\n",
      "   not_recom       1.00      0.01      0.01       164\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.68      0.45      0.44      6480\n",
      "weighted avg       0.58      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.5790123456790124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.30      0.37      2216\n",
      "    priority       0.62      0.74      0.67      2166\n",
      "  spec_prior       0.57      0.73      0.64      1950\n",
      "   not_recom       1.00      0.01      0.01       148\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.67      0.45      0.42      6480\n",
      "weighted avg       0.57      0.57      0.55      6480\n",
      "\n",
      "accuracy:  0.5709876543209876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.43      0.45      2103\n",
      "    priority       0.63      0.71      0.67      2100\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.61      0.64      0.63      2095\n",
      "   not_recom       0.00      0.00      0.00       180\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.5763888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.37      0.42      2168\n",
      "    priority       0.62      0.73      0.67      2127\n",
      "  spec_prior       0.59      0.67      0.63      2030\n",
      "   not_recom       1.00      0.01      0.01       155\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.67      0.44      0.43      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "accuracy:  0.5726851851851852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.38      0.43      2151\n",
      "    priority       0.63      0.73      0.68      2139\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.68      0.64      2015\n",
      "   not_recom       0.00      0.00      0.00       173\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.578858024691358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.38      0.42      2154\n",
      "    priority       0.65      0.71      0.67      2175\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.70      0.63      1990\n",
      "   not_recom       0.00      0.00      0.00       160\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.5762345679012346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.39      0.43      2165\n",
      "    priority       0.61      0.76      0.68      2091\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.64      0.62      2055\n",
      "   not_recom       1.00      0.01      0.02       168\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.54      0.36      0.35      6480\n",
      "weighted avg       0.58      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.5793209876543209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.35      0.40      2195\n",
      "    priority       0.62      0.73      0.67      2107\n",
      "  spec_prior       0.58      0.70      0.64      2014\n",
      "   not_recom       0.00      0.00      0.00       164\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.42      0.45      0.43      6480\n",
      "weighted avg       0.55      0.57      0.55      6480\n",
      "\n",
      "accuracy:  0.5737654320987654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.43      0.46      2124\n",
      "    priority       0.63      0.70      0.66      2159\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.61      0.66      0.63      2031\n",
      "   not_recom       0.75      0.02      0.04       164\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.50      0.36      0.36      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "accuracy:  0.5816358024691358\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.50      0.29      0.37      2178\n",
      "    priority       0.60      0.79      0.68      2143\n",
      "  spec_prior       0.58      0.70      0.64      1991\n",
      "   not_recom       0.00      0.00      0.00       168\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.42      0.45      0.42      6480\n",
      "weighted avg       0.55      0.58      0.55      6480\n",
      "\n",
      "accuracy:  0.575462962962963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.35      0.40      2141\n",
      "    priority       0.63      0.73      0.67      2123\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.72      0.65      2054\n",
      "   not_recom       0.00      0.00      0.00       160\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.5810185185185185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.34      0.40      2162\n",
      "    priority       0.63      0.73      0.68      2181\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.72      0.64      1970\n",
      "   not_recom       0.00      0.00      0.00       166\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.34      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.5794753086419753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.31      0.38      2157\n",
      "    priority       0.60      0.78      0.68      2085\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.70      0.65      2075\n",
      "   not_recom       0.00      0.00      0.00       162\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.34      6480\n",
      "weighted avg       0.55      0.58      0.55      6480\n",
      "\n",
      "accuracy:  0.5760802469135803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.29      0.36      2171\n",
      "    priority       0.60      0.78      0.68      2116\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.58      0.71      0.64      2014\n",
      "   not_recom       0.00      0.00      0.00       177\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.33      0.35      0.34      6480\n",
      "weighted avg       0.54      0.57      0.54      6480\n",
      "\n",
      "accuracy:  0.5700617283950618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.35      0.41      2148\n",
      "    priority       0.63      0.72      0.67      2150\n",
      "  spec_prior       0.59      0.72      0.65      2031\n",
      "   not_recom       0.00      0.00      0.00       151\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.43      0.45      0.43      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.5793209876543209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.35      0.40      2091\n",
      "    priority       0.62      0.77      0.68      2129\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.67      0.64      2080\n",
      "   not_recom       0.00      0.00      0.00       179\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.34      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.5800925925925926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.28      0.35      2228\n",
      "    priority       0.61      0.75      0.67      2137\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.57      0.73      0.64      1965\n",
      "   not_recom       0.00      0.00      0.00       149\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.33      0.35      0.33      6480\n",
      "weighted avg       0.54      0.57      0.54      6480\n",
      "\n",
      "accuracy:  0.5669753086419753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.31      0.38      2164\n",
      "    priority       0.61      0.75      0.67      2139\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.71      0.63      2014\n",
      "   not_recom       0.00      0.00      0.00       162\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.33      0.35      0.34      6480\n",
      "weighted avg       0.54      0.57      0.54      6480\n",
      "\n",
      "accuracy:  0.5695987654320988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.50      0.32      0.39      2155\n",
      "    priority       0.62      0.76      0.68      2127\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.72      0.65      2031\n",
      "   not_recom       0.00      0.00      0.00       166\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.34      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "accuracy:  0.5830246913580247\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=150, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
