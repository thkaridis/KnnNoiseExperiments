{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Parents', ' Has_nurs', ' Form', ' Children', ' Housing',\n",
       "       ' Finance', ' Social', ' Health', 'Class'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nurseryNum = pd.read_csv(\"nursery_numerical.csv\")\n",
    "nurseryNum.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "j = 1\n",
    "features = ['Parents', ' Has_nurs', ' Form', ' Children', ' Housing', ' Finance', ' Social', ' Health']\n",
    "for index, m in nurseryNum.iterrows():\n",
    "    if index % 20 == 0:\n",
    "        nurseryNum.at[index+2, features[j]] = i + 1\n",
    "        j += 3\n",
    "        i+=10\n",
    "        if j >= 7:\n",
    "            j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for index, m in nurseryNum.iterrows():\n",
    "    if index % 20 == 0:\n",
    "        if index < 12954:\n",
    "            nurseryNum.at[index+5,:] = nurseryNum.loc[j,:]\n",
    "        else:\n",
    "            nurseryNum.at[index+1,:] = nurseryNum.loc[j,:]\n",
    "        j += 120\n",
    "        if j >= 12959:\n",
    "            j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nurseryNum.to_csv('nureryNoise.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nurseryNum.iloc[:,0:8]\n",
    "labels = nurseryNum.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.values.astype(np.float32) #returns a numpy array\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)\n",
    "nurseryNum = pd.concat([df, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True) #5 fores me 2 folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean and k tuning on 10% noise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.82      0.85      0.83      2098\n",
      "   priority       0.77      0.82      0.79      2152\n",
      " spec_prior       0.33      1.00      0.50         2\n",
      "  recommend       0.87      0.76      0.81      2069\n",
      "  not_recom       0.55      0.67      0.60       159\n",
      "\n",
      "avg / total       0.81      0.81      0.81      6480\n",
      "\n",
      "accuracy:  0.8069444444444445\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.82      0.85      0.84      2175\n",
      "   priority       0.79      0.80      0.79      2115\n",
      " spec_prior       1.00      1.00      1.00         5\n",
      "  recommend       0.85      0.79      0.82      2017\n",
      "  not_recom       0.60      0.71      0.65       168\n",
      "\n",
      "avg / total       0.82      0.81      0.81      6480\n",
      "\n",
      "accuracy:  0.8137345679012346\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.81      0.83      0.82      2148\n",
      "   priority       0.76      0.79      0.78      2133\n",
      " spec_prior       0.57      1.00      0.73         4\n",
      "  recommend       0.85      0.75      0.79      2042\n",
      "  not_recom       0.50      0.74      0.59       153\n",
      "\n",
      "avg / total       0.80      0.79      0.79      6480\n",
      "\n",
      "accuracy:  0.7908950617283951\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.82      0.84      0.83      2125\n",
      "   priority       0.77      0.81      0.79      2134\n",
      " spec_prior       0.43      1.00      0.60         3\n",
      "  recommend       0.85      0.77      0.81      2044\n",
      "  not_recom       0.61      0.65      0.63       174\n",
      "\n",
      "avg / total       0.81      0.81      0.81      6480\n",
      "\n",
      "accuracy:  0.8061728395061728\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.83      0.82      0.83      2161\n",
      "   priority       0.76      0.82      0.79      2090\n",
      " spec_prior       0.57      1.00      0.73         4\n",
      "  recommend       0.87      0.78      0.82      2063\n",
      "  not_recom       0.54      0.72      0.62       162\n",
      "\n",
      "avg / total       0.81      0.81      0.81      6480\n",
      "\n",
      "accuracy:  0.8064814814814815\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.80      0.86      0.83      2112\n",
      "   priority       0.80      0.78      0.79      2177\n",
      " spec_prior       0.38      1.00      0.55         3\n",
      "  recommend       0.84      0.76      0.80      2023\n",
      "  not_recom       0.55      0.70      0.61       165\n",
      "\n",
      "avg / total       0.80      0.80      0.80      6480\n",
      "\n",
      "accuracy:  0.8006172839506173\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.82      0.83      0.82      2143\n",
      "   priority       0.76      0.80      0.78      2152\n",
      " spec_prior       0.67      1.00      0.80         4\n",
      "  recommend       0.83      0.76      0.79      2019\n",
      "  not_recom       0.53      0.64      0.58       162\n",
      "\n",
      "avg / total       0.79      0.79      0.79      6480\n",
      "\n",
      "accuracy:  0.792283950617284\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.82      0.84      0.83      2130\n",
      "   priority       0.78      0.80      0.79      2115\n",
      " spec_prior       0.38      1.00      0.55         3\n",
      "  recommend       0.86      0.77      0.81      2067\n",
      "  not_recom       0.59      0.79      0.68       165\n",
      "\n",
      "avg / total       0.81      0.81      0.81      6480\n",
      "\n",
      "accuracy:  0.8058641975308642\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.82      0.85      0.84      2115\n",
      "   priority       0.78      0.81      0.80      2142\n",
      " spec_prior       0.80      1.00      0.89         4\n",
      "  recommend       0.87      0.78      0.82      2046\n",
      "  not_recom       0.60      0.70      0.65       173\n",
      "\n",
      "avg / total       0.82      0.81      0.81      6480\n",
      "\n",
      "accuracy:  0.8131172839506173\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.81      0.85      0.83      2158\n",
      "   priority       0.78      0.81      0.80      2125\n",
      " spec_prior       0.38      1.00      0.55         3\n",
      "  recommend       0.85      0.76      0.80      2040\n",
      "  not_recom       0.55      0.69      0.61       154\n",
      "\n",
      "avg / total       0.81      0.81      0.81      6480\n",
      "\n",
      "accuracy:  0.8055555555555556\n",
      "mean accuracy 0.8041666666666666\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "mean_accuracy_model_euclidean = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=1, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.89      0.94      0.92      2145\n",
      "   priority       0.85      0.92      0.88      2102\n",
      " spec_prior       0.27      1.00      0.43         3\n",
      "  recommend       0.94      0.83      0.88      2070\n",
      "  not_recom       0.95      0.65      0.77       160\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8898148148148148\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.89      0.94      0.92      2128\n",
      "   priority       0.87      0.89      0.88      2165\n",
      " spec_prior       0.57      1.00      0.73         4\n",
      "  recommend       0.92      0.85      0.89      2016\n",
      "  not_recom       0.89      0.71      0.79       167\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8922839506172839\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.89      0.94      0.91      2113\n",
      "   priority       0.86      0.91      0.88      2166\n",
      " spec_prior       0.57      1.00      0.73         4\n",
      "  recommend       0.92      0.85      0.88      2026\n",
      "  not_recom       0.93      0.60      0.73       171\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8890432098765432\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.89      0.94      0.91      2160\n",
      "   priority       0.85      0.91      0.88      2101\n",
      " spec_prior       0.33      1.00      0.50         3\n",
      "  recommend       0.92      0.82      0.87      2060\n",
      "  not_recom       0.96      0.72      0.82       156\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8871913580246914\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.89      0.95      0.92      2156\n",
      "   priority       0.87      0.91      0.89      2129\n",
      " spec_prior       0.50      1.00      0.67         4\n",
      "  recommend       0.93      0.84      0.88      2030\n",
      "  not_recom       0.98      0.65      0.78       161\n",
      "\n",
      "avg / total       0.90      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8930555555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.94      0.92      2117\n",
      "   priority       0.85      0.92      0.88      2138\n",
      " spec_prior       0.30      1.00      0.46         3\n",
      "  recommend       0.93      0.82      0.87      2056\n",
      "  not_recom       0.91      0.66      0.76       166\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8898148148148148\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.95      0.92      2107\n",
      "   priority       0.86      0.90      0.88      2173\n",
      " spec_prior       0.57      1.00      0.73         4\n",
      "  recommend       0.92      0.84      0.88      2031\n",
      "  not_recom       0.90      0.70      0.78       165\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8916666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.92      2166\n",
      "   priority       0.84      0.92      0.88      2094\n",
      " spec_prior       0.38      1.00      0.55         3\n",
      "  recommend       0.93      0.83      0.88      2055\n",
      "  not_recom       0.89      0.64      0.75       162\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8904320987654321\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.93      0.92      2131\n",
      "   priority       0.85      0.93      0.88      2098\n",
      " spec_prior       0.36      1.00      0.53         4\n",
      "  recommend       0.93      0.83      0.88      2078\n",
      "  not_recom       0.95      0.60      0.73       169\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8904320987654321\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.89      0.94      0.92      2142\n",
      "   priority       0.86      0.90      0.88      2169\n",
      " spec_prior       0.43      1.00      0.60         3\n",
      "  recommend       0.93      0.84      0.88      2008\n",
      "  not_recom       0.91      0.68      0.78       158\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.891358024691358\n",
      "mean accuracy 0.8905092592592594\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.93      0.93      2134\n",
      "   priority       0.84      0.91      0.88      2164\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.91      0.84      0.87      2005\n",
      "  not_recom       0.89      0.62      0.73       173\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8871913580246914\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.93      2139\n",
      "   priority       0.86      0.90      0.88      2103\n",
      " spec_prior       0.75      1.00      0.86         3\n",
      "  recommend       0.91      0.84      0.87      2081\n",
      "  not_recom       0.94      0.73      0.82       154\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8924382716049383\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.92      2112\n",
      "   priority       0.86      0.90      0.88      2199\n",
      " spec_prior       0.43      1.00      0.60         3\n",
      "  recommend       0.89      0.85      0.87      1985\n",
      "  not_recom       0.94      0.61      0.74       181\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8876543209876543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eleni/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.94      0.93      2161\n",
      "   priority       0.83      0.90      0.86      2068\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.92      0.82      0.87      2101\n",
      "  not_recom       0.78      0.68      0.73       146\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.8833333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.92      2117\n",
      "   priority       0.86      0.91      0.88      2140\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.92      0.84      0.88      2070\n",
      "  not_recom       0.86      0.68      0.76       150\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8930555555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.94      0.93      2156\n",
      "   priority       0.86      0.91      0.88      2127\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.91      0.86      0.89      2016\n",
      "  not_recom       0.92      0.64      0.76       177\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.8975308641975308\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.93      2124\n",
      "   priority       0.85      0.91      0.88      2174\n",
      " spec_prior       0.38      1.00      0.55         3\n",
      "  recommend       0.92      0.83      0.87      2017\n",
      "  not_recom       0.88      0.65      0.75       162\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8919753086419753\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.93      2149\n",
      "   priority       0.84      0.92      0.87      2093\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.93      0.83      0.87      2069\n",
      "  not_recom       0.92      0.66      0.77       165\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8891975308641975\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.93      2141\n",
      "   priority       0.86      0.91      0.88      2159\n",
      " spec_prior       0.30      1.00      0.46         3\n",
      "  recommend       0.92      0.85      0.88      2008\n",
      "  not_recom       0.93      0.63      0.75       169\n",
      "\n",
      "avg / total       0.90      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8936728395061728\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.93      2132\n",
      "   priority       0.83      0.92      0.87      2108\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.92      0.81      0.86      2078\n",
      "  not_recom       0.93      0.71      0.80       158\n",
      "\n",
      "avg / total       0.89      0.89      0.88      6480\n",
      "\n",
      "accuracy:  0.8853395061728395\n",
      "mean accuracy 0.8901388888888888\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.95      0.94      2150\n",
      "   priority       0.87      0.90      0.89      2160\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.90      0.88      0.89      1979\n",
      "  not_recom       0.90      0.56      0.69       187\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.899537037037037\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.93      0.93      2123\n",
      "   priority       0.84      0.92      0.88      2107\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.92      0.84      0.88      2107\n",
      "  not_recom       0.89      0.70      0.78       140\n",
      "\n",
      "avg / total       0.90      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8933641975308642\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.94      0.92      0.93      2127\n",
      "   priority       0.84      0.92      0.88      2140\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.90      0.86      0.88      2039\n",
      "  not_recom       0.94      0.59      0.72       170\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.891358024691358\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.92      2146\n",
      "   priority       0.86      0.91      0.88      2127\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.91      0.85      0.88      2047\n",
      "  not_recom       0.89      0.60      0.71       157\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8919753086419753\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.92      0.92      2203\n",
      "   priority       0.85      0.91      0.88      2088\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.91      0.86      0.88      2028\n",
      "  not_recom       0.90      0.73      0.81       156\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8939814814814815\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.92      2070\n",
      "   priority       0.86      0.91      0.88      2179\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.91      0.85      0.88      2058\n",
      "  not_recom       0.95      0.61      0.74       171\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.891358024691358\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.93      0.92      2115\n",
      "   priority       0.85      0.92      0.88      2122\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.91      0.85      0.88      2067\n",
      "  not_recom       0.93      0.58      0.71       171\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8904320987654321\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.93      0.92      2158\n",
      "   priority       0.86      0.89      0.88      2145\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.90      0.87      0.88      2019\n",
      "  not_recom       0.90      0.67      0.77       156\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8922839506172839\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.94      0.94      0.94      2107\n",
      "   priority       0.86      0.91      0.89      2192\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.91      0.86      0.88      2011\n",
      "  not_recom       0.86      0.61      0.71       165\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.8987654320987655\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.93      0.93      2166\n",
      "   priority       0.84      0.92      0.88      2075\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.91      0.84      0.87      2075\n",
      "  not_recom       0.94      0.65      0.77       162\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8895061728395062\n",
      "mean accuracy 0.8932561728395061\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=15, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.96      0.93      2106\n",
      "   priority       0.88      0.90      0.89      2171\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.91      0.87      0.89      2048\n",
      "  not_recom       0.88      0.66      0.75       152\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.9007716049382716\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.92      0.93      2167\n",
      "   priority       0.84      0.92      0.88      2096\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.90      0.87      0.89      2038\n",
      "  not_recom       0.95      0.44      0.60       175\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8916666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.94      0.94      0.94      2198\n",
      "   priority       0.86      0.91      0.89      2112\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.90      0.87      0.89      2008\n",
      "  not_recom       0.93      0.59      0.72       158\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.9001543209876544\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.95      0.94      2075\n",
      "   priority       0.87      0.92      0.89      2155\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.92      0.86      0.89      2078\n",
      "  not_recom       0.92      0.64      0.76       169\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.9016975308641976\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.94      0.93      2095\n",
      "   priority       0.85      0.91      0.88      2190\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.91      0.86      0.88      2018\n",
      "  not_recom       0.92      0.51      0.65       174\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8916666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.95      0.94      2178\n",
      "   priority       0.87      0.91      0.89      2077\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.91      0.87      0.89      2068\n",
      "  not_recom       0.92      0.62      0.74       153\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.9009259259259259\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.94      0.94      0.94      2168\n",
      "   priority       0.90      0.90      0.90      2168\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.90      0.90      0.90      1987\n",
      "  not_recom       0.91      0.69      0.79       154\n",
      "\n",
      "avg / total       0.91      0.91      0.91      6480\n",
      "\n",
      "accuracy:  0.9118827160493828\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.95      0.93      2105\n",
      "   priority       0.85      0.90      0.87      2099\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.91      0.83      0.87      2099\n",
      "  not_recom       0.93      0.51      0.66       173\n",
      "\n",
      "avg / total       0.89      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.884104938271605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eleni/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.95      0.93      2137\n",
      "   priority       0.86      0.92      0.89      2144\n",
      " spec_prior       0.00      0.00      0.00         0\n",
      "  recommend       0.92      0.86      0.89      2024\n",
      "  not_recom       0.97      0.53      0.69       175\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.8986111111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.93      0.93      2136\n",
      "   priority       0.86      0.91      0.88      2123\n",
      " spec_prior       0.00      0.00      0.00         7\n",
      "  recommend       0.89      0.85      0.87      2062\n",
      "  not_recom       0.89      0.61      0.72       152\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8924382716049383\n",
      "mean accuracy 0.897391975308642\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=20, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.88      0.93      0.90      2100\n",
      "   priority       0.86      0.89      0.87      2171\n",
      " spec_prior       0.00      0.00      0.00         7\n",
      "  recommend       0.90      0.85      0.87      2036\n",
      "  not_recom       0.90      0.46      0.61       166\n",
      "\n",
      "avg / total       0.88      0.88      0.87      6480\n",
      "\n",
      "accuracy:  0.8771604938271605\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.92      0.91      2173\n",
      "   priority       0.86      0.89      0.88      2096\n",
      " spec_prior       0.87      0.87      0.87      2050\n",
      "  not_recom       0.99      0.43      0.60       161\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.883179012345679\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.88      0.94      0.91      2089\n",
      "   priority       0.86      0.88      0.87      2168\n",
      " spec_prior       0.00      0.00      0.00         1\n",
      "  recommend       0.88      0.86      0.87      2034\n",
      "  not_recom       0.98      0.32      0.49       188\n",
      "\n",
      "avg / total       0.88      0.88      0.87      6480\n",
      "\n",
      "accuracy:  0.875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.92      0.92      2184\n",
      "   priority       0.84      0.91      0.88      2099\n",
      " spec_prior       0.00      0.00      0.00         6\n",
      "  recommend       0.90      0.86      0.88      2052\n",
      "  not_recom       0.89      0.59      0.71       139\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.887962962962963\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.92      0.92      2142\n",
      "   priority       0.84      0.91      0.87      2124\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.89      0.85      0.87      2040\n",
      "  not_recom       0.95      0.42      0.58       171\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.8799382716049383\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.92      0.91      2131\n",
      "   priority       0.86      0.89      0.87      2143\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.88      0.86      0.87      2046\n",
      "  not_recom       0.91      0.50      0.64       156\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.8800925925925925\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.92      0.91      2153\n",
      "   priority       0.86      0.91      0.88      2141\n",
      " spec_prior       0.00      0.00      0.00         6\n",
      "  recommend       0.89      0.86      0.88      2024\n",
      "  not_recom       0.84      0.47      0.60       156\n",
      "\n",
      "avg / total       0.88      0.89      0.88      6480\n",
      "\n",
      "accuracy:  0.8850308641975309\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.94      0.92      2120\n",
      "   priority       0.85      0.88      0.86      2126\n",
      " spec_prior       0.00      0.00      0.00         1\n",
      "  recommend       0.89      0.85      0.87      2062\n",
      "  not_recom       0.97      0.41      0.58       171\n",
      "\n",
      "avg / total       0.88      0.88      0.87      6480\n",
      "\n",
      "accuracy:  0.8774691358024691\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.92      0.91      2144\n",
      "   priority       0.84      0.91      0.87      2100\n",
      " spec_prior       0.00      0.00      0.00         6\n",
      "  recommend       0.89      0.85      0.87      2062\n",
      "  not_recom       0.89      0.40      0.55       168\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.879320987654321\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.94      0.92      2129\n",
      "   priority       0.87      0.89      0.88      2167\n",
      " spec_prior       0.00      0.00      0.00         1\n",
      "  recommend       0.89      0.87      0.88      2024\n",
      "  not_recom       0.94      0.50      0.65       159\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8902777777777777\n",
      "mean accuracy 0.8815432098765432\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=30, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.87      0.90      0.88      2132\n",
      "   priority       0.83      0.89      0.86      2141\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.89      0.82      0.85      2049\n",
      "  not_recom       0.85      0.46      0.60       153\n",
      "\n",
      "avg / total       0.86      0.86      0.86      6480\n",
      "\n",
      "accuracy:  0.8598765432098765\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.85      0.85      0.85      2141\n",
      "   priority       0.81      0.87      0.84      2126\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.84      0.83      0.84      2037\n",
      "  not_recom       0.96      0.28      0.43       174\n",
      "\n",
      "avg / total       0.84      0.84      0.83      6480\n",
      "\n",
      "accuracy:  0.8350308641975308\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.86      0.89      0.87      2140\n",
      "   priority       0.82      0.87      0.85      2129\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.86      0.82      0.84      2038\n",
      "  not_recom       0.93      0.25      0.40       170\n",
      "\n",
      "avg / total       0.85      0.85      0.84      6480\n",
      "\n",
      "accuracy:  0.8458333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.86      0.91      0.88      2133\n",
      "   priority       0.85      0.87      0.86      2138\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.88      0.82      0.85      2048\n",
      "  not_recom       0.85      0.48      0.61       157\n",
      "\n",
      "avg / total       0.86      0.86      0.86      6480\n",
      "\n",
      "accuracy:  0.8580246913580247\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.87      0.87      0.87      2155\n",
      "   priority       0.83      0.89      0.86      2131\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.85      0.83      0.84      2030\n",
      "  not_recom       0.91      0.46      0.61       160\n",
      "\n",
      "avg / total       0.85      0.85      0.85      6480\n",
      "\n",
      "accuracy:  0.8495370370370371\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.84      0.92      0.88      2118\n",
      "   priority       0.84      0.87      0.85      2136\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.88      0.82      0.85      2056\n",
      "  not_recom       0.95      0.34      0.50       167\n",
      "\n",
      "avg / total       0.86      0.86      0.85      6480\n",
      "\n",
      "accuracy:  0.8557098765432098\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.88      0.88      0.88      2127\n",
      "   priority       0.82      0.88      0.85      2112\n",
      " spec_prior       0.00      0.00      0.00         6\n",
      "  recommend       0.85      0.83      0.84      2070\n",
      "  not_recom       0.90      0.39      0.54       165\n",
      "\n",
      "avg / total       0.85      0.85      0.85      6480\n",
      "\n",
      "accuracy:  0.8515432098765432\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.84      0.91      0.87      2146\n",
      "   priority       0.84      0.87      0.85      2155\n",
      " spec_prior       0.00      0.00      0.00         1\n",
      "  recommend       0.88      0.81      0.84      2016\n",
      "  not_recom       0.98      0.37      0.54       162\n",
      "\n",
      "avg / total       0.85      0.85      0.85      6480\n",
      "\n",
      "accuracy:  0.8498456790123456\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.87      0.87      0.87      2152\n",
      "   priority       0.82      0.88      0.85      2091\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.85      0.83      0.84      2075\n",
      "  not_recom       0.94      0.38      0.54       160\n",
      "\n",
      "avg / total       0.85      0.85      0.85      6480\n",
      "\n",
      "accuracy:  0.8489197530864198\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.84      0.89      0.86      2121\n",
      "   priority       0.84      0.87      0.85      2176\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.85      0.81      0.83      2011\n",
      "  not_recom       0.88      0.34      0.48       167\n",
      "\n",
      "avg / total       0.84      0.84      0.84      6480\n",
      "\n",
      "accuracy:  0.8430555555555556\n",
      "mean accuracy 0.8497376543209876\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=50, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.73      0.81      0.77      2141\n",
      "   priority       0.79      0.77      0.78      2126\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.80      0.77      0.79      2052\n",
      "  not_recom       0.80      0.15      0.26       157\n",
      "\n",
      "avg / total       0.77      0.77      0.77      6480\n",
      "\n",
      "accuracy:  0.7709876543209877\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.74      0.80      0.77      2132\n",
      "   priority       0.77      0.84      0.80      2141\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.83      0.75      0.79      2034\n",
      "  not_recom       0.87      0.12      0.21       170\n",
      "\n",
      "avg / total       0.78      0.78      0.77      6480\n",
      "\n",
      "accuracy:  0.7796296296296297\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.73      0.80      0.77      2129\n",
      "   priority       0.78      0.82      0.80      2150\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.82      0.75      0.78      2040\n",
      "  not_recom       0.90      0.18      0.30       158\n",
      "\n",
      "avg / total       0.78      0.78      0.77      6480\n",
      "\n",
      "accuracy:  0.7754629629629629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.75      0.82      0.79      2144\n",
      "   priority       0.77      0.82      0.79      2117\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.83      0.76      0.80      2046\n",
      "  not_recom       0.78      0.08      0.15       169\n",
      "\n",
      "avg / total       0.78      0.78      0.77      6480\n",
      "\n",
      "accuracy:  0.7813271604938271\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.74      0.77      0.75      2131\n",
      "   priority       0.79      0.82      0.80      2126\n",
      " spec_prior       0.00      0.00      0.00         6\n",
      "  recommend       0.78      0.78      0.78      2044\n",
      "  not_recom       0.78      0.12      0.21       173\n",
      "\n",
      "avg / total       0.77      0.77      0.77      6480\n",
      "\n",
      "accuracy:  0.7717592592592593\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.75      0.82      0.78      2142\n",
      "   priority       0.79      0.81      0.80      2141\n",
      " spec_prior       0.00      0.00      0.00         1\n",
      "  recommend       0.82      0.77      0.79      2042\n",
      "  not_recom       0.97      0.21      0.35       154\n",
      "\n",
      "avg / total       0.79      0.79      0.78      6480\n",
      "\n",
      "accuracy:  0.7858024691358024\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.76      0.79      0.77      2126\n",
      "   priority       0.77      0.83      0.80      2113\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.82      0.76      0.79      2091\n",
      "  not_recom       0.82      0.18      0.30       146\n",
      "\n",
      "avg / total       0.78      0.78      0.78      6480\n",
      "\n",
      "accuracy:  0.7796296296296297\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.74      0.80      0.77      2147\n",
      "   priority       0.80      0.80      0.80      2154\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.80      0.78      0.79      1995\n",
      "  not_recom       0.85      0.09      0.17       181\n",
      "\n",
      "avg / total       0.78      0.78      0.77      6480\n",
      "\n",
      "accuracy:  0.7759259259259259\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.76      0.81      0.78      2141\n",
      "   priority       0.80      0.81      0.81      2123\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.80      0.79      0.79      2055\n",
      "  not_recom       0.85      0.19      0.31       156\n",
      "\n",
      "avg / total       0.79      0.79      0.78      6480\n",
      "\n",
      "accuracy:  0.7876543209876543\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.71      0.81      0.76      2132\n",
      "   priority       0.79      0.80      0.79      2144\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.83      0.75      0.79      2031\n",
      "  not_recom       0.88      0.13      0.23       171\n",
      "\n",
      "avg / total       0.78      0.77      0.77      6480\n",
      "\n",
      "accuracy:  0.7717592592592593\n",
      "mean accuracy 0.7779938271604939\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.64      0.77      0.70      2103\n",
      "   priority       0.79      0.74      0.76      2177\n",
      " spec_prior       0.00      0.00      0.00         1\n",
      "  recommend       0.80      0.74      0.77      2043\n",
      "  not_recom       0.92      0.08      0.14       156\n",
      "\n",
      "avg / total       0.75      0.73      0.73      6480\n",
      "\n",
      "accuracy:  0.7324074074074074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.71      0.70      0.71      2170\n",
      "   priority       0.74      0.81      0.77      2090\n",
      " spec_prior       0.00      0.00      0.00         6\n",
      "  recommend       0.78      0.77      0.78      2043\n",
      "  not_recom       0.67      0.07      0.13       171\n",
      "\n",
      "avg / total       0.74      0.74      0.73      6480\n",
      "\n",
      "accuracy:  0.7422839506172839\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.67      0.70      0.69      2169\n",
      "   priority       0.75      0.76      0.75      2093\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.77      0.78      0.78      2051\n",
      "  not_recom       1.00      0.04      0.07       165\n",
      "\n",
      "avg / total       0.74      0.73      0.72      6480\n",
      "\n",
      "accuracy:  0.7307098765432098\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.64      0.77      0.70      2104\n",
      "   priority       0.77      0.73      0.75      2174\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.81      0.73      0.77      2035\n",
      "  not_recom       0.79      0.12      0.20       162\n",
      "\n",
      "avg / total       0.74      0.73      0.72      6480\n",
      "\n",
      "accuracy:  0.7282407407407407\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.62      0.73      0.67      2092\n",
      "   priority       0.77      0.73      0.75      2168\n",
      " spec_prior       0.00      0.00      0.00         6\n",
      "  recommend       0.77      0.74      0.76      2056\n",
      "  not_recom       0.50      0.04      0.07       158\n",
      "\n",
      "avg / total       0.72      0.71      0.71      6480\n",
      "\n",
      "accuracy:  0.7140432098765432\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.72      0.73      0.72      2181\n",
      "   priority       0.74      0.80      0.77      2099\n",
      " spec_prior       0.00      0.00      0.00         1\n",
      "  recommend       0.80      0.77      0.79      2030\n",
      "  not_recom       0.87      0.08      0.14       169\n",
      "\n",
      "avg / total       0.75      0.75      0.74      6480\n",
      "\n",
      "accuracy:  0.7498456790123457\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.70      0.72      0.71      2173\n",
      "   priority       0.79      0.80      0.79      2146\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.74      0.77      0.76      1996\n",
      "  not_recom       0.79      0.07      0.12       162\n",
      "\n",
      "avg / total       0.74      0.74      0.74      6480\n",
      "\n",
      "accuracy:  0.7438271604938271\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.63      0.76      0.69      2100\n",
      "   priority       0.75      0.74      0.75      2121\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.81      0.72      0.76      2090\n",
      "  not_recom       0.60      0.04      0.07       165\n",
      "\n",
      "avg / total       0.73      0.72      0.72      6480\n",
      "\n",
      "accuracy:  0.7222222222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.65      0.76      0.70      2101\n",
      "   priority       0.79      0.77      0.78      2138\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.80      0.76      0.78      2060\n",
      "  not_recom       0.43      0.02      0.03       177\n",
      "\n",
      "avg / total       0.74      0.74      0.73      6480\n",
      "\n",
      "accuracy:  0.7427469135802469\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.69      0.73      0.71      2172\n",
      "   priority       0.75      0.76      0.75      2129\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.78      0.77      0.78      2026\n",
      "  not_recom       0.86      0.13      0.22       150\n",
      "\n",
      "avg / total       0.74      0.74      0.73      6480\n",
      "\n",
      "accuracy:  0.7376543209876543\n",
      "mean accuracy 0.7343981481481483\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=150, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "\n",
    "mean_accuracy_model1 =  sum(acc)/10    \n",
    "mean_accuracy_model_euclidean.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8041666666666666, 0.8905092592592594, 0.8901388888888888, 0.8932561728395061, 0.897391975308642, 0.8815432098765432, 0.8497376543209876, 0.7779938271604939, 0.7343981481481483]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print mean_accuracy_model_euclidean\n",
    "k = [1, 5, 10, 15, 20, 30, 50, 100, 150]\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(k, mean_accuracy_model_euclidean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minkowski and k tuning on 10% noise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.80      0.85      0.83      2115\n",
      "   priority       0.81      0.77      0.79      2184\n",
      " spec_prior       0.62      1.00      0.77         5\n",
      "  recommend       0.82      0.80      0.81      2004\n",
      "  not_recom       0.57      0.67      0.62       172\n",
      "\n",
      "avg / total       0.80      0.80      0.80      6480\n",
      "\n",
      "accuracy:  0.8020061728395061\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.82      0.83      0.83      2158\n",
      "   priority       0.75      0.82      0.79      2083\n",
      " spec_prior       0.40      1.00      0.57         2\n",
      "  recommend       0.86      0.75      0.80      2082\n",
      "  not_recom       0.56      0.79      0.66       155\n",
      "\n",
      "avg / total       0.81      0.80      0.80      6480\n",
      "\n",
      "accuracy:  0.799074074074074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.82      0.84      0.83      2164\n",
      "   priority       0.77      0.81      0.79      2129\n",
      " spec_prior       0.00      0.00      0.00         7\n",
      "  recommend       0.85      0.76      0.80      1995\n",
      "  not_recom       0.58      0.72      0.64       185\n",
      "\n",
      "avg / total       0.80      0.80      0.80      6480\n",
      "\n",
      "accuracy:  0.8021604938271605\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.80      0.84      0.82      2109\n",
      "   priority       0.77      0.81      0.79      2138\n",
      " spec_prior       0.00      0.00      0.00         0\n",
      "  recommend       0.86      0.75      0.81      2091\n",
      "  not_recom       0.50      0.73      0.59       142\n",
      "\n",
      "avg / total       0.80      0.80      0.80      6480\n",
      "\n",
      "accuracy:  0.7984567901234568\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.83      0.86      0.84      2134\n",
      "   priority       0.78      0.82      0.80      2138\n",
      " spec_prior       0.43      1.00      0.60         3\n",
      "  recommend       0.86      0.78      0.82      2029\n",
      "  not_recom       0.61      0.65      0.63       176\n",
      "\n",
      "avg / total       0.82      0.81      0.82      6480\n",
      "\n",
      "accuracy:  0.8148148148148148\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.80      0.84      0.82      2139\n",
      "   priority       0.76      0.78      0.77      2129\n",
      " spec_prior       0.57      1.00      0.73         4\n",
      "  recommend       0.82      0.74      0.78      2057\n",
      "  not_recom       0.59      0.78      0.67       151\n",
      "\n",
      "avg / total       0.79      0.79      0.79      6480\n",
      "\n",
      "accuracy:  0.7859567901234568\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.81      0.85      0.83      2140\n",
      "   priority       0.78      0.79      0.79      2135\n",
      " spec_prior       0.40      1.00      0.57         2\n",
      "  recommend       0.84      0.77      0.80      2041\n",
      "  not_recom       0.54      0.71      0.61       162\n",
      "\n",
      "avg / total       0.80      0.80      0.80      6480\n",
      "\n",
      "accuracy:  0.8\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.82      0.85      0.83      2133\n",
      "   priority       0.76      0.81      0.78      2132\n",
      " spec_prior       0.62      1.00      0.77         5\n",
      "  recommend       0.86      0.75      0.80      2045\n",
      "  not_recom       0.59      0.71      0.64       165\n",
      "\n",
      "avg / total       0.81      0.80      0.80      6480\n",
      "\n",
      "accuracy:  0.8030864197530864\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.82      0.84      0.83      2164\n",
      "   priority       0.77      0.82      0.79      2118\n",
      " spec_prior       0.57      1.00      0.73         4\n",
      "  recommend       0.86      0.76      0.80      2014\n",
      "  not_recom       0.64      0.74      0.69       180\n",
      "\n",
      "avg / total       0.81      0.80      0.80      6480\n",
      "\n",
      "accuracy:  0.8040123456790124\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.81      0.83      0.82      2109\n",
      "   priority       0.78      0.78      0.78      2149\n",
      " spec_prior       0.50      1.00      0.67         3\n",
      "  recommend       0.83      0.77      0.80      2072\n",
      "  not_recom       0.52      0.81      0.63       147\n",
      "\n",
      "avg / total       0.80      0.79      0.80      6480\n",
      "\n",
      "accuracy:  0.7949074074074074\n",
      "mean accuracy 0.8004475308641975\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "mean_accuracy_model_minkowski = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=1, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model10 = sum(acc)/10  \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n",
    "print \"mean accuracy\", mean_accuracy_model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.95      0.93      2136\n",
      "   priority       0.85      0.91      0.88      2128\n",
      " spec_prior       0.50      1.00      0.67         3\n",
      "  recommend       0.94      0.84      0.88      2070\n",
      "  not_recom       0.89      0.72      0.80       143\n",
      "\n",
      "avg / total       0.90      0.90      0.89      6480\n",
      "\n",
      "accuracy:  0.8953703703703704\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.94      0.92      2137\n",
      "   priority       0.85      0.90      0.87      2139\n",
      " spec_prior       0.31      1.00      0.47         4\n",
      "  recommend       0.92      0.84      0.88      2016\n",
      "  not_recom       0.91      0.55      0.69       184\n",
      "\n",
      "avg / total       0.89      0.89      0.88      6480\n",
      "\n",
      "accuracy:  0.8859567901234567\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.92      2174\n",
      "   priority       0.84      0.92      0.88      2097\n",
      " spec_prior       0.20      1.00      0.33         1\n",
      "  recommend       0.92      0.84      0.88      2031\n",
      "  not_recom       0.91      0.59      0.72       177\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.890895061728395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.89      0.94      0.91      2099\n",
      "   priority       0.85      0.90      0.88      2170\n",
      " spec_prior       0.00      0.00      0.00         6\n",
      "  recommend       0.91      0.82      0.86      2055\n",
      "  not_recom       0.89      0.72      0.79       150\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.8834876543209876\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.92      2160\n",
      "   priority       0.88      0.91      0.89      2155\n",
      " spec_prior       0.20      1.00      0.33         1\n",
      "  recommend       0.92      0.87      0.89      2000\n",
      "  not_recom       0.96      0.65      0.77       164\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.8993827160493827\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.89      0.95      0.92      2113\n",
      "   priority       0.84      0.92      0.88      2112\n",
      " spec_prior       0.00      0.00      0.00         6\n",
      "  recommend       0.94      0.81      0.87      2086\n",
      "  not_recom       0.89      0.66      0.76       163\n",
      "\n",
      "avg / total       0.89      0.89      0.88      6480\n",
      "\n",
      "accuracy:  0.8859567901234567\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.94      0.92      2159\n",
      "   priority       0.85      0.90      0.88      2113\n",
      " spec_prior       0.50      1.00      0.67         3\n",
      "  recommend       0.92      0.84      0.88      2029\n",
      "  not_recom       0.89      0.62      0.74       176\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8878086419753086\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.89      0.94      0.92      2114\n",
      "   priority       0.85      0.91      0.88      2154\n",
      " spec_prior       0.31      1.00      0.47         4\n",
      "  recommend       0.93      0.83      0.88      2057\n",
      "  not_recom       0.91      0.62      0.74       151\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8890432098765432\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.93      0.92      2161\n",
      "   priority       0.85      0.92      0.88      2088\n",
      " spec_prior       0.33      1.00      0.50         3\n",
      "  recommend       0.92      0.84      0.88      2083\n",
      "  not_recom       0.94      0.66      0.78       145\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8898148148148148\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.89      0.95      0.92      2112\n",
      "   priority       0.87      0.91      0.89      2179\n",
      " spec_prior       0.57      1.00      0.73         4\n",
      "  recommend       0.92      0.84      0.88      2003\n",
      "  not_recom       0.94      0.59      0.72       182\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8916666666666667\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.95      0.94      2144\n",
      "   priority       0.85      0.92      0.88      2149\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.93      0.83      0.88      2026\n",
      "  not_recom       0.87      0.70      0.77       158\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.8967592592592593\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.93      0.92      2129\n",
      "   priority       0.85      0.91      0.88      2118\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.91      0.86      0.88      2060\n",
      "  not_recom       0.94      0.61      0.74       169\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.891358024691358\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.94      0.93      2132\n",
      "   priority       0.83      0.91      0.87      2126\n",
      " spec_prior       0.38      1.00      0.55         3\n",
      "  recommend       0.92      0.83      0.87      2041\n",
      "  not_recom       0.94      0.59      0.72       178\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8867283950617284\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.95      0.93      2141\n",
      "   priority       0.86      0.91      0.88      2141\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.92      0.83      0.87      2045\n",
      "  not_recom       0.88      0.72      0.79       149\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8929012345679013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.94      0.92      2076\n",
      "   priority       0.86      0.91      0.88      2178\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.93      0.84      0.88      2066\n",
      "  not_recom       0.92      0.71      0.80       156\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8919753086419753\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.94      0.93      2197\n",
      "   priority       0.84      0.92      0.88      2089\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.92      0.85      0.88      2020\n",
      "  not_recom       0.88      0.60      0.71       171\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8925925925925926\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.92      0.92      2156\n",
      "   priority       0.86      0.92      0.88      2147\n",
      " spec_prior       0.14      1.00      0.25         2\n",
      "  recommend       0.90      0.85      0.87      2017\n",
      "  not_recom       0.91      0.67      0.77       158\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8907407407407407\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.96      0.93      2117\n",
      "   priority       0.87      0.91      0.89      2120\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.92      0.85      0.89      2069\n",
      "  not_recom       0.89      0.73      0.81       169\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.9012345679012346\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.95      0.93      2101\n",
      "   priority       0.86      0.90      0.88      2177\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.92      0.85      0.89      2038\n",
      "  not_recom       0.86      0.66      0.75       161\n",
      "\n",
      "avg / total       0.90      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8945987654320988\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.94      0.93      2172\n",
      "   priority       0.85      0.91      0.88      2090\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.91      0.85      0.88      2048\n",
      "  not_recom       0.88      0.72      0.79       166\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.895679012345679\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.94      0.93      2157\n",
      "   priority       0.84      0.93      0.89      2086\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.92      0.84      0.88      2070\n",
      "  not_recom       0.94      0.63      0.75       163\n",
      "\n",
      "avg / total       0.90      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8945987654320988\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.93      0.92      2116\n",
      "   priority       0.86      0.90      0.88      2181\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.90      0.86      0.88      2016\n",
      "  not_recom       0.92      0.63      0.75       164\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8922839506172839\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.92      2154\n",
      "   priority       0.85      0.91      0.88      2098\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.92      0.85      0.88      2062\n",
      "  not_recom       0.83      0.52      0.64       162\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.888425925925926\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.93      0.93      2119\n",
      "   priority       0.87      0.90      0.88      2169\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.89      0.88      0.88      2024\n",
      "  not_recom       0.93      0.60      0.73       165\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8945987654320988\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.92      2125\n",
      "   priority       0.87      0.91      0.89      2141\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.91      0.86      0.88      2063\n",
      "  not_recom       0.95      0.68      0.79       147\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.8967592592592593\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.91      0.92      2148\n",
      "   priority       0.84      0.91      0.87      2126\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.89      0.85      0.87      2023\n",
      "  not_recom       0.89      0.61      0.72       180\n",
      "\n",
      "avg / total       0.89      0.89      0.88      6480\n",
      "\n",
      "accuracy:  0.8851851851851852\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.93      0.93      2148\n",
      "   priority       0.85      0.91      0.88      2123\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.90      0.86      0.88      2038\n",
      "  not_recom       0.89      0.65      0.76       168\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8929012345679013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.93      0.93      2125\n",
      "   priority       0.87      0.92      0.89      2144\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.90      0.88      0.89      2048\n",
      "  not_recom       0.88      0.62      0.73       159\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.9012345679012346\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.93      0.93      2146\n",
      "   priority       0.88      0.91      0.89      2173\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.90      0.86      0.88      2009\n",
      "  not_recom       0.88      0.75      0.81       150\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.8993827160493827\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.92      2127\n",
      "   priority       0.85      0.92      0.88      2094\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.92      0.84      0.88      2077\n",
      "  not_recom       0.94      0.57      0.71       177\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8912037037037037\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=15, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.95      0.94      2157\n",
      "   priority       0.88      0.90      0.89      2141\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.90      0.88      0.89      2032\n",
      "  not_recom       0.93      0.61      0.74       146\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.9029320987654321\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.94      0.92      2116\n",
      "   priority       0.84      0.92      0.88      2126\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.92      0.84      0.88      2054\n",
      "  not_recom       0.95      0.50      0.65       181\n",
      "\n",
      "avg / total       0.89      0.89      0.88      6480\n",
      "\n",
      "accuracy:  0.8859567901234567\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.94      0.92      2110\n",
      "   priority       0.86      0.91      0.89      2124\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.92      0.87      0.89      2078\n",
      "  not_recom       0.93      0.59      0.72       164\n",
      "\n",
      "avg / total       0.90      0.90      0.89      6480\n",
      "\n",
      "accuracy:  0.8959876543209877\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.93      0.93      2163\n",
      "   priority       0.86      0.92      0.89      2143\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.90      0.86      0.88      2008\n",
      "  not_recom       0.95      0.58      0.72       163\n",
      "\n",
      "avg / total       0.90      0.90      0.89      6480\n",
      "\n",
      "accuracy:  0.8959876543209877\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.93      0.93      2146\n",
      "   priority       0.86      0.91      0.89      2144\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.91      0.87      0.89      2014\n",
      "  not_recom       0.92      0.53      0.67       172\n",
      "\n",
      "avg / total       0.90      0.90      0.89      6480\n",
      "\n",
      "accuracy:  0.8961419753086419\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.95      0.94      2127\n",
      "   priority       0.86      0.92      0.89      2123\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.91      0.86      0.89      2072\n",
      "  not_recom       0.95      0.58      0.72       155\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.8998456790123457\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.94      0.93      0.94      2139\n",
      "   priority       0.87      0.92      0.89      2164\n",
      " spec_prior       0.00      0.00      0.00         6\n",
      "  recommend       0.89      0.88      0.89      2010\n",
      "  not_recom       0.94      0.63      0.76       161\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.9018518518518519\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.92      0.95      0.93      2134\n",
      "   priority       0.86      0.90      0.88      2103\n",
      " spec_prior       0.00      0.00      0.00         1\n",
      "  recommend       0.91      0.86      0.89      2076\n",
      "  not_recom       0.97      0.56      0.71       166\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6480\n",
      "\n",
      "accuracy:  0.8969135802469136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.93      0.94      0.94      2165\n",
      "   priority       0.87      0.92      0.90      2143\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.92      0.87      0.89      2018\n",
      "  not_recom       0.94      0.64      0.76       151\n",
      "\n",
      "avg / total       0.91      0.91      0.91      6480\n",
      "\n",
      "accuracy:  0.9064814814814814\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.95      0.93      2108\n",
      "   priority       0.87      0.91      0.89      2124\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.91      0.85      0.88      2068\n",
      "  not_recom       0.95      0.57      0.72       176\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8942901234567902\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=20, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.91      0.91      2176\n",
      "   priority       0.85      0.90      0.87      2137\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.88      0.86      0.87      1996\n",
      "  not_recom       0.96      0.51      0.67       167\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.878858024691358\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.88      0.94      0.91      2097\n",
      "   priority       0.86      0.88      0.87      2130\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.90      0.86      0.88      2090\n",
      "  not_recom       0.92      0.42      0.58       160\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.8794753086419753\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.91      0.93      0.92      2149\n",
      "   priority       0.85      0.90      0.87      2133\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.89      0.86      0.87      2033\n",
      "  not_recom       0.97      0.45      0.61       163\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.8825617283950618\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.93      0.92      2124\n",
      "   priority       0.87      0.90      0.89      2134\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.89      0.87      0.88      2053\n",
      "  not_recom       0.92      0.44      0.60       164\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6480\n",
      "\n",
      "accuracy:  0.8885802469135803\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.86      0.91      0.89      2104\n",
      "   priority       0.84      0.89      0.87      2144\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.89      0.83      0.86      2059\n",
      "  not_recom       0.92      0.40      0.56       168\n",
      "\n",
      "avg / total       0.87      0.86      0.86      6480\n",
      "\n",
      "accuracy:  0.8646604938271605\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.93      0.92      2169\n",
      "   priority       0.86      0.89      0.88      2123\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.88      0.87      0.87      2027\n",
      "  not_recom       0.98      0.50      0.66       159\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.8837962962962963\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.93      0.92      2151\n",
      "   priority       0.86      0.90      0.88      2123\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.90      0.85      0.87      2045\n",
      "  not_recom       0.93      0.51      0.66       157\n",
      "\n",
      "avg / total       0.89      0.89      0.88      6480\n",
      "\n",
      "accuracy:  0.8850308641975309\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.91      0.90      2122\n",
      "   priority       0.84      0.89      0.87      2144\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.88      0.86      0.87      2041\n",
      "  not_recom       0.95      0.49      0.65       170\n",
      "\n",
      "avg / total       0.88      0.88      0.87      6480\n",
      "\n",
      "accuracy:  0.8753086419753087\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.94      0.92      2081\n",
      "   priority       0.86      0.89      0.87      2160\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.89      0.85      0.87      2078\n",
      "  not_recom       0.92      0.54      0.68       157\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.883179012345679\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.90      0.91      0.91      2192\n",
      "   priority       0.86      0.91      0.88      2107\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.89      0.87      0.88      2008\n",
      "  not_recom       0.95      0.41      0.57       170\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6480\n",
      "\n",
      "accuracy:  0.8833333333333333\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=30, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.85      0.88      0.86      2127\n",
      "   priority       0.81      0.88      0.85      2122\n",
      " spec_prior       0.00      0.00      0.00         6\n",
      "  recommend       0.88      0.81      0.84      2070\n",
      "  not_recom       0.89      0.37      0.53       155\n",
      "\n",
      "avg / total       0.85      0.85      0.84      6480\n",
      "\n",
      "accuracy:  0.8453703703703703\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.84      0.88      0.86      2146\n",
      "   priority       0.82      0.86      0.84      2145\n",
      " spec_prior       0.00      0.00      0.00         1\n",
      "  recommend       0.86      0.82      0.84      2016\n",
      "  not_recom       0.98      0.28      0.44       172\n",
      "\n",
      "avg / total       0.84      0.84      0.84      6480\n",
      "\n",
      "accuracy:  0.8401234567901235\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.84      0.88      0.86      2113\n",
      "   priority       0.84      0.88      0.86      2158\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.87      0.81      0.84      2059\n",
      "  not_recom       0.92      0.49      0.64       146\n",
      "\n",
      "avg / total       0.85      0.85      0.85      6480\n",
      "\n",
      "accuracy:  0.8487654320987654\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.86      0.90      0.88      2160\n",
      "   priority       0.83      0.88      0.85      2109\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.87      0.83      0.85      2027\n",
      "  not_recom       0.95      0.29      0.44       181\n",
      "\n",
      "avg / total       0.86      0.85      0.85      6480\n",
      "\n",
      "accuracy:  0.854783950617284\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.86      0.90      0.88      2124\n",
      "   priority       0.83      0.87      0.85      2139\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.86      0.83      0.85      2045\n",
      "  not_recom       0.95      0.33      0.49       169\n",
      "\n",
      "avg / total       0.85      0.85      0.85      6480\n",
      "\n",
      "accuracy:  0.8512345679012345\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.84      0.89      0.87      2149\n",
      "   priority       0.82      0.87      0.85      2128\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.87      0.80      0.83      2041\n",
      "  not_recom       0.88      0.34      0.49       158\n",
      "\n",
      "avg / total       0.84      0.84      0.84      6480\n",
      "\n",
      "accuracy:  0.8432098765432099\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.83      0.90      0.86      2115\n",
      "   priority       0.84      0.87      0.85      2131\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.87      0.81      0.84      2065\n",
      "  not_recom       0.94      0.37      0.53       166\n",
      "\n",
      "avg / total       0.85      0.85      0.84      6480\n",
      "\n",
      "accuracy:  0.8453703703703703\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.88      0.87      0.88      2158\n",
      "   priority       0.81      0.88      0.84      2136\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.86      0.84      0.85      2021\n",
      "  not_recom       0.92      0.34      0.49       161\n",
      "\n",
      "avg / total       0.85      0.85      0.85      6480\n",
      "\n",
      "accuracy:  0.85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.84      0.90      0.87      2085\n",
      "   priority       0.83      0.85      0.84      2181\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.86      0.82      0.84      2043\n",
      "  not_recom       0.91      0.31      0.46       167\n",
      "\n",
      "avg / total       0.84      0.84      0.84      6480\n",
      "\n",
      "accuracy:  0.841358024691358\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.86      0.88      0.87      2188\n",
      "   priority       0.82      0.89      0.85      2086\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.86      0.81      0.84      2043\n",
      "  not_recom       0.93      0.47      0.63       160\n",
      "\n",
      "avg / total       0.85      0.85      0.85      6480\n",
      "\n",
      "accuracy:  0.8503086419753086\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=50, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.70      0.85      0.76      2081\n",
      "   priority       0.83      0.77      0.80      2197\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.82      0.76      0.79      2038\n",
      "  not_recom       0.89      0.19      0.32       161\n",
      "\n",
      "avg / total       0.79      0.78      0.77      6480\n",
      "\n",
      "accuracy:  0.7762345679012346\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.77      0.76      0.77      2192\n",
      "   priority       0.76      0.82      0.79      2070\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.78      0.79      0.78      2048\n",
      "  not_recom       0.83      0.11      0.20       166\n",
      "\n",
      "avg / total       0.77      0.77      0.77      6480\n",
      "\n",
      "accuracy:  0.7723765432098766\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.75      0.79      0.77      2120\n",
      "   priority       0.79      0.80      0.79      2138\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.80      0.82      0.81      2035\n",
      "  not_recom       0.81      0.09      0.17       183\n",
      "\n",
      "avg / total       0.78      0.78      0.77      6480\n",
      "\n",
      "accuracy:  0.779783950617284\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.72      0.80      0.76      2153\n",
      "   priority       0.79      0.80      0.79      2129\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.82      0.75      0.78      2051\n",
      "  not_recom       0.92      0.24      0.38       144\n",
      "\n",
      "avg / total       0.78      0.77      0.77      6480\n",
      "\n",
      "accuracy:  0.7739197530864198\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.74      0.81      0.77      2126\n",
      "   priority       0.79      0.81      0.80      2142\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.83      0.78      0.81      2041\n",
      "  not_recom       0.93      0.15      0.26       169\n",
      "\n",
      "avg / total       0.79      0.79      0.78      6480\n",
      "\n",
      "accuracy:  0.7858024691358024\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.76      0.82      0.79      2147\n",
      "   priority       0.79      0.81      0.80      2125\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.81      0.79      0.80      2045\n",
      "  not_recom       0.80      0.13      0.22       158\n",
      "\n",
      "avg / total       0.79      0.79      0.78      6480\n",
      "\n",
      "accuracy:  0.7868827160493828\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.74      0.82      0.78      2154\n",
      "   priority       0.81      0.81      0.81      2135\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.80      0.76      0.78      2034\n",
      "  not_recom       0.91      0.19      0.31       154\n",
      "\n",
      "avg / total       0.78      0.78      0.78      6480\n",
      "\n",
      "accuracy:  0.7796296296296297\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.69      0.82      0.75      2119\n",
      "   priority       0.79      0.79      0.79      2132\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.84      0.74      0.79      2052\n",
      "  not_recom       0.73      0.06      0.12       173\n",
      "\n",
      "avg / total       0.77      0.76      0.76      6480\n",
      "\n",
      "accuracy:  0.7640432098765432\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.82      0.80      0.81      2187\n",
      "   priority       0.79      0.87      0.83      2082\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.82      0.82      0.82      2042\n",
      "  not_recom       0.88      0.17      0.28       166\n",
      "\n",
      "avg / total       0.81      0.81      0.80      6480\n",
      "\n",
      "accuracy:  0.807716049382716\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.68      0.83      0.75      2086\n",
      "   priority       0.81      0.75      0.78      2185\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.81      0.74      0.77      2044\n",
      "  not_recom       0.86      0.19      0.31       161\n",
      "\n",
      "avg / total       0.77      0.76      0.75      6480\n",
      "\n",
      "accuracy:  0.7583333333333333\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.68      0.72      0.70      2160\n",
      "   priority       0.75      0.77      0.76      2137\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.78      0.76      0.77      2013\n",
      "  not_recom       0.71      0.06      0.11       166\n",
      "\n",
      "avg / total       0.73      0.73      0.72      6480\n",
      "\n",
      "accuracy:  0.7317901234567902\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.64      0.73      0.68      2113\n",
      "   priority       0.75      0.74      0.75      2130\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.79      0.74      0.77      2073\n",
      "  not_recom       0.73      0.05      0.09       161\n",
      "\n",
      "avg / total       0.73      0.72      0.72      6480\n",
      "\n",
      "accuracy:  0.7219135802469135\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.71      0.69      0.70      2175\n",
      "   priority       0.76      0.81      0.78      2120\n",
      " spec_prior       0.00      0.00      0.00         4\n",
      "  recommend       0.76      0.79      0.78      2021\n",
      "  not_recom       0.79      0.09      0.17       160\n",
      "\n",
      "avg / total       0.74      0.74      0.74      6480\n",
      "\n",
      "accuracy:  0.7438271604938271\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.65      0.78      0.71      2098\n",
      "   priority       0.78      0.75      0.76      2147\n",
      " spec_prior       0.00      0.00      0.00         3\n",
      "  recommend       0.80      0.73      0.77      2065\n",
      "  not_recom       1.00      0.02      0.04       167\n",
      "\n",
      "avg / total       0.75      0.73      0.73      6480\n",
      "\n",
      "accuracy:  0.7344135802469136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.66      0.76      0.71      2118\n",
      "   priority       0.80      0.75      0.77      2167\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.78      0.77      0.77      2028\n",
      "  not_recom       0.83      0.09      0.16       165\n",
      "\n",
      "avg / total       0.75      0.74      0.74      6480\n",
      "\n",
      "accuracy:  0.741358024691358\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.67      0.71      0.69      2155\n",
      "   priority       0.75      0.79      0.77      2100\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.79      0.74      0.76      2058\n",
      "  not_recom       0.38      0.02      0.04       162\n",
      "\n",
      "avg / total       0.72      0.73      0.72      6480\n",
      "\n",
      "accuracy:  0.7308641975308642\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.65      0.76      0.70      2120\n",
      "   priority       0.78      0.74      0.76      2155\n",
      " spec_prior       0.00      0.00      0.00         6\n",
      "  recommend       0.79      0.76      0.77      2034\n",
      "  not_recom       0.45      0.03      0.06       165\n",
      "\n",
      "avg / total       0.73      0.73      0.73      6480\n",
      "\n",
      "accuracy:  0.7345679012345679\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.67      0.72      0.70      2153\n",
      "   priority       0.76      0.78      0.77      2112\n",
      " spec_prior       0.00      0.00      0.00         1\n",
      "  recommend       0.77      0.75      0.76      2052\n",
      "  not_recom       0.92      0.07      0.14       162\n",
      "\n",
      "avg / total       0.74      0.73      0.73      6480\n",
      "\n",
      "accuracy:  0.7333333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.65      0.75      0.70      2141\n",
      "   priority       0.76      0.73      0.75      2165\n",
      " spec_prior       0.00      0.00      0.00         2\n",
      "  recommend       0.78      0.74      0.76      2012\n",
      "  not_recom       0.86      0.07      0.14       160\n",
      "\n",
      "avg / total       0.73      0.72      0.72      6480\n",
      "\n",
      "accuracy:  0.7240740740740741\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " very_recom       0.67      0.72      0.70      2132\n",
      "   priority       0.75      0.78      0.77      2102\n",
      " spec_prior       0.00      0.00      0.00         5\n",
      "  recommend       0.79      0.76      0.77      2074\n",
      "  not_recom       0.62      0.05      0.09       167\n",
      "\n",
      "avg / total       0.73      0.74      0.73      6480\n",
      "\n",
      "accuracy:  0.7356481481481482\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(nurseryNum):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=150, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n",
    "        acc.append(accuracy_score(y_test, predicted))\n",
    "        print \"accuracy: \", accuracy_score(y_test, predicted)\n",
    "        \n",
    "mean_accuracy_model_minkowski.append(sum(acc)/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8004475308641975, 0.8899382716049384, 0.8934567901234567, 0.8936574074074075, 0.8976388888888888, 0.8804783950617285, 0.8470524691358022, 0.7784722222222223, 0.7331790123456791]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print mean_accuracy_model_minkowski\n",
    "k = [1, 5, 10, 15, 20, 30, 50, 100, 150]\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(k, mean_accuracy_model_minkowski)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(k, mean_accuracy_model_minkowski)\n",
    "ax.plot(k, mean_accuracy_model_euclidean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
