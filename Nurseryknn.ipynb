{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nursery.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:,0:8]\n",
    "labels = df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    if row[0] == 'usual':\n",
    "        row[0] = 1\n",
    "    elif row[0] == 'pretentious':\n",
    "        row[0] = 2\n",
    "    elif row[0] == 'great_pret':\n",
    "        row[0] = 3\n",
    "    \n",
    "    if row[1] == ' proper':\n",
    "        row[1] = 1\n",
    "    elif row[1] == ' less_proper':\n",
    "        row[1] = 2\n",
    "    elif row[1] == ' improper':\n",
    "        row[1] = 3\n",
    "    elif row[1] == ' critical':\n",
    "        row[1] = 4\n",
    "    elif row[1] == ' very_crit':\n",
    "        row[1] = 5\n",
    "    \n",
    "    if row[2] == ' complete':\n",
    "        row[2] = 1\n",
    "    elif row[2] == ' incomplete':\n",
    "        row[2] = 2\n",
    "    elif row[2] == ' foster':\n",
    "        row[2] = 3\n",
    "    elif row[2] == ' critical':\n",
    "        row[2] = 4\n",
    "    elif row[2] == ' completed':\n",
    "        row[2] = 5\n",
    "       \n",
    "    if row[3] == ' more':\n",
    "        row[3] = 10\n",
    "        \n",
    "    if row[4] == ' convenient':\n",
    "        row[4] = 1\n",
    "    elif row[4] == ' less_conv':\n",
    "        row[4] = 2\n",
    "    elif row[4] == ' critical':\n",
    "        row[4] = 3\n",
    "    \n",
    "    if row[5] == ' convenient':\n",
    "        row[5] = 1\n",
    "    elif row[5] == ' inconv':\n",
    "        row[5] = 2\n",
    "   \n",
    "    if row[6] == ' nonprob':\n",
    "        row[6] = 1\n",
    "    elif row[6] == ' slightly_prob':\n",
    "        row[6] = 2\n",
    "    elif row[6] == ' problematic':\n",
    "        row[6] = 2\n",
    "        \n",
    "    if row[7] == ' recommended':\n",
    "        row[7] = 1\n",
    "    elif row[7] == ' not_recom':\n",
    "        row[7] = 2\n",
    "    elif row[7] == ' priority':\n",
    "        row[7] = 2\n",
    "#print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = data.iloc[:10000,0:8]\n",
    "dataTest = data.iloc[10000:,0:8]\n",
    "labelsTrain = labels.iloc[0:10000]\n",
    "labelsTest = labels.iloc[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, algorithm = 'auto', metric = 'minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(dataTrain, labelsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = knn.predict(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['recomend','not_recom', 'spec_recom', 'priority', 'spec_prior']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    recomend       0.42      0.43      0.42       980\n",
      "   not_recom       0.59      0.64      0.61       552\n",
      "  spec_recom       0.00      0.00      0.00         1\n",
      "    priority       0.65      0.61      0.63      1395\n",
      "  spec_prior       0.76      0.50      0.60        32\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      2960\n",
      "   macro avg       0.48      0.44      0.45      2960\n",
      "weighted avg       0.56      0.56      0.56      2960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(labelsTest, predicted, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True) #5 fores me 2 folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.42      0.40      2147\n",
      "    priority       0.59      0.66      0.63      2135\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.57      0.46      0.51      2041\n",
      "   not_recom       0.69      0.31      0.42       156\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.44      0.37      0.39      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.39      0.39      2173\n",
      "    priority       0.61      0.65      0.63      2131\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.55      0.53      0.54      2003\n",
      "   not_recom       0.68      0.34      0.46       172\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      6480\n",
      "   macro avg       0.44      0.38      0.40      6480\n",
      "weighted avg       0.52      0.52      0.51      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.41      0.40      2147\n",
      "    priority       0.60      0.65      0.63      2130\n",
      "  spec_prior       0.57      0.48      0.52      2042\n",
      "   not_recom       0.66      0.34      0.44       161\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.55      0.47      0.50      6480\n",
      "weighted avg       0.52      0.51      0.51      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.39      0.39      2173\n",
      "    priority       0.60      0.65      0.62      2136\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.55      0.52      0.54      2002\n",
      "   not_recom       0.73      0.28      0.40       167\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.45      0.37      0.39      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.41      0.39      2145\n",
      "    priority       0.60      0.63      0.62      2174\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.55      0.50      0.53      2005\n",
      "   not_recom       0.62      0.31      0.42       154\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.43      0.37      0.39      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.40      0.39      2175\n",
      "    priority       0.59      0.67      0.63      2092\n",
      "  spec_prior       0.56      0.50      0.53      2039\n",
      "   not_recom       0.71      0.26      0.38       174\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.56      0.46      0.48      6480\n",
      "weighted avg       0.52      0.51      0.51      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.40      0.42      0.41      2168\n",
      "    priority       0.60      0.67      0.63      2138\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.57      0.49      0.53      2015\n",
      "   not_recom       0.67      0.34      0.45       158\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      6480\n",
      "   macro avg       0.45      0.38      0.40      6480\n",
      "weighted avg       0.52      0.52      0.52      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.41      0.39      2152\n",
      "    priority       0.60      0.64      0.62      2128\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.56      0.49      0.53      2029\n",
      "   not_recom       0.68      0.29      0.40       170\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.44      0.37      0.39      6480\n",
      "weighted avg       0.52      0.51      0.51      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.37      0.39      0.38      2151\n",
      "    priority       0.60      0.65      0.63      2148\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.56      0.50      0.53      2038\n",
      "   not_recom       0.63      0.35      0.45       142\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.43      0.38      0.40      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.39      0.42      0.40      2169\n",
      "    priority       0.59      0.65      0.62      2118\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.56      0.48      0.52      2006\n",
      "   not_recom       0.76      0.23      0.35       186\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.46      0.35      0.38      6480\n",
      "weighted avg       0.51      0.51      0.50      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric and k tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.37      0.41      0.39      2112\n",
      "    priority       0.60      0.64      0.62      2159\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.57      0.48      0.52      2047\n",
      "   not_recom       0.64      0.32      0.42       161\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.43      0.37      0.39      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.37      0.38      2208\n",
      "    priority       0.60      0.65      0.62      2107\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.54      0.52      0.53      1997\n",
      "   not_recom       0.72      0.33      0.45       167\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.45      0.38      0.40      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.41      0.40      2159\n",
      "    priority       0.60      0.65      0.62      2127\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.56      0.50      0.53      2032\n",
      "   not_recom       0.69      0.33      0.45       161\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.45      0.38      0.40      6480\n",
      "weighted avg       0.52      0.51      0.51      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.39      0.41      0.40      2161\n",
      "    priority       0.60      0.66      0.63      2139\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.55      0.48      0.51      2012\n",
      "   not_recom       0.70      0.32      0.44       167\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.45      0.37      0.40      6480\n",
      "weighted avg       0.52      0.51      0.51      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.39      0.40      0.39      2166\n",
      "    priority       0.59      0.67      0.63      2141\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.56      0.49      0.52      2014\n",
      "   not_recom       0.72      0.30      0.43       158\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.45      0.37      0.39      6480\n",
      "weighted avg       0.52      0.51      0.51      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.39      0.40      0.39      2154\n",
      "    priority       0.60      0.65      0.63      2125\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.56      0.51      0.53      2030\n",
      "   not_recom       0.62      0.32      0.42       170\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      6480\n",
      "   macro avg       0.43      0.38      0.40      6480\n",
      "weighted avg       0.52      0.52      0.51      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.39      0.43      0.41      2167\n",
      "    priority       0.60      0.64      0.62      2093\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.56      0.49      0.53      2052\n",
      "   not_recom       0.67      0.33      0.44       166\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.44      0.38      0.40      6480\n",
      "weighted avg       0.52      0.51      0.51      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.39      0.40      0.40      2153\n",
      "    priority       0.61      0.67      0.64      2173\n",
      "  spec_prior       0.56      0.50      0.53      1992\n",
      "   not_recom       0.67      0.43      0.53       162\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      6480\n",
      "   macro avg       0.56      0.50      0.52      6480\n",
      "weighted avg       0.52      0.52      0.52      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.39      0.40      0.39      2158\n",
      "    priority       0.61      0.65      0.63      2123\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.55      0.52      0.53      2039\n",
      "   not_recom       0.73      0.38      0.50       159\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      6480\n",
      "   macro avg       0.45      0.39      0.41      6480\n",
      "weighted avg       0.52      0.52      0.52      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.38      0.41      0.40      2162\n",
      "    priority       0.59      0.66      0.63      2143\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.55      0.47      0.51      2005\n",
      "   not_recom       0.68      0.30      0.42       169\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      6480\n",
      "   macro avg       0.44      0.37      0.39      6480\n",
      "weighted avg       0.51      0.51      0.51      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.53      0.48      2144\n",
      "    priority       0.67      0.61      0.64      2129\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.53      0.56      2034\n",
      "   not_recom       0.76      0.27      0.40       171\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.49      0.39      0.42      6480\n",
      "weighted avg       0.57      0.55      0.55      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.49      0.46      2176\n",
      "    priority       0.64      0.67      0.65      2137\n",
      "  spec_prior       0.58      0.48      0.53      2010\n",
      "   not_recom       0.88      0.24      0.38       157\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.63      0.47      0.50      6480\n",
      "weighted avg       0.55      0.54      0.54      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.47      0.45      2176\n",
      "    priority       0.63      0.66      0.64      2110\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.52      0.55      2043\n",
      "   not_recom       0.73      0.29      0.41       150\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.48      0.39      0.41      6480\n",
      "weighted avg       0.55      0.54      0.54      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.54      0.48      2144\n",
      "    priority       0.65      0.63      0.64      2156\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.49      0.54      2001\n",
      "   not_recom       0.87      0.22      0.35       178\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.51      0.38      0.40      6480\n",
      "weighted avg       0.57      0.55      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.54      0.48      2115\n",
      "    priority       0.65      0.63      0.64      2144\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.61      0.49      0.54      2056\n",
      "   not_recom       0.82      0.23      0.36       163\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.50      0.38      0.40      6480\n",
      "weighted avg       0.57      0.55      0.55      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.48      0.46      2205\n",
      "    priority       0.63      0.66      0.65      2122\n",
      "  spec_prior       0.57      0.51      0.54      1988\n",
      "   not_recom       0.78      0.28      0.41       165\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.60      0.48      0.51      6480\n",
      "weighted avg       0.55      0.54      0.54      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.51      0.47      2181\n",
      "    priority       0.65      0.65      0.65      2137\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.51      0.54      1993\n",
      "   not_recom       0.87      0.24      0.38       168\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.51      0.38      0.41      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.53      0.48      2139\n",
      "    priority       0.64      0.63      0.63      2129\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.50      0.54      2051\n",
      "   not_recom       0.75      0.26      0.38       160\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.48      0.38      0.41      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.42      0.56      0.48      2119\n",
      "    priority       0.65      0.60      0.62      2136\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.47      0.53      2060\n",
      "   not_recom       0.78      0.30      0.43       164\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.49      0.39      0.41      6480\n",
      "weighted avg       0.56      0.54      0.54      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.46      0.45      2201\n",
      "    priority       0.64      0.65      0.64      2130\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.56      0.53      0.55      1984\n",
      "   not_recom       0.73      0.30      0.42       164\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.47      0.39      0.41      6480\n",
      "weighted avg       0.55      0.54      0.54      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.42      0.50      0.46      2190\n",
      "    priority       0.63      0.62      0.62      2133\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.57      0.51      0.53      1986\n",
      "   not_recom       0.81      0.15      0.26       169\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      6480\n",
      "   macro avg       0.49      0.35      0.37      6480\n",
      "weighted avg       0.54      0.53      0.53      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.42      0.51      0.46      2130\n",
      "    priority       0.63      0.64      0.64      2133\n",
      "  spec_prior       0.58      0.48      0.52      2058\n",
      "   not_recom       0.74      0.27      0.40       159\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.60      0.47      0.51      6480\n",
      "weighted avg       0.55      0.54      0.54      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.54      0.48      2133\n",
      "    priority       0.64      0.63      0.64      2132\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.47      0.52      2059\n",
      "   not_recom       0.74      0.32      0.45       155\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.48      0.39      0.42      6480\n",
      "weighted avg       0.56      0.54      0.54      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.50      0.47      2187\n",
      "    priority       0.65      0.64      0.65      2134\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.52      0.55      1985\n",
      "   not_recom       0.77      0.25      0.38       173\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.49      0.38      0.41      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.42      0.47      0.45      2202\n",
      "    priority       0.63      0.66      0.64      2092\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.56      0.50      0.53      2023\n",
      "   not_recom       0.78      0.22      0.34       161\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      6480\n",
      "   macro avg       0.48      0.37      0.39      6480\n",
      "weighted avg       0.54      0.53      0.53      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.42      0.52      0.47      2118\n",
      "    priority       0.65      0.61      0.63      2174\n",
      "  spec_prior       0.57      0.50      0.53      2021\n",
      "   not_recom       0.80      0.28      0.42       167\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.61      0.48      0.51      6480\n",
      "weighted avg       0.56      0.54      0.54      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.53      0.48      2154\n",
      "    priority       0.64      0.63      0.64      2139\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.58      0.48      0.53      2017\n",
      "   not_recom       0.76      0.28      0.41       168\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6480\n",
      "   macro avg       0.48      0.39      0.41      6480\n",
      "weighted avg       0.56      0.54      0.54      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.51      0.47      2166\n",
      "    priority       0.64      0.63      0.64      2127\n",
      "  spec_prior       0.59      0.51      0.55      2027\n",
      "   not_recom       0.84      0.23      0.36       160\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.63      0.47      0.50      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.42      0.49      0.46      2192\n",
      "    priority       0.64      0.63      0.63      2158\n",
      "  spec_prior       0.56      0.50      0.53      1979\n",
      "   not_recom       0.72      0.26      0.38       151\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      6480\n",
      "   macro avg       0.59      0.47      0.50      6480\n",
      "weighted avg       0.54      0.53      0.53      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.42      0.50      0.46      2128\n",
      "    priority       0.62      0.65      0.63      2108\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.48      0.53      2065\n",
      "   not_recom       0.76      0.21      0.33       177\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      6480\n",
      "   macro avg       0.48      0.37      0.39      6480\n",
      "weighted avg       0.55      0.53      0.53      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.50      0.47      2133\n",
      "    priority       0.65      0.67      0.66      2154\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.55      0.57      2034\n",
      "   not_recom       0.92      0.14      0.24       157\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.52      0.37      0.39      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.40      0.43      2187\n",
      "    priority       0.63      0.72      0.67      2112\n",
      "  spec_prior       0.60      0.63      0.61      2010\n",
      "   not_recom       1.00      0.08      0.15       171\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.67      0.46      0.47      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.50      0.48      2111\n",
      "    priority       0.64      0.72      0.68      2116\n",
      "  spec_prior       0.64      0.53      0.58      2079\n",
      "   not_recom       0.93      0.07      0.14       174\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.66      0.46      0.47      6480\n",
      "weighted avg       0.59      0.57      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.43      0.45      2209\n",
      "    priority       0.65      0.66      0.65      2150\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.56      0.62      0.59      1965\n",
      "   not_recom       0.86      0.12      0.22       154\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.51      0.37      0.38      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.49      0.47      2166\n",
      "    priority       0.64      0.67      0.65      2121\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.58      0.59      2021\n",
      "   not_recom       0.70      0.09      0.16       171\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.48      0.37      0.38      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.44      0.44      2154\n",
      "    priority       0.64      0.68      0.66      2145\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.60      0.59      2023\n",
      "   not_recom       0.78      0.09      0.16       157\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.49      0.36      0.37      6480\n",
      "weighted avg       0.56      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.47      0.46      2136\n",
      "    priority       0.65      0.69      0.67      2116\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.60      0.61      2063\n",
      "   not_recom       0.80      0.10      0.17       164\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.50      0.37      0.38      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.45      0.46      2184\n",
      "    priority       0.63      0.69      0.66      2150\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.58      0.58      1981\n",
      "   not_recom       0.93      0.09      0.16       164\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.52      0.36      0.37      6480\n",
      "weighted avg       0.57      0.56      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.47      0.46      2157\n",
      "    priority       0.64      0.71      0.67      2101\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.56      0.58      2062\n",
      "   not_recom       0.95      0.12      0.21       159\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.53      0.37      0.38      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.44      0.45      2163\n",
      "    priority       0.64      0.69      0.67      2165\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.61      0.61      1982\n",
      "   not_recom       0.83      0.11      0.20       169\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.51      0.37      0.38      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=30, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.51      0.47      2123\n",
      "    priority       0.66      0.64      0.65      2145\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.56      0.58      2045\n",
      "   not_recom       0.90      0.23      0.37       165\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.52      0.39      0.41      6480\n",
      "weighted avg       0.58      0.56      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.44      0.44      2197\n",
      "    priority       0.63      0.69      0.66      2121\n",
      "  spec_prior       0.58      0.55      0.57      1999\n",
      "   not_recom       0.86      0.19      0.31       163\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.63      0.47      0.49      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.51      0.47      2120\n",
      "    priority       0.65      0.63      0.64      2151\n",
      "  spec_prior       0.59      0.53      0.56      2048\n",
      "   not_recom       0.79      0.19      0.30       161\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.61      0.46      0.49      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.43      0.44      2200\n",
      "    priority       0.63      0.68      0.65      2115\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.57      0.58      0.57      1996\n",
      "   not_recom       0.83      0.18      0.30       167\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.50      0.37      0.39      6480\n",
      "weighted avg       0.55      0.55      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.46      0.45      2177\n",
      "    priority       0.63      0.67      0.65      2077\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.55      0.57      2075\n",
      "   not_recom       0.87      0.18      0.30       150\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.50      0.37      0.39      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.49      0.46      2143\n",
      "    priority       0.66      0.62      0.64      2189\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.57      0.56      0.56      1969\n",
      "   not_recom       0.80      0.24      0.37       178\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.49      0.38      0.41      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.47      0.46      2159\n",
      "    priority       0.64      0.68      0.66      2121\n",
      "  spec_prior       0.58      0.55      0.56      2019\n",
      "   not_recom       0.89      0.17      0.29       181\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.64      0.47      0.49      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.50      0.47      2161\n",
      "    priority       0.66      0.65      0.65      2145\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.55      0.57      2025\n",
      "   not_recom       0.77      0.28      0.41       147\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.49      0.40      0.42      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.45      0.45      2181\n",
      "    priority       0.63      0.69      0.66      2104\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.56      0.57      2020\n",
      "   not_recom       0.87      0.16      0.26       174\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.51      0.37      0.39      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.43      0.50      0.46      2139\n",
      "    priority       0.65      0.65      0.65      2162\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.54      0.56      2024\n",
      "   not_recom       0.74      0.23      0.35       154\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.48      0.38      0.41      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=15, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.42      0.44      2164\n",
      "    priority       0.65      0.72      0.69      2157\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.64      0.61      2004\n",
      "   not_recom       1.00      0.06      0.12       154\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.54      0.37      0.37      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.45      0.46      2156\n",
      "    priority       0.64      0.70      0.67      2109\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.63      0.62      2040\n",
      "   not_recom       0.00      0.00      0.00       174\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.56      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.44      0.45      2138\n",
      "    priority       0.63      0.69      0.66      2137\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.61      0.60      2036\n",
      "   not_recom       1.00      0.04      0.08       168\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.36      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.41      0.43      2182\n",
      "    priority       0.63      0.71      0.67      2129\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.64      0.61      2008\n",
      "   not_recom       1.00      0.04      0.08       160\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.36      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.46      0.46      2144\n",
      "    priority       0.65      0.69      0.67      2134\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.63      0.62      2046\n",
      "   not_recom       1.00      0.03      0.06       155\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.55      0.36      0.36      6480\n",
      "weighted avg       0.59      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.41      0.44      2176\n",
      "    priority       0.63      0.71      0.67      2132\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.64      0.62      1998\n",
      "   not_recom       1.00      0.05      0.09       173\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.36      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.42      0.45      2174\n",
      "    priority       0.63      0.71      0.67      2109\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.63      0.61      2025\n",
      "   not_recom       0.83      0.03      0.06       170\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.51      0.36      0.36      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.46      0.46      2146\n",
      "    priority       0.65      0.68      0.67      2157\n",
      "  spec_prior       0.60      0.63      0.62      2019\n",
      "   not_recom       0.78      0.04      0.08       158\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.63      0.45      0.46      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.36      0.41      2206\n",
      "    priority       0.61      0.75      0.68      2130\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.64      0.61      1971\n",
      "   not_recom       0.71      0.03      0.06       172\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.48      0.36      0.35      6480\n",
      "weighted avg       0.56      0.57      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.51      0.48      2114\n",
      "    priority       0.67      0.63      0.65      2136\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.63      0.62      2073\n",
      "   not_recom       0.91      0.06      0.12       156\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.53      0.37      0.37      6480\n",
      "weighted avg       0.59      0.58      0.57      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=50, algorithm = 'auto', metric = 'euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.59      0.50      2068\n",
      "    priority       0.68      0.59      0.64      2202\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.51      0.55      2051\n",
      "   not_recom       0.83      0.18      0.30       158\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.51      0.38      0.40      6480\n",
      "weighted avg       0.58      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.42      0.44      2252\n",
      "    priority       0.62      0.73      0.67      2064\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.57      0.57      1993\n",
      "   not_recom       0.79      0.14      0.23       170\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.49      0.37      0.38      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.50      0.47      2142\n",
      "    priority       0.66      0.65      0.65      2145\n",
      "  spec_prior       0.59      0.56      0.58      2023\n",
      "   not_recom       0.77      0.16      0.26       170\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.62      0.47      0.49      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.47      0.46      2178\n",
      "    priority       0.64      0.67      0.66      2121\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.55      0.57      2021\n",
      "   not_recom       0.86      0.20      0.33       158\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.51      0.38      0.40      6480\n",
      "weighted avg       0.56      0.56      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.52      0.48      2167\n",
      "    priority       0.64      0.68      0.66      2078\n",
      "  spec_prior       0.61      0.50      0.55      2077\n",
      "   not_recom       0.85      0.22      0.34       158\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.64      0.48      0.51      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.50      0.47      2153\n",
      "    priority       0.66      0.65      0.65      2188\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.58      0.56      0.57      1967\n",
      "   not_recom       0.81      0.13      0.22       170\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.50      0.37      0.38      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.48      0.46      2197\n",
      "    priority       0.63      0.68      0.65      2111\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.54      0.56      2004\n",
      "   not_recom       0.90      0.11      0.20       167\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.51      0.36      0.38      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.51      0.47      2123\n",
      "    priority       0.65      0.64      0.64      2155\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.55      0.57      2040\n",
      "   not_recom       0.88      0.23      0.36       161\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.51      0.38      0.41      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.48      0.46      2184\n",
      "    priority       0.64      0.66      0.65      2109\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.58      0.55      0.57      2018\n",
      "   not_recom       0.90      0.17      0.28       167\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      6480\n",
      "   macro avg       0.51      0.37      0.39      6480\n",
      "weighted avg       0.56      0.55      0.55      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.52      0.48      2136\n",
      "    priority       0.66      0.65      0.65      2157\n",
      "  spec_prior       0.59      0.53      0.56      2026\n",
      "   not_recom       0.96      0.14      0.24       161\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.66      0.46      0.48      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=20, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.52      0.48      2101\n",
      "    priority       0.65      0.67      0.66      2160\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.61      0.53      0.57      2045\n",
      "   not_recom       0.91      0.12      0.21       172\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.52      0.37      0.38      6480\n",
      "weighted avg       0.58      0.56      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.39      0.43      2219\n",
      "    priority       0.64      0.72      0.68      2106\n",
      "  spec_prior       0.59      0.66      0.62      1999\n",
      "   not_recom       0.96      0.16      0.27       156\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.66      0.48      0.50      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.46      0.47      2188\n",
      "    priority       0.64      0.69      0.66      2096\n",
      "  spec_prior       0.59      0.59      0.59      2022\n",
      "   not_recom       0.85      0.13      0.22       174\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.64      0.47      0.49      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.52      0.48      2132\n",
      "    priority       0.67      0.66      0.67      2170\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.56      0.58      2022\n",
      "   not_recom       0.84      0.18      0.29       154\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.51      0.38      0.40      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.46      0.46      2202\n",
      "    priority       0.63      0.70      0.66      2096\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.57      0.58      2024\n",
      "   not_recom       0.85      0.18      0.29       157\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.51      0.38      0.40      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.50      0.48      2118\n",
      "    priority       0.66      0.67      0.67      2170\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.59      0.60      2020\n",
      "   not_recom       0.82      0.16      0.26       171\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.51      0.38      0.40      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.50      0.47      2133\n",
      "    priority       0.66      0.66      0.66      2163\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.56      0.58      2027\n",
      "   not_recom       1.00      0.12      0.22       156\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.54      0.37      0.39      6480\n",
      "weighted avg       0.58      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.42      0.43      2187\n",
      "    priority       0.63      0.71      0.66      2103\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.59      0.59      2017\n",
      "   not_recom       0.88      0.16      0.27       172\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.51      0.38      0.39      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.46      0.46      2180\n",
      "    priority       0.64      0.70      0.67      2128\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.59      0.59      2002\n",
      "   not_recom       0.91      0.12      0.21       169\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.52      0.37      0.38      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.49      0.47      2140\n",
      "    priority       0.67      0.67      0.67      2138\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.58      0.59      2042\n",
      "   not_recom       0.64      0.21      0.32       159\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.47      0.39      0.41      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=25, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.41      0.43      2172\n",
      "    priority       0.63      0.74      0.68      2082\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.61      0.61      2056\n",
      "   not_recom       0.86      0.07      0.13       169\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.51      0.37      0.37      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.48      0.47      2148\n",
      "    priority       0.64      0.66      0.65      2184\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.57      0.58      1988\n",
      "   not_recom       0.78      0.09      0.16       159\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.49      0.36      0.37      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.43      0.45      2180\n",
      "    priority       0.63      0.74      0.68      2105\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.58      0.59      2035\n",
      "   not_recom       0.89      0.10      0.18       158\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.52      0.37      0.38      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.46      0.46      2140\n",
      "    priority       0.65      0.67      0.66      2161\n",
      "  spec_prior       0.58      0.61      0.60      2009\n",
      "   not_recom       1.00      0.08      0.15       170\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.67      0.46      0.47      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.43      0.44      2147\n",
      "    priority       0.64      0.71      0.67      2138\n",
      "  spec_prior       0.60      0.63      0.61      2027\n",
      "   not_recom       0.93      0.08      0.15       168\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.66      0.46      0.47      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.46      0.46      2173\n",
      "    priority       0.64      0.71      0.68      2128\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.59      0.59      2017\n",
      "   not_recom       1.00      0.06      0.12       160\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.37      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.47      0.46      2115\n",
      "    priority       0.65      0.66      0.66      2184\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.61      0.60      2015\n",
      "   not_recom       0.82      0.11      0.19       165\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.50      0.37      0.38      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.42      0.45      2205\n",
      "    priority       0.62      0.74      0.67      2082\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.60      0.61      2029\n",
      "   not_recom       1.00      0.07      0.14       163\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.37      0.37      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.43      0.45      2145\n",
      "    priority       0.64      0.71      0.67      2159\n",
      "  spec_prior       0.60      0.60      0.60      2012\n",
      "   not_recom       1.00      0.04      0.08       164\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.67      0.45      0.45      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.45      0.45      2175\n",
      "    priority       0.64      0.69      0.66      2107\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.61      0.60      2032\n",
      "   not_recom       0.73      0.05      0.09       164\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.48      0.36      0.36      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=35, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.41      0.44      2175\n",
      "    priority       0.65      0.68      0.66      2154\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.58      0.69      0.63      1978\n",
      "   not_recom       0.86      0.04      0.07       171\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.51      0.36      0.36      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.45      0.46      2145\n",
      "    priority       0.63      0.73      0.67      2112\n",
      "  spec_prior       0.63      0.60      0.61      2066\n",
      "   not_recom       1.00      0.04      0.09       157\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.68      0.46      0.46      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.44      0.45      2160\n",
      "    priority       0.64      0.68      0.66      2116\n",
      "  spec_prior       0.60      0.62      0.61      2050\n",
      "   not_recom       0.88      0.05      0.09       154\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.64      0.45      0.45      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.42      0.45      2160\n",
      "    priority       0.64      0.71      0.67      2150\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.64      0.61      1994\n",
      "   not_recom       1.00      0.01      0.02       174\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.35      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.51      0.48      2091\n",
      "    priority       0.66      0.69      0.67      2182\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.61      0.57      0.59      2036\n",
      "   not_recom       0.89      0.05      0.09       169\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.52      0.36      0.37      6480\n",
      "weighted avg       0.59      0.57      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.37      0.42      2229\n",
      "    priority       0.63      0.73      0.67      2084\n",
      "  spec_prior       0.58      0.69      0.63      2008\n",
      "   not_recom       1.00      0.05      0.10       159\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.67      0.46      0.45      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.44      0.45      2117\n",
      "    priority       0.63      0.71      0.67      2144\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.61      0.60      0.61      2041\n",
      "   not_recom       1.00      0.01      0.02       176\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.35      0.35      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.39      0.43      2203\n",
      "    priority       0.63      0.70      0.67      2122\n",
      "  spec_prior       0.58      0.67      0.62      2003\n",
      "   not_recom       0.86      0.04      0.08       152\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.64      0.45      0.45      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.48      0.47      2119\n",
      "    priority       0.65      0.70      0.67      2148\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.62      0.58      0.60      2051\n",
      "   not_recom       0.82      0.06      0.11       160\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.51      0.36      0.37      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.39      0.43      2201\n",
      "    priority       0.62      0.69      0.66      2118\n",
      "  spec_prior       0.58      0.67      0.62      1993\n",
      "   not_recom       1.00      0.03      0.06       168\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.67      0.44      0.44      6480\n",
      "weighted avg       0.57      0.56      0.55      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=50, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.41      0.44      2147\n",
      "    priority       0.63      0.70      0.66      2120\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.66      0.62      2054\n",
      "   not_recom       1.00      0.01      0.01       158\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.35      0.35      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.34      0.40      2173\n",
      "    priority       0.63      0.73      0.68      2146\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.72      0.65      1990\n",
      "   not_recom       0.00      0.00      0.00       170\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.34      0.40      2193\n",
      "    priority       0.62      0.74      0.68      2138\n",
      "  spec_prior       0.58      0.70      0.63      1999\n",
      "   not_recom       0.00      0.00      0.00       150\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.42      0.45      0.43      6480\n",
      "weighted avg       0.55      0.58      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.41      0.45      2127\n",
      "    priority       0.63      0.71      0.67      2128\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.61      0.68      0.64      2045\n",
      "   not_recom       0.00      0.00      0.00       178\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.35      0.36      0.35      6480\n",
      "weighted avg       0.56      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.36      0.42      2156\n",
      "    priority       0.62      0.74      0.68      2117\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.69      0.64      2064\n",
      "   not_recom       1.00      0.01      0.01       142\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.54      0.36      0.35      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.38      0.42      2164\n",
      "    priority       0.63      0.72      0.67      2149\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.69      0.63      1980\n",
      "   not_recom       0.00      0.00      0.00       186\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.55      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.37      0.41      2169\n",
      "    priority       0.62      0.74      0.68      2088\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.67      0.64      2057\n",
      "   not_recom       0.00      0.00      0.00       165\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.38      0.42      2151\n",
      "    priority       0.63      0.70      0.67      2178\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.68      0.62      1987\n",
      "   not_recom       1.00      0.01      0.01       163\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.35      0.35      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.38      0.43      2146\n",
      "    priority       0.63      0.73      0.68      2149\n",
      "  spec_prior       0.59      0.68      0.63      2029\n",
      "   not_recom       0.00      0.00      0.00       156\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.43      0.45      0.43      6480\n",
      "weighted avg       0.56      0.58      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.37      0.42      2174\n",
      "    priority       0.63      0.75      0.68      2117\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.69      0.64      2015\n",
      "   not_recom       1.00      0.01      0.01       172\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.54      0.36      0.35      6480\n",
      "weighted avg       0.58      0.58      0.56      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.27      0.35      2185\n",
      "    priority       0.59      0.79      0.68      2112\n",
      "  spec_prior       0.59      0.71      0.65      2022\n",
      "   not_recom       0.00      0.00      0.00       161\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.42      0.44      0.42      6480\n",
      "weighted avg       0.54      0.57      0.54      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.31      0.38      2135\n",
      "    priority       0.62      0.74      0.67      2154\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.58      0.73      0.64      2022\n",
      "   not_recom       0.00      0.00      0.00       167\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.34      6480\n",
      "weighted avg       0.55      0.58      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.51      0.27      0.36      2158\n",
      "    priority       0.61      0.78      0.68      2137\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.74      0.65      2016\n",
      "   not_recom       0.00      0.00      0.00       168\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.34      6480\n",
      "weighted avg       0.55      0.58      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.31      0.38      2162\n",
      "    priority       0.60      0.74      0.66      2129\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.72      0.64      2028\n",
      "   not_recom       0.00      0.00      0.00       160\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.33      0.35      0.34      6480\n",
      "weighted avg       0.54      0.57      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.30      0.37      2154\n",
      "    priority       0.61      0.74      0.67      2145\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.72      0.64      2023\n",
      "   not_recom       0.00      0.00      0.00       157\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.34      0.35      0.34      6480\n",
      "weighted avg       0.55      0.57      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.28      0.36      2166\n",
      "    priority       0.61      0.79      0.69      2121\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.73      0.65      2021\n",
      "   not_recom       0.00      0.00      0.00       171\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.34      6480\n",
      "weighted avg       0.55      0.58      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.31      0.38      2151\n",
      "    priority       0.61      0.77      0.68      2106\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.70      0.64      2054\n",
      "   not_recom       0.00      0.00      0.00       167\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.34      0.36      0.34      6480\n",
      "weighted avg       0.54      0.57      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.50      0.28      0.36      2169\n",
      "    priority       0.61      0.77      0.68      2160\n",
      "  spec_prior       0.58      0.74      0.65      1990\n",
      "   not_recom       0.00      0.00      0.00       161\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.42      0.45      0.42      6480\n",
      "weighted avg       0.55      0.58      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.50      0.28      0.36      2183\n",
      "    priority       0.60      0.79      0.68      2087\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.72      0.65      2049\n",
      "   not_recom       0.00      0.00      0.00       160\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.34      6480\n",
      "weighted avg       0.55      0.58      0.54      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.31      0.38      2137\n",
      "    priority       0.61      0.72      0.66      2179\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.74      0.65      1995\n",
      "   not_recom       0.00      0.00      0.00       168\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.34      0.35      0.34      6480\n",
      "weighted avg       0.54      0.57      0.55      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=200, algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and K with distance weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.35      0.33      2197\n",
      "    priority       0.55      0.56      0.56      2122\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.42      0.44      2000\n",
      "   not_recom       0.61      0.32      0.42       160\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.39      0.33      0.35      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.38      0.34      2123\n",
      "    priority       0.55      0.54      0.55      2144\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.39      0.43      2044\n",
      "   not_recom       0.60      0.35      0.44       168\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.39      0.33      0.35      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.38      0.34      2114\n",
      "    priority       0.55      0.55      0.55      2150\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.39      0.43      2039\n",
      "   not_recom       0.49      0.24      0.32       176\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.37      0.31      0.33      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.36      0.34      2206\n",
      "    priority       0.55      0.53      0.54      2116\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.42      0.44      2005\n",
      "   not_recom       0.46      0.34      0.39       152\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.36      0.33      0.34      6480\n",
      "weighted avg       0.44      0.43      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.34      2189\n",
      "    priority       0.56      0.56      0.56      2135\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.46      0.40      0.43      1993\n",
      "   not_recom       0.54      0.35      0.43       163\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.38      0.34      0.35      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.40      0.35      2131\n",
      "    priority       0.57      0.53      0.55      2131\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.47      0.39      0.43      2051\n",
      "   not_recom       0.51      0.33      0.40       165\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.37      0.33      0.35      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.34      2180\n",
      "    priority       0.56      0.53      0.55      2166\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.46      0.40      0.43      1985\n",
      "   not_recom       0.49      0.34      0.40       149\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.36      0.33      0.34      6480\n",
      "weighted avg       0.44      0.43      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.39      0.35      2140\n",
      "    priority       0.55      0.53      0.54      2100\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.47      0.40      0.43      2059\n",
      "   not_recom       0.55      0.29      0.38       179\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.38      0.32      0.34      6480\n",
      "weighted avg       0.45      0.43      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.38      0.35      2164\n",
      "    priority       0.57      0.53      0.55      2155\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.47      0.42      0.44      1995\n",
      "   not_recom       0.50      0.33      0.39       166\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.37      0.33      0.35      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.34      2156\n",
      "    priority       0.55      0.57      0.56      2111\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.48      0.40      0.44      2049\n",
      "   not_recom       0.54      0.32      0.40       162\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.38      0.33      0.35      6480\n",
      "weighted avg       0.45      0.44      0.45      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, weights = 'distance', algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.39      0.35      2156\n",
      "    priority       0.58      0.52      0.55      2167\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.45      0.42      0.43      1998\n",
      "   not_recom       0.54      0.31      0.39       158\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.38      0.33      0.35      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.34      2164\n",
      "    priority       0.55      0.55      0.55      2099\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.40      0.43      2046\n",
      "   not_recom       0.49      0.29      0.36       170\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.37      0.32      0.34      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.40      0.36      2160\n",
      "    priority       0.57      0.51      0.54      2159\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.41      0.43      2020\n",
      "   not_recom       0.42      0.29      0.34       140\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.36      0.32      0.34      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.41      0.37      2160\n",
      "    priority       0.55      0.53      0.54      2107\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.39      0.43      2024\n",
      "   not_recom       0.57      0.27      0.37       188\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.38      0.32      0.34      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.39      0.35      2158\n",
      "    priority       0.56      0.53      0.55      2130\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.47      0.43      0.45      2028\n",
      "   not_recom       0.51      0.25      0.33       162\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.37      0.32      0.34      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.39      0.35      2162\n",
      "    priority       0.56      0.54      0.55      2136\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.46      0.40      0.43      2016\n",
      "   not_recom       0.55      0.31      0.40       166\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.38      0.33      0.35      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.39      0.36      2155\n",
      "    priority       0.57      0.53      0.55      2176\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.44      0.45      1970\n",
      "   not_recom       0.44      0.23      0.30       178\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.36      0.32      0.33      6480\n",
      "weighted avg       0.46      0.44      0.45      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.34      0.42      0.37      2165\n",
      "    priority       0.56      0.52      0.54      2090\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.49      0.40      0.44      2074\n",
      "   not_recom       0.53      0.32      0.40       150\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.38      0.33      0.35      6480\n",
      "weighted avg       0.46      0.44      0.45      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.39      0.36      2158\n",
      "    priority       0.57      0.55      0.56      2107\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.48      0.42      0.45      2033\n",
      "   not_recom       0.57      0.24      0.34       181\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      6480\n",
      "   macro avg       0.39      0.32      0.34      6480\n",
      "weighted avg       0.46      0.45      0.45      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.41      0.37      2162\n",
      "    priority       0.58      0.53      0.56      2159\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.40      0.43      2011\n",
      "   not_recom       0.50      0.38      0.43       147\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      6480\n",
      "   macro avg       0.38      0.35      0.36      6480\n",
      "weighted avg       0.46      0.45      0.45      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, weights = 'distance', algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.34      2189\n",
      "    priority       0.56      0.53      0.54      2126\n",
      "  spec_prior       0.46      0.44      0.45      1996\n",
      "   not_recom       0.45      0.23      0.31       169\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.45      0.39      0.41      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.38      0.35      2131\n",
      "    priority       0.57      0.54      0.55      2140\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.48      0.43      0.45      2048\n",
      "   not_recom       0.45      0.25      0.32       159\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.36      0.32      0.33      6480\n",
      "weighted avg       0.45      0.44      0.45      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.36      0.34      2192\n",
      "    priority       0.56      0.55      0.55      2059\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.43      0.45      2068\n",
      "   not_recom       0.46      0.26      0.33       160\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.36      0.32      0.33      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.40      0.36      2128\n",
      "    priority       0.58      0.52      0.55      2207\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.43      0.45      1976\n",
      "   not_recom       0.46      0.25      0.32       168\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.37      0.32      0.33      6480\n",
      "weighted avg       0.46      0.44      0.45      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.38      0.35      2153\n",
      "    priority       0.56      0.55      0.56      2143\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.41      0.44      2026\n",
      "   not_recom       0.49      0.24      0.32       157\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.37      0.32      0.33      6480\n",
      "weighted avg       0.45      0.44      0.45      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.38      0.35      2167\n",
      "    priority       0.57      0.52      0.54      2123\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.44      0.46      2018\n",
      "   not_recom       0.44      0.22      0.29       171\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.36      0.31      0.33      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.39      0.36      2152\n",
      "    priority       0.57      0.54      0.55      2100\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.48      0.42      0.45      2065\n",
      "   not_recom       0.47      0.28      0.35       163\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      6480\n",
      "   macro avg       0.37      0.33      0.34      6480\n",
      "weighted avg       0.46      0.45      0.45      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.40      0.36      2168\n",
      "    priority       0.57      0.52      0.55      2166\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.46      0.42      0.44      1979\n",
      "   not_recom       0.48      0.25      0.33       165\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.37      0.32      0.34      6480\n",
      "weighted avg       0.46      0.44      0.45      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.36      0.34      2135\n",
      "    priority       0.56      0.55      0.56      2163\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.47      0.41      0.44      2017\n",
      "   not_recom       0.43      0.21      0.28       165\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.35      0.31      0.32      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.37      0.34      2185\n",
      "    priority       0.55      0.53      0.54      2103\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.46      0.42      0.44      2027\n",
      "   not_recom       0.42      0.20      0.27       163\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.35      0.30      0.32      6480\n",
      "weighted avg       0.44      0.43      0.43      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=15, weights = 'distance', algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.36      0.34      2164\n",
      "    priority       0.56      0.55      0.55      2156\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.44      0.45      1993\n",
      "   not_recom       0.23      0.06      0.10       166\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.31      0.28      0.29      6480\n",
      "weighted avg       0.44      0.44      0.44      6480\n",
      "\n",
      "5\n",
      "5\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.38      0.35      2156\n",
      "    priority       0.55      0.51      0.53      2110\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.44      0.45      2051\n",
      "   not_recom       0.24      0.07      0.11       162\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.32      0.28      0.29      6480\n",
      "weighted avg       0.44      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.34      2170\n",
      "    priority       0.56      0.53      0.54      2121\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.47      0.45      0.46      2032\n",
      "   not_recom       0.25      0.10      0.14       155\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.32      0.29      0.30      6480\n",
      "weighted avg       0.44      0.44      0.44      6480\n",
      "\n",
      "5\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.35      2150\n",
      "    priority       0.56      0.53      0.55      2145\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.47      0.44      0.46      2012\n",
      "   not_recom       0.18      0.05      0.08       173\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.31      0.28      0.29      6480\n",
      "weighted avg       0.44      0.44      0.44      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.37      0.34      2133\n",
      "    priority       0.55      0.52      0.54      2147\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.43      0.45      2028\n",
      "   not_recom       0.11      0.03      0.05       171\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.29      0.27      0.27      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "5\n",
      "5\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.36      0.34      2187\n",
      "    priority       0.54      0.52      0.53      2119\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.43      0.45      2016\n",
      "   not_recom       0.20      0.07      0.10       157\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.30      0.28      0.28      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "4\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.34      2127\n",
      "    priority       0.56      0.52      0.54      2156\n",
      "  spec_prior       0.47      0.44      0.45      2040\n",
      "   not_recom       0.20      0.06      0.09       157\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.39      0.35      0.36      6480\n",
      "weighted avg       0.44      0.44      0.44      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.34      0.33      2193\n",
      "    priority       0.54      0.54      0.54      2110\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.46      0.45      0.46      2004\n",
      "   not_recom       0.12      0.04      0.05       171\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.29      0.27      0.28      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.36      0.33      2137\n",
      "    priority       0.54      0.51      0.53      2150\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.44      0.45      2024\n",
      "   not_recom       0.11      0.04      0.05       168\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.29      0.27      0.27      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "5\n",
      "5\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.35      0.33      2183\n",
      "    priority       0.54      0.53      0.54      2116\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.44      0.45      2020\n",
      "   not_recom       0.24      0.08      0.12       160\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.31      0.28      0.29      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=50, weights = 'distance', algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        print len(set(predicted))\n",
    "        print len(set(y_test))\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.35      0.33      2164\n",
      "    priority       0.55      0.55      0.55      2133\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.46      0.44      0.45      2018\n",
      "   not_recom       0.05      0.01      0.02       163\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.28      0.27      0.27      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "4\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.34      2156\n",
      "    priority       0.54      0.51      0.53      2133\n",
      "  spec_prior       0.46      0.43      0.45      2026\n",
      "   not_recom       0.05      0.01      0.02       165\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.34      0.33      0.33      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "5\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.34      0.32      2162\n",
      "    priority       0.55      0.51      0.53      2140\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.45      0.46      0.46      2017\n",
      "   not_recom       0.00      0.00      0.00       161\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.26      0.26      0.26      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.34      0.32      2158\n",
      "    priority       0.53      0.54      0.54      2126\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.46      0.44      0.45      2027\n",
      "   not_recom       0.02      0.01      0.01       167\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.27      0.27      0.26      6480\n",
      "weighted avg       0.42      0.43      0.43      6480\n",
      "\n",
      "5\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.35      0.33      2117\n",
      "    priority       0.56      0.53      0.54      2190\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.46      0.45      0.46      2019\n",
      "   not_recom       0.05      0.01      0.02       154\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.28      0.27      0.27      6480\n",
      "weighted avg       0.44      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.33      0.32      2203\n",
      "    priority       0.53      0.53      0.53      2076\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.45      0.45      0.45      2025\n",
      "   not_recom       0.03      0.01      0.01       174\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      6480\n",
      "   macro avg       0.26      0.26      0.26      6480\n",
      "weighted avg       0.42      0.42      0.42      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.35      0.33      2160\n",
      "    priority       0.56      0.52      0.54      2169\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.45      0.45      0.45      1981\n",
      "   not_recom       0.00      0.00      0.00       169\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.26      0.26      0.26      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.34      0.32      2160\n",
      "    priority       0.55      0.55      0.55      2097\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.44      0.45      2063\n",
      "   not_recom       0.06      0.01      0.02       159\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.27      0.27      0.27      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "5\n",
      "5\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.36      0.33      2119\n",
      "    priority       0.56      0.50      0.53      2185\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.46      0.46      2016\n",
      "   not_recom       0.04      0.01      0.02       159\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.27      0.27      0.27      6480\n",
      "weighted avg       0.43      0.43      0.43      6480\n",
      "\n",
      "4\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.31      0.33      0.32      2201\n",
      "    priority       0.52      0.54      0.53      2081\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.45      0.45      2028\n",
      "   not_recom       0.00      0.00      0.00       169\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      6480\n",
      "   macro avg       0.26      0.26      0.26      6480\n",
      "weighted avg       0.42      0.43      0.42      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, weights = 'distance', algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm selection and k tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.44      0.46      2186\n",
      "    priority       0.65      0.70      0.67      2143\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.64      0.61      1987\n",
      "   not_recom       1.00      0.04      0.08       163\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.54      0.36      0.36      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.45      0.45      2134\n",
      "    priority       0.63      0.72      0.68      2123\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.62      0.60      0.61      2057\n",
      "   not_recom       0.88      0.04      0.08       165\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.52      0.36      0.36      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.44      0.46      2164\n",
      "    priority       0.63      0.74      0.68      2123\n",
      "  spec_prior       0.60      0.59      0.60      2009\n",
      "   not_recom       1.00      0.01      0.02       184\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.68      0.45      0.44      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.48      0.48      2156\n",
      "    priority       0.66      0.68      0.67      2143\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.61      0.60      2035\n",
      "   not_recom       0.65      0.09      0.16       144\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.48      0.37      0.38      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.43      0.45      2162\n",
      "    priority       0.65      0.69      0.67      2180\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.65      0.62      1980\n",
      "   not_recom       1.00      0.04      0.07       157\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.36      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.43      0.44      2158\n",
      "    priority       0.63      0.74      0.68      2086\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.58      0.59      2064\n",
      "   not_recom       1.00      0.05      0.09       171\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.36      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.42      0.44      2169\n",
      "    priority       0.62      0.74      0.67      2098\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.61      0.61      2043\n",
      "   not_recom       1.00      0.01      0.02       169\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.35      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.46      0.46      2151\n",
      "    priority       0.65      0.68      0.67      2168\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.60      0.59      2001\n",
      "   not_recom       1.00      0.08      0.14       159\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.37      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.44      0.45      2155\n",
      "    priority       0.62      0.72      0.67      2099\n",
      "  spec_prior       0.62      0.58      0.60      2071\n",
      "   not_recom       1.00      0.01      0.03       155\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.67      0.44      0.44      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.46      0.46      2165\n",
      "    priority       0.65      0.68      0.66      2167\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.62      0.60      1973\n",
      "   not_recom       1.00      0.03      0.07       173\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.36      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=50, algorithm = 'ball_tree', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.33      0.39      2223\n",
      "    priority       0.60      0.79      0.68      2081\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.58      0.66      0.62      2006\n",
      "   not_recom       0.00      0.00      0.00       168\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.33      0.35      0.34      6480\n",
      "weighted avg       0.54      0.57      0.54      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.42      0.45      2097\n",
      "    priority       0.64      0.68      0.66      2185\n",
      "  spec_prior       0.60      0.68      0.64      2038\n",
      "   not_recom       0.00      0.00      0.00       160\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.43      0.44      0.44      6480\n",
      "weighted avg       0.56      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.39      0.42      2144\n",
      "    priority       0.62      0.71      0.66      2127\n",
      "  spec_prior       0.59      0.67      0.63      2023\n",
      "   not_recom       0.00      0.00      0.00       186\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.42      0.44      0.43      6480\n",
      "weighted avg       0.54      0.57      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.38      0.43      2176\n",
      "    priority       0.63      0.73      0.68      2139\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.67      0.63      2021\n",
      "   not_recom       1.00      0.01      0.03       142\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.54      0.36      0.35      6480\n",
      "weighted avg       0.58      0.58      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.40      0.44      2151\n",
      "    priority       0.64      0.73      0.68      2136\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.67      0.63      2032\n",
      "   not_recom       0.00      0.00      0.00       160\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.56      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.38      0.43      2169\n",
      "    priority       0.63      0.73      0.68      2130\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.67      0.63      2012\n",
      "   not_recom       0.00      0.00      0.00       168\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.37      0.42      2169\n",
      "    priority       0.63      0.75      0.68      2102\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.67      0.63      2053\n",
      "   not_recom       0.00      0.00      0.00       155\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.41      0.44      2151\n",
      "    priority       0.63      0.72      0.67      2164\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.65      0.62      1991\n",
      "   not_recom       0.00      0.00      0.00       173\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.40      0.43      2167\n",
      "    priority       0.64      0.71      0.67      2155\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.67      0.63      1991\n",
      "   not_recom       0.00      0.00      0.00       166\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.55      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.36      0.41      2153\n",
      "    priority       0.61      0.74      0.67      2111\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.67      0.64      2053\n",
      "   not_recom       0.00      0.00      0.00       162\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.34      0.35      0.34      6480\n",
      "weighted avg       0.55      0.57      0.56      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, algorithm = 'ball_tree', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.40      0.36      2092\n",
      "    priority       0.57      0.53      0.55      2141\n",
      "  spec_prior       0.49      0.41      0.45      2082\n",
      "   not_recom       0.44      0.22      0.29       165\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.45      0.39      0.41      6480\n",
      "weighted avg       0.46      0.44      0.45      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.35      0.33      2228\n",
      "    priority       0.56      0.54      0.55      2125\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.46      0.46      0.46      1962\n",
      "   not_recom       0.44      0.18      0.26       163\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.36      0.31      0.32      6480\n",
      "weighted avg       0.44      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.41      0.36      2121\n",
      "    priority       0.55      0.53      0.54      2096\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.48      0.41      0.45      2088\n",
      "   not_recom       0.43      0.17      0.25       175\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.36      0.30      0.32      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.37      0.35      2199\n",
      "    priority       0.56      0.54      0.55      2170\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.46      0.44      0.45      1956\n",
      "   not_recom       0.40      0.22      0.28       153\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.35      0.31      0.33      6480\n",
      "weighted avg       0.45      0.44      0.45      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.38      0.35      2137\n",
      "    priority       0.57      0.54      0.56      2154\n",
      "  spec_prior       0.47      0.42      0.44      2029\n",
      "   not_recom       0.48      0.26      0.33       160\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.46      0.40      0.42      6480\n",
      "weighted avg       0.46      0.44      0.45      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.34      2183\n",
      "    priority       0.55      0.53      0.54      2112\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.47      0.44      0.45      2015\n",
      "   not_recom       0.39      0.17      0.24       168\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.35      0.30      0.31      6480\n",
      "weighted avg       0.44      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.33      0.38      0.35      2175\n",
      "    priority       0.55      0.54      0.54      2130\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.46      0.41      0.44      2009\n",
      "   not_recom       0.37      0.20      0.25       164\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.34      0.30      0.32      6480\n",
      "weighted avg       0.44      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.37      0.34      2145\n",
      "    priority       0.56      0.52      0.54      2136\n",
      "  spec_prior       0.00      0.00      0.00         0\n",
      "   recommend       0.47      0.44      0.46      2035\n",
      "   not_recom       0.42      0.19      0.26       164\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.35      0.30      0.32      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.38      0.35      2168\n",
      "    priority       0.56      0.53      0.55      2126\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.46      0.43      0.44      2028\n",
      "   not_recom       0.48      0.23      0.31       157\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.36      0.31      0.33      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' recommend', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.32      0.38      0.35      2152\n",
      "    priority       0.55      0.53      0.54      2140\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.47      0.41      0.44      2016\n",
      "   not_recom       0.47      0.23      0.31       171\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6480\n",
      "   macro avg       0.36      0.31      0.33      6480\n",
      "weighted avg       0.45      0.44      0.44      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=20, weights = 'distance', algorithm = 'auto', metric = 'minkowski')\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm and k tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.50      0.47      2143\n",
      "    priority       0.64      0.68      0.66      2170\n",
      "  spec_prior       0.60      0.55      0.58      2002\n",
      "   not_recom       1.00      0.10      0.18       165\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.68      0.46      0.47      6480\n",
      "weighted avg       0.58      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.48      0.47      2177\n",
      "    priority       0.64      0.69      0.66      2096\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.56      0.58      2042\n",
      "   not_recom       0.81      0.13      0.22       163\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.50      0.37      0.39      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.53      0.50      2112\n",
      "    priority       0.66      0.67      0.67      2186\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.62      0.56      0.59      2006\n",
      "   not_recom       0.80      0.05      0.09       175\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.51      0.36      0.37      6480\n",
      "weighted avg       0.59      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.46      0.46      2208\n",
      "    priority       0.63      0.72      0.67      2080\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.56      0.57      2038\n",
      "   not_recom       0.70      0.14      0.23       153\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.48      0.37      0.39      6480\n",
      "weighted avg       0.56      0.56      0.56      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.47      0.47      2166\n",
      "    priority       0.64      0.69      0.67      2181\n",
      "  spec_prior       0.60      0.58      0.59      1955\n",
      "   not_recom       0.83      0.11      0.19       178\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.63      0.46      0.48      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.51      0.48      2154\n",
      "    priority       0.64      0.71      0.67      2085\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.62      0.52      0.56      2089\n",
      "   not_recom       0.80      0.11      0.19       150\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.50      0.37      0.38      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.49      0.47      2131\n",
      "    priority       0.65      0.68      0.66      2168\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.56      0.58      2011\n",
      "   not_recom       0.85      0.13      0.23       169\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.51      0.37      0.39      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.46      0.46      2189\n",
      "    priority       0.63      0.71      0.67      2098\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.57      0.59      2033\n",
      "   not_recom       0.78      0.09      0.16       159\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.49      0.37      0.37      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.50      0.47      2129\n",
      "    priority       0.66      0.67      0.66      2154\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.56      0.58      2016\n",
      "   not_recom       0.94      0.09      0.16       180\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.53      0.36      0.38      6480\n",
      "weighted avg       0.58      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.43      0.44      2191\n",
      "    priority       0.63      0.72      0.67      2112\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.58      0.56      0.57      2028\n",
      "   not_recom       0.80      0.16      0.27       148\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.49      0.37      0.39      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=30, algorithm = 'ball_tree', metric = 'minkowski', leaf_size = 10)\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.49      0.47      2154\n",
      "    priority       0.65      0.67      0.66      2164\n",
      "  spec_prior       0.59      0.57      0.58      1996\n",
      "   not_recom       0.94      0.10      0.18       166\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.66      0.46      0.47      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.48      0.47      2166\n",
      "    priority       0.64      0.74      0.68      2102\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.62      0.54      0.58      2048\n",
      "   not_recom       0.94      0.10      0.19       162\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.53      0.37      0.38      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.47      0.46      2149\n",
      "    priority       0.64      0.71      0.67      2127\n",
      "  spec_prior       0.60      0.55      0.57      2045\n",
      "   not_recom       0.83      0.13      0.22       159\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.63      0.46      0.48      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.44      0.45      0.45      2171\n",
      "    priority       0.62      0.70      0.66      2139\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.56      0.58      1999\n",
      "   not_recom       0.85      0.07      0.12       169\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.50      0.35      0.36      6480\n",
      "weighted avg       0.56      0.56      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.46      0.46      2165\n",
      "    priority       0.64      0.71      0.67      2125\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.56      0.58      2026\n",
      "   not_recom       0.94      0.10      0.19       163\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.53      0.37      0.38      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.49      0.47      2155\n",
      "    priority       0.65      0.68      0.66      2141\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.56      0.58      2018\n",
      "   not_recom       0.95      0.13      0.22       165\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.53      0.37      0.39      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.48      0.47      2158\n",
      "    priority       0.66      0.71      0.68      2136\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.62      0.57      0.59      2048\n",
      "   not_recom       0.87      0.15      0.25       137\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.52      0.38      0.40      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.45      0.47      0.46      2162\n",
      "    priority       0.63      0.69      0.66      2130\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.60      0.55      0.57      1996\n",
      "   not_recom       0.95      0.09      0.17       191\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.52      0.36      0.37      6480\n",
      "weighted avg       0.57      0.56      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.46      0.46      2167\n",
      "    priority       0.65      0.67      0.66      2162\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.61      0.60      1993\n",
      "   not_recom       1.00      0.13      0.24       157\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.37      0.39      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.50      0.47      2153\n",
      "    priority       0.63      0.71      0.67      2104\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.52      0.56      2051\n",
      "   not_recom       0.86      0.07      0.13       171\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.51      0.36      0.37      6480\n",
      "weighted avg       0.57      0.56      0.56      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=30, algorithm = 'ball_tree', metric = 'minkowski', leaf_size = 20)\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.46      0.47      2154\n",
      "    priority       0.65      0.73      0.69      2140\n",
      "  spec_prior       0.61      0.60      0.61      2014\n",
      "   not_recom       1.00      0.04      0.08       172\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.68      0.46      0.46      6480\n",
      "weighted avg       0.59      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.43      0.45      2166\n",
      "    priority       0.63      0.72      0.68      2126\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.62      0.61      2030\n",
      "   not_recom       0.78      0.04      0.08       156\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.50      0.36      0.36      6480\n",
      "weighted avg       0.57      0.58      0.57      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.44      0.46      2171\n",
      "    priority       0.63      0.74      0.68      2102\n",
      "  spec_prior       0.62      0.60      0.61      2036\n",
      "   not_recom       1.00      0.01      0.01       171\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.68      0.45      0.44      6480\n",
      "weighted avg       0.58      0.58      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.46      0.46      2149\n",
      "    priority       0.65      0.68      0.67      2164\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.63      0.61      2008\n",
      "   not_recom       0.91      0.06      0.12       157\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.52      0.37      0.37      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.45      0.45      2162\n",
      "    priority       0.64      0.69      0.66      2156\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.62      0.61      2004\n",
      "   not_recom       0.88      0.04      0.08       157\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.51      0.36      0.36      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.44      0.45      2158\n",
      "    priority       0.63      0.71      0.67      2110\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.62      0.62      0.62      2040\n",
      "   not_recom       0.67      0.01      0.02       171\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.48      0.36      0.35      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.48      0.47      2126\n",
      "    priority       0.66      0.69      0.67      2147\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.60      0.60      2044\n",
      "   not_recom       0.86      0.07      0.14       162\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.52      0.37      0.38      6480\n",
      "weighted avg       0.58      0.58      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.40      0.44      2194\n",
      "    priority       0.62      0.75      0.68      2119\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.61      0.60      2000\n",
      "   not_recom       1.00      0.03      0.06       166\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.35      6480\n",
      "weighted avg       0.57      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.45      0.46      2135\n",
      "    priority       0.65      0.69      0.67      2148\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.61      0.60      2046\n",
      "   not_recom       0.91      0.07      0.12       150\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.52      0.36      0.37      6480\n",
      "weighted avg       0.58      0.57      0.57      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.44      0.46      2185\n",
      "    priority       0.63      0.74      0.68      2118\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.61      0.60      0.60      1998\n",
      "   not_recom       1.00      0.02      0.03       178\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.36      0.35      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=50, algorithm = 'ball_tree', metric = 'minkowski', leaf_size = 10)\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.49      0.38      0.42      2173\n",
      "    priority       0.65      0.72      0.68      2172\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.58      0.71      0.64      1972\n",
      "   not_recom       1.00      0.01      0.01       161\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.54      0.36      0.35      6480\n",
      "weighted avg       0.58      0.58      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.39      0.43      2147\n",
      "    priority       0.62      0.75      0.68      2094\n",
      "  spec_prior       0.61      0.64      0.63      2072\n",
      "   not_recom       0.00      0.00      0.00       167\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.43      0.45      0.43      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.46      0.43      0.44      2126\n",
      "    priority       0.65      0.68      0.67      2179\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.66      0.62      2023\n",
      "   not_recom       1.00      0.01      0.01       151\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.54      0.35      0.35      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.33      0.39      2194\n",
      "    priority       0.61      0.76      0.67      2087\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.59      0.69      0.63      2021\n",
      "   not_recom       0.00      0.00      0.00       177\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.34      0.36      0.34      6480\n",
      "weighted avg       0.54      0.57      0.55      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.49      0.48      2057\n",
      "    priority       0.66      0.65      0.66      2204\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.62      0.64      0.63      2065\n",
      "   not_recom       1.00      0.02      0.04       153\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.55      0.36      0.36      6480\n",
      "weighted avg       0.60      0.58      0.58      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.29      0.36      2263\n",
      "    priority       0.59      0.78      0.67      2062\n",
      "  spec_prior       0.00      0.00      0.00         1\n",
      "   recommend       0.57      0.69      0.62      1979\n",
      "   not_recom       0.00      0.00      0.00       175\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      6480\n",
      "   macro avg       0.33      0.35      0.33      6480\n",
      "weighted avg       0.53      0.56      0.53      6480\n",
      "\n",
      "set([' very_recom', ' priority', ' spec_prior', ' not_recom'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.47      0.40      0.43      2157\n",
      "    priority       0.63      0.72      0.67      2138\n",
      "  spec_prior       0.60      0.65      0.62      2024\n",
      "   not_recom       1.00      0.01      0.02       161\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.67      0.45      0.44      6480\n",
      "weighted avg       0.58      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.37      0.42      2163\n",
      "    priority       0.63      0.74      0.68      2128\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.60      0.67      0.63      2020\n",
      "   not_recom       0.00      0.00      0.00       167\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.34      0.36      0.35      6480\n",
      "weighted avg       0.55      0.58      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.37      0.42      2153\n",
      "    priority       0.61      0.76      0.68      2124\n",
      "  spec_prior       0.60      0.64      0.62      2042\n",
      "   not_recom       0.00      0.00      0.00       161\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      6480\n",
      "   macro avg       0.42      0.44      0.43      6480\n",
      "weighted avg       0.55      0.57      0.56      6480\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  very_recom       0.48      0.40      0.44      2167\n",
      "    priority       0.64      0.69      0.67      2142\n",
      "  spec_prior       0.00      0.00      0.00         2\n",
      "   recommend       0.59      0.70      0.64      2002\n",
      "   not_recom       1.00      0.01      0.01       167\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      6480\n",
      "   macro avg       0.54      0.36      0.35      6480\n",
      "weighted avg       0.58      0.58      0.56      6480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        all_labels = pd.concat([y_train, y_test], axis=0)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, algorithm = 'ball_tree', metric = 'minkowski', leaf_size = 20)\n",
    "        knn.fit(X_train, y_train)\n",
    "        predicted = knn.predict(X_test)\n",
    "        if len(set(predicted)) == len(set(y_test)):\n",
    "            unique_labels = set(predicted)\n",
    "            print unique_labels\n",
    "        elif len(set(predicted)) < len(set(y_test)):\n",
    "            unique_labels = set(y_test)\n",
    "        else :\n",
    "            unique_labels = set(predicted)\n",
    "        print classification_report(y_test, predicted, target_names=unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
